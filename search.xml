<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Docker 容器文件（数据）共享</title>
      <link href="/2023/03/23/Docker%20%E5%AE%B9%E5%99%A8%E6%96%87%E4%BB%B6%EF%BC%88%E6%95%B0%E6%8D%AE%EF%BC%89%E5%85%B1%E4%BA%AB/"/>
      <url>/2023/03/23/Docker%20%E5%AE%B9%E5%99%A8%E6%96%87%E4%BB%B6%EF%BC%88%E6%95%B0%E6%8D%AE%EF%BC%89%E5%85%B1%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908134844265.png" alt="image-20220908134844265"></p><p><font color=Brown><strong>Author</strong>：rab</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>有这样一个场景，当我们的服务都是通过容器化方式时，不仅要考虑数据持久化的问题，在 web 集群的时候也要考虑到数据共享的问题，如我需要负载均衡多个 web 服务（这些 web 主要是作为前端展示），且这些 web 服务的功能完全一致，那这时就可用到我们的文件共享技术了。而文件共享又分为两种情况：<code>容器与 Host 共享</code>、<code>容器间数据共享</code>，接下来分别介绍以下这两种文件（数据）共享方式。</p><h2 id="一、共享"><a href="#一、共享" class="headerlink" title="一、共享"></a>一、共享</h2><h3 id="1-1-容器与-Host-共享"><a href="#1-1-容器与-Host-共享" class="headerlink" title="1.1 容器与 Host 共享"></a>1.1 容器与 Host 共享</h3><p>对于容器与 Host 共享间进行数据共享也是比较常用的，比如，当我们运行某个容器的时候，我们需要获取到该容器的配置文件（实现动态配置和持久化），我们一般的做法就是去该服务的官网去下载配置文件或 copy 容器中的配置文件到 Host（其实这就实现了文档的共享了）。</p><p>以 Nginx 为例，看看容器的文件如何共享到 Host 上。</p><p>1、先运行一个 nginx 容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=my-web nginx:1.20.2</span><br></pre></td></tr></table></figure><p>2、将容器数据复制到 Host</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker cp my-web:/etc/nginx/nginx.conf .</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这样就将nginx容器的配置文件复制到Host的当前目录下</span></span><br></pre></td></tr></table></figure><p>3、将 Host 的数据复制到容器内部</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在Host上创建一个测试文件</span></span><br><span class="line">touch web.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将创建的文件copy到容器内部</span></span><br><span class="line">docker cp web.conf my-web:/etc/nginx/conf.d/</span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;这样就实现了容器与 Host 间的数据共享了，准确说不叫共享，应该叫做容器和 Host 之间可以互相传输文件或实现 Docker 容器的持久化存储。&#x3D;&#x3D;</p><h3 id="1-2-容器间共享"><a href="#1-2-容器间共享" class="headerlink" title="1.2 容器间共享"></a>1.2 容器间共享</h3><h4 id="1-2-1-bind-mount"><a href="#1-2-1-bind-mount" class="headerlink" title="1.2.1 bind mount"></a>1.2.1 bind mount</h4><p>这种共享方式是多个容器共享 Host 上的数据，即将共享数据放在 bind mount 中，然后将其 mount 到多个容器中，我们以 nginx 容器为例进行演示。</p><p>1、创建共享数据（目录或文件）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/web/conf.d</span><br><span class="line">touch /data/web/conf.d/web.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我就以一个目录为共享数据</span></span><br></pre></td></tr></table></figure><p>2、运行 nginx 容器（并将共享数据 mount 到容器中）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=web-1 -v /data/web/conf.d:/etc/nginx/conf.d nginx:1.20.2</span><br><span class="line">docker run -itd --name=web-2 -v /data/web/conf.d:/etc/nginx/conf.d nginx:1.20.2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行两个容器，且这两个容器共享同一个Host数据（目录或文件）</span></span><br></pre></td></tr></table></figure><p>3、验证数据是否 mount 到容器中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@shop ~]# docker exec -it web-1 bash</span><br><span class="line">root@5d3c487a409a:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br><span class="line">root@5d3c487a409a:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@shop ~]# docker exec -it web-2 bash</span><br><span class="line">root@fdbb7e98d971:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908115951256.png" alt="image-20220908115951256"></p><p>&#x3D;&#x3D;这样就实现了多个容器共享同个数据。&#x3D;&#x3D;</p><h4 id="1-2-2-volume-container"><a href="#1-2-2-volume-container" class="headerlink" title="1.2.2 volume container"></a>1.2.2 volume container</h4><p>上面是多个容器共享 Host 里面的数据（目录或文件），而这个方式共享则是多个容器共享同个容器中的数据卷（该数据卷类型可以是 bind mount，也可以是 managed volume）。</p><p>1、创建共享容器的数据卷</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/conf.d</span><br><span class="line">touch /root/conf.d/web.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我就以一个目录为共享数据</span></span><br></pre></td></tr></table></figure><p>2、运行共享容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker create --name=share_data -v /root/conf.d:/etc/nginx/conf.d busybox</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意：提供数据共享的这个容器是可以不需要运行的，因此只需创建即可</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908124543366.png" alt="image-20220908124543366"></p><p>3、其他容器共享刚创建的容器数据卷</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=web-1 --volumes-from share_data nginx:1.20.2</span><br><span class="line">docker run -itd --name=web-2 --volumes-from share_data nginx:1.20.2</span><br></pre></td></tr></table></figure><p>4、验证数据是否被共享</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@shop ~]# docker exec -it web-1 bash</span><br><span class="line">root@5daf7ba565cd:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br><span class="line">root@5daf7ba565cd:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@shop ~]# docker exec -it web-2 bash</span><br><span class="line">root@5510e1b6b4cb:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908124816867.png" alt="image-20220908124816867"></p><p>&#x3D;&#x3D;这有什么好处？其实对于多个容器共享数据（或数据持久化时），在运行容器时不需要指定 Host 的共享目录，而只需指定提供共享数据的容器的容器名即可，这样的话更便于管理。&#x3D;&#x3D;</p><p>还有这样一种场景，如果我需要做容器应用数据迁移（如将容器 web-1 从主机 A 迁移至主机 B），对于以上的数据共享策略来说，还没真正实现数据随容器的迁移而迁移，于是我们可以将数据直接持久化到某个镜像中，这样在做数据迁移的时候就会随镜像的迁移而迁移，而这类方法只适用于数据存储较小或数据改动不是很大容器服务（如配置文件、静态文件等）。要实现这样的功能，就需要我们制作自定义镜像（如 Dockerfile），将数据 copy 到镜像中。</p><p>5、创建 Dockerfile </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/dockerfile &amp;&amp; cd /root/dockerfile</span><br><span class="line">touch web.conf</span><br><span class="line">vim Dockerfile</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908131305346.png" alt="image-20220908131305346"></p><p>6、构建镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t share:v1 .</span><br></pre></td></tr></table></figure><p>7、创建共享容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker create --name=share_data-1 share:v1</span><br></pre></td></tr></table></figure><p>8、运行 web 容器并进行数据共享</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=web-1 --volumes-from share_data-1 nginx:1.20.2</span><br><span class="line">docker run -itd --name=web-2 --volumes-from share_data-1 nginx:1.20.2</span><br></pre></td></tr></table></figure><p>9、验证数据是否被共享</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@shop dockerfile]# docker exec -it web-1 bash</span><br><span class="line">root@34a7c0d48078:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br><span class="line">root@34a7c0d48078:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@shop dockerfile]# docker exec -it web-2 bash</span><br><span class="line">root@d3a5bcf6b10b:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908131129793.png" alt="image-20220908131129793"></p><p>&#x3D;&#x3D;运行的 web 容器能正确读取 共享容器 volume 中数据，我们可看到，创建的共享容器不依赖于 Host 提供的数据，真正实现了 docker 容器服务的迁移即应用，只需要迁移目标提供 docker 环境即可。&#x3D;&#x3D;</p><h2 id="二、小结"><a href="#二、小结" class="headerlink" title="二、小结"></a>二、小结</h2><p>Docker 容器共享可实现容器与 Host 间共享、容器与容器间共享，其中共享 Host 数据的情况用的比较多，容器间共享也有在使用，如一些数据变动较小的容器服务，就可以采用容器间数据共享。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 环境下 Docker 容器的 PID 变化情况</title>
      <link href="/2023/03/23/Linux%20%E7%8E%AF%E5%A2%83%E4%B8%8B%20Docker%20%E5%AE%B9%E5%99%A8%E7%9A%84%20PID%20%E5%8F%98%E5%8C%96%E6%83%85%E5%86%B5/"/>
      <url>/2023/03/23/Linux%20%E7%8E%AF%E5%A2%83%E4%B8%8B%20Docker%20%E5%AE%B9%E5%99%A8%E7%9A%84%20PID%20%E5%8F%98%E5%8C%96%E6%83%85%E5%86%B5/</url>
      
        <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/docker-docs.webp" alt="docker-docs"></p><p>参考1：<a href="https://www.modb.pro/db/100271">https://www.modb.pro/db/100271</a></p><p>参考2：<a href="http://www.asznl.com/post/31">http://www.asznl.com/post/31</a></p><hr><p>有时候你使用 Docker 部署服务，在你的 Linux 系统上你会发现多出来一些进程，那我们如何通过这些进程 ID 来查看是由谁产生的呢？其实很简单，找到它父进程即可。</p><p>首先查看 Docker 服务本身进程 ID：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep dockerd</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221155349700.png" alt="image-20221221155349700"></p><p>可看到其 Dockerd 服务的子进程 ID 为 31803，父进程 ID 为 1。我们知道，Linux 中有<code>pid 0、pid 1 和 pid 2</code> 三个特殊的进程。</p><ul><li>pid 0：即 <code>“swapper”</code> 进程，是 pid 1 和 pid 2 的父进程；</li><li>pid 1：即 <code>“init”</code> 进程，是用户空间所有进程的父进程；</li><li>pid 2，即 <code>“kthreadd”</code> 进程，是内核空间所有进程的父进程。</li></ul><p>继续查看 <code>31803</code> 的进程信息：</p> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep 31803</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221155615309.png" alt="image-20221221155615309"></p><p>可以看到作为 <code>31803</code> 的父进程产生了很多子进程，其中就包括所有已经创建的容器进程 ID，可看到我们 Jenkins 容器监听的两个端口进程也是来源于 <code>31803</code>，如下图所示：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221152518700.png" alt="image-20221221152518700"></p><p>这里就出现一个问题，不同容器之间是相互隔离的，实际就是对进程的隔离，那这些容器运行的进程又在哪找呢？</p><p>我们先看看 <code>containerd-shim</code> </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep containerd-shim</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221161405255.png" alt="image-20221221161405255"></p><p>继续看看 949 的 PPID 是多少？</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221174525177.png" alt="image-20221221174525177"></p><p>这个时候，我们可以来看看 Docker 的基本架构图。从 Docker 1.11 版本开始，Docker 容器运行就不是简单通过 Docker Daemon 来启动了，而是通过集成 containerd、runc 等多个组件来完成的。虽然 Docker Daemon 守护进程模块在不停的重构，但是基本功能和定位没有太大的变化，一直都是 CS 架构，守护进程负责和 Docker Client 端交互，并管理 Docker 镜像和容器。现在的架构中组件 containerd 就会负责集群节点上容器的生命周期管理，并向上为 Docker Daemon 提供 gRPC 接口。</p><p>参考图1：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221161634949.png" alt="image-20221221161634949"></p><p>参考图2：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221163546886.png" alt="image-20221221163546886"></p><p>可以根据以下概念截图进程树查看：</p><ul><li><code>docker CLI</code> 命令行工具，是给用户和 docker daemon 建立通信的客户端</li><li><code>dockerd</code>: 是 docker 架构中一个常驻在后台的系统进程，称为 docker daemon，dockerd 实际调用的还是 containerd 的 api 接口。有了 containerd 之后，dockerd 可以独立升级，以此避免之前 dockerd 升级会导致所有容器不可用的问题。</li><li><code>containerd</code> 是 dockerd 和 runc 之间的一个中间交流组件，docker 对容器的管理和操作基本都是通过 containerd 完成的。containerd 的主要功能有：容器生命周期管理、日志管理、镜像管理、存储管理、容器网络接口及网络管理</li><li><code>containerd-shim</code> 是一个真实运行容器的载体，每启动一个容器都会起一个新的containerd-shim的一个进程， 它直接通过指定的三个参数：容器id，boundle目录（containerd 对应某个容器生成的目录，一般位于：&#x2F;var&#x2F;run&#x2F;docker&#x2F;libcontainerd&#x2F;containerID，其中包括了容器配置和标准输入、标准输出、标准错误三个管道文件），运行时二进制（默认为runC）来调用 runc 的 api 创建一个容器，上面的 docker 进程图中可以直观的显示。其主要作用是：<ul><li>它允许容器运行时(即 runC)在启动容器之后退出，简单说就是不必为每个容器一直运行一个容器运行时(runC)；</li><li>即使在 containerd 和 dockerd 都挂掉的情况下，容器的标准 IO 和其它的文件描述符也都是可用的；</li><li>向 containerd 报告容器的退出状态；</li><li>有了它就可以在不中断容器运行的情况下升级或重启 dockerd，对于生产环境来说意义重大。</li><li><code>runC</code> 是 Docker 公司按照 OCI 标准规范编写的一个操作容器的命令行工具，其前身是 libcontainer 项目演化而来，runC 实际上就是 libcontainer 配上了一个轻型的客户端，是一个命令行工具端，根据 OCI（开放容器组织）的标准来创建和运行容器，实现了容器启停、资源隔离等功能。</li></ul></li><li><code>docker-proxy</code>: 用来做端口映射的，其底层是默认使用iptables实现。</li></ul><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221181247275.png" alt="image-20221221181247275"></p><p>以上是 docker 19 的架构，但是到了 docker 20 时，结构就有变化了，貌似不再经过 containerd 了。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221173702572.png" alt="image-20221221173702572"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pstree -p</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221180909732.png" alt="image-20221221180909732"></p><p>和上图对比可看到少了 <code>containerd</code></p><p>通过 <code>docker inspect</code> 查看容器本身的 PID，如下图：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect &lt;容器名&gt;</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221181913969.png" alt="image-20221221181913969"></p><p>通过该 PID 就可以查看容器在 Host 中产生的 PID</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221182051790.png" alt="image-20221221182051790"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 容器间通信</title>
      <link href="/2023/03/23/Docker-%E5%AE%B9%E5%99%A8%E9%97%B4%E9%80%9A%E4%BF%A1/"/>
      <url>/2023/03/23/Docker-%E5%AE%B9%E5%99%A8%E9%97%B4%E9%80%9A%E4%BF%A1/</url>
      
        <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/docker.png" alt="docker"></p><hr><p>这里分两个部分来讲解，分别为：<code>容器间通信</code>和<code>外部（宿主机外的网络）与容器的通信</code>。</p><h2 id="一、容器间通信"><a href="#一、容器间通信" class="headerlink" title="一、容器间通信"></a>一、容器间通信</h2><h3 id="1-1-IP"><a href="#1-1-IP" class="headerlink" title="1.1 IP"></a>1.1 IP</h3><p>通过 IP 的形式来通信。试想一下，两个容器之间是相互隔离的，因此是无法互相 ping 通的，那如果运行的这两个容器使用的是同一个<code>自定义的网络模式</code>，那是否可以连接呢？答案是可以的。我们来实际测试一下。</p><p>前提条件：</p><ul><li>自定义网络名：net_b</li><li>自定义网络IP段：192.168.4.0&#x2F;244</li></ul><p><strong>创建 A 容器：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --name test_a --network=net_b busybox</span><br><span class="line">/ # ifconfig </span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:04:05  </span><br><span class="line">          inet addr:192.168.4.5  Bcast:192.168.4.255  Mask:255.255.255.0</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:9 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:726 (726.0 B)  TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p><strong>创建 B 容器：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --name test_b --network=net_b busybox</span><br><span class="line">/ # ifconfig </span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:04:06  </span><br><span class="line">          inet addr:192.168.4.6  Bcast:192.168.4.255  Mask:255.255.255.0</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:6 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:516 (516.0 B)  TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p>B 容器 ping A 容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ # ping 192.168.4.5</span><br><span class="line">PING 192.168.4.5 (192.168.4.5): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.5: seq=0 ttl=64 time=0.117 ms</span><br><span class="line">64 bytes from 192.168.4.5: seq=1 ttl=64 time=0.126 ms</span><br><span class="line">64 bytes from 192.168.4.5: seq=2 ttl=64 time=0.125 ms</span><br></pre></td></tr></table></figure><p>A 容器 ping B 容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ # ping 192.168.4.6</span><br><span class="line">PING 192.168.4.6 (192.168.4.6): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.6: seq=0 ttl=64 time=0.177 ms</span><br><span class="line">64 bytes from 192.168.4.6: seq=1 ttl=64 time=0.132 ms</span><br><span class="line">64 bytes from 192.168.4.6: seq=2 ttl=64 time=0.116 ms</span><br></pre></td></tr></table></figure><p>从结果看，A、B 容器可互相 通信。</p><p><strong>创建 C 容器：</strong></p><p>如果该容器为<code>普通 Bridge 网络模式</code>的容器（如：Nginx），那么容器 A 或容器 B 是否能访问 Nginx 容器呢？<code>答案是不能访问</code>。如何解决不可访问的问题？</p><p>如果 Host 上对每个网络都有一条路由，且 Host 打开了路由转发（net.ipv4.ip_forward &#x3D; 1），那不同网桥上的网络就可互相通信。此时，我在 C 容器上加入一块 A、B 容器的虚拟网卡设备，来实现与 A、B 容器的通信。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker network connect net_b nginx</span><br></pre></td></tr></table></figure><p>Nginx 容器里没有查看 IP 地址的命令，可通过 <code>docker inspect nginx</code> 来查看，如下图，Nginx 容器已经分配了 net_b 网络的一个 IP 地址。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182720975.png" alt="image-20221214182720975"></p><p>Nginx 容器的 index.html 我已经提前更改为：hello zhurs 111</p><p>A 容器 ping 一下 C 容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ # ping 192.168.4.4</span><br><span class="line">PING 192.168.4.4 (192.168.4.4): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.4: seq=0 ttl=64 time=0.214 ms</span><br><span class="line">64 bytes from 192.168.4.4: seq=1 ttl=64 time=0.129 ms</span><br><span class="line">64 bytes from 192.168.4.4: seq=2 ttl=64 time=0.225 ms</span><br></pre></td></tr></table></figure><p>A 容器访问 C 容器的 Nginx 内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/ # wget 192.168.4.4</span><br><span class="line">Connecting to 192.168.4.4 (192.168.4.4:80)</span><br><span class="line">saving to &#x27;index.html&#x27;</span><br><span class="line">index.html           100% |**************************************************************************************************************************|    16  0:00:00 ETA</span><br><span class="line">&#x27;index.html&#x27; saved</span><br><span class="line">/ # cat index.html </span><br><span class="line">hello zhurs 111</span><br></pre></td></tr></table></figure><p>从结果看，A 容器可正常访问 C 容器的资源。</p><p><strong>小结：</strong></p><ul><li>结论1：同一个<code>自定义网络（&quot;Driver&quot;: &quot;bridge&quot;）</code>下的所有容器可互相通信。</li><li>结论2：<code>自定义网络（&quot;Driver&quot;: &quot;bridge&quot;）</code> 想与<code>普通 Bridge 网络模式</code>进行通信，可在双方任意一方加入对方的网络模式即可。</li></ul><h3 id="1-2-Docker-DNS-Server"><a href="#1-2-Docker-DNS-Server" class="headerlink" title="1.2 Docker DNS Server"></a>1.2 Docker DNS Server</h3><p>上面提到网络驱动 Driver 为 bridge 的自定义网络模式下的容器可通过 IP 进行通信，但在实际应用场景中，IP 可能并不稳定（除非你自定义 IP），因此，我们可以通过<code>容器名</code>的方式进行通信。</p><p>创建容器名为 dns1：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --network=net_b --name=dns1 busybox</span><br></pre></td></tr></table></figure><p>创建容器名为 dns2：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --network=net_b --name=dns2 busybox</span><br><span class="line">/ # ping dns1</span><br><span class="line">PING dns1 (192.168.4.5): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.5: seq=0 ttl=64 time=0.107 ms</span><br><span class="line">64 bytes from 192.168.4.5: seq=1 ttl=64 time=0.121 ms</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可见，通过域名可正常通信，该通信方式等效于 IP 通信方式，无非就是一个通过 IP 方式，另一个通过容器名的方式。</p><p>但是需要注意，通过容器名通信的前提是：网络模式必须为<code>自定义网络（&quot;Driver&quot;: &quot;bridge&quot;）</code>模式</p><h3 id="1-3-Joined"><a href="#1-3-Joined" class="headerlink" title="1.3 Joined"></a>1.3 Joined</h3><p>这种模式类似 k8s 中 pod 的多容器情况，在 k8s 中，一个 pod 可有一个或多个容器，一般我们多出的那些容器主要起辅助作用，比如一些日志监控等。Docker 的 Joined 通信类型也类似，该模式的作用是：它可使两个或多个容器共享一个网络栈（网卡、配置信息等），因此 Joined 模式下的所有容器可通过 <code>127.0.0.1</code> 直接通信，你可以将他们想象为是一个整体。</p><p><strong>如何实现？</strong></p><blockquote><p>在运行容器时指定要 joined 的目标容器，成功后将共享目标容器的网络栈。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --name=join-test --network=container:nginx busybox</span><br><span class="line">/ # ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">388: eth1@if389: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue </span><br><span class="line">    link/ether 02:42:c0:a8:04:04 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.4.4/24 brd 192.168.4.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">216: eth0@if217: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue </span><br><span class="line">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>查看 IP 信息，完全共享被 joined 目标容器的网络。</p><h2 id="二、容器与外部通信"><a href="#二、容器与外部通信" class="headerlink" title="二、容器与外部通信"></a>二、容器与外部通信</h2><p>其实这是通过 Host 的 iptables 机制来实现的，如下标红的几个示例，当收到 172.19.0.0&#x2F;16 网段的外出包，就把它交给 MASQUERADE 处理，MASQUERADE 则将外出包的源地址转换为 Host 的地址发送出去，实现了网络的 NAT 转换。这也是容器可以与外部通信的原因。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182740504.png" alt="image-20221214182740504"></p><p>容器能与外界通信，那外部是如何与容器内部通信呢？其实道理是一样的，也是通过 NAT 技术，在结合端口映射的方式实现外部与 Host 下的容器通信。</p><h3 id="2-1-动态端口映射"><a href="#2-1-动态端口映射" class="headerlink" title="2.1 动态端口映射"></a>2.1 动态端口映射</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -itd --name=httpd -p 80 httpd</span><br><span class="line">[root@qcloud ~]# docker port httpd</span><br><span class="line">80/tcp -&gt; 0.0.0.0:1024</span><br></pre></td></tr></table></figure><p>该方式会随机生成一个动态端口，且是用于浏览器访问的端口号。</p><h3 id="2-2-静态端口映射"><a href="#2-2-静态端口映射" class="headerlink" title="2.2 静态端口映射"></a>2.2 静态端口映射</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -itd --name=httpd-1 -p 8686:80 httpd</span><br><span class="line">[root@qcloud ~]# docker port httpd-1</span><br><span class="line">80/tcp -&gt; 0.0.0.0:8686</span><br></pre></td></tr></table></figure><p>该方式会指定一个静态端口，且是用于浏览器访问的端口号。静态端口映射用的居多。</p><p><strong>小结：</strong></p><p>没映射一个端口，Host 都会启动一个 docker-proxy 进程来处理访问容器的流量。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182755401.png" alt="image-20221214182755401"></p><hr><p>附件：容器内&#x2F;外通信图解</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/Docker-network.jpg" alt="Docker-network"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible 快速入门</title>
      <link href="/2023/03/23/Ansible-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
      <url>/2023/03/23/Ansible-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Ansible-快速入门"><a href="#Ansible-快速入门" class="headerlink" title="Ansible 快速入门"></a><center>Ansible 快速入门</center></h1><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/timg.jpg" alt="timg"></p><p><a href="https://docs.ansible.com/ansible/latest/">官方文档</a></p><hr><h2 id="一、Ansible-是什么"><a href="#一、Ansible-是什么" class="headerlink" title="一、Ansible 是什么?"></a>一、Ansible 是什么?</h2><p><code>Ansible</code>它是一个 IT 自动化工具。它可以配置系统、部署软件并协调更高级的 IT 任务，例如持续部署或零停机时间滚动更新等。Ansible 的主要目标是简单和易用，它还非常关注安全性和可靠性，具有最少的移动部件，其使用 <code>OpenSSH</code> 进行传输。</p><h2 id="二、Ansible-安装"><a href="#二、Ansible-安装" class="headerlink" title="二、Ansible 安装"></a>二、Ansible 安装</h2><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><h4 id="2-1-1-Python-方式"><a href="#2-1-1-Python-方式" class="headerlink" title="2.1.1 Python 方式"></a>2.1.1 Python 方式</h4><p>1、安装最新版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user ansible</span><br></pre></td></tr></table></figure><p>2、安装指定版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user ansible-core==2.12.3</span><br></pre></td></tr></table></figure><p>3、升级 Ansible</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --upgrade --user ansible</span><br></pre></td></tr></table></figure><p>4、验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible --version</span><br></pre></td></tr></table></figure><p>5、Ansible 的 shell补全</p><ul><li><p>安装 argcomplete</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user argcomplete</span><br></pre></td></tr></table></figure></li><li><p>配置 argcomplete</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">全局配置：要求 bash 4.2</span></span><br><span class="line">activate-global-python-argcomplete</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果您没有 bash 4.2，则必须单独注册每个脚本</span></span><br><span class="line">eval $(register-python-argcomplete ansible)</span><br><span class="line">eval $(register-python-argcomplete ansible-config)</span><br><span class="line">eval $(register-python-argcomplete ansible-console)</span><br><span class="line">eval $(register-python-argcomplete ansible-doc)</span><br><span class="line">eval $(register-python-argcomplete ansible-galaxy)</span><br><span class="line">eval $(register-python-argcomplete ansible-inventory)</span><br><span class="line">eval $(register-python-argcomplete ansible-playbook)</span><br><span class="line">eval $(register-python-argcomplete ansible-pull)</span><br><span class="line">eval $(register-python-argcomplete ansible-vault)</span><br></pre></td></tr></table></figure></li></ul><h4 id="2-1-2-Yum-方式"><a href="#2-1-2-Yum-方式" class="headerlink" title="2.1.2 Yum 方式"></a>2.1.2 Yum 方式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install epel-release</span><br><span class="line">sudo yum install ansible</span><br></pre></td></tr></table></figure><p>其他特定系统安装请看<a href="https://docs.ansible.com/ansible/latest/installation_guide/installation_distros.html">官方文档</a>。</p><h3 id="2-2-配置"><a href="#2-2-配置" class="headerlink" title="2.2 配置"></a>2.2 配置</h3><p>配置文件位于 <code>/etc/ansible</code> 下，Ansible 中的某些设置可通过配置文件 (ansible.cfg) 进行调整。对于大多数用户来说，Inventory 配置已经足够了。</p><h2 id="三、快速入门"><a href="#三、快速入门" class="headerlink" title="三、快速入门"></a>三、快速入门</h2><h3 id="3-1-三组件"><a href="#3-1-三组件" class="headerlink" title="3.1 三组件"></a>3.1 三组件</h3><p>一个基本的 Ansible 环境包含三个主要组件：<code>Control node</code>、<code>Managed node</code>、<code>Inventory</code></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922100244734.png" alt="image-20220922100244734"></p><p><strong>1、Control node</strong></p><p>安装了 Ansible 的系统，安装完成后，可以在控制节点上运行 Ansible 相关命令，例如<code>ansible</code>或<code>ansible-inventory</code>。</p><p><strong>2、Managed node</strong></p><p>Ansible 控制的远程系统或主机，即接下来要说到的 hosts 文件中的主机清单。</p><p><strong>3、Inventory</strong></p><p>逻辑组织的受管节点列表，在控制节点上创建一个清单以向 Ansible 描述主机部署。</p><h3 id="3-2-基础使用"><a href="#3-2-基础使用" class="headerlink" title="3.2 基础使用"></a>3.2 基础使用</h3><blockquote><p>我的 ansible 机器为：192.168.56.132</p></blockquote><p><strong>1、安装 Ansible</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user ansible</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或 yum 安装</span></span><br><span class="line">yum install -y ansible</span><br></pre></td></tr></table></figure><p><strong>2、添加主机列表</strong></p><blockquote><p>通过将一个或多个远程系统的 IP 地址或完全限定域名 (FQDN) 添加到<code>/etc/ansible/hosts</code></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[web]</span><br><span class="line">192.168.56.132</span><br><span class="line">192.168.56.180</span><br></pre></td></tr></table></figure><p><strong>3、验证清单中的主机</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible all --list-hosts</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hosts (2):</span><br><span class="line">  192.168.56.132</span><br><span class="line">  192.168.56.180</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922101103515.png" alt="image-20220922101103515"></p><p><strong>3、设置 SSH 连接</strong></p><blockquote><p>将 <code>Control node</code> 主机的 SSH 公密添加到每个远程系统（主机）上的 <code>authorized_keys</code> 文件中，以便 Ansible 可以连接到受管节点。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id 192.168.56.180</span><br></pre></td></tr></table></figure><p>如果控制节点上的用户名在主机上不同，则需要将<code>-u</code>选项与<code>ansible</code>命令一起传递。</p><p><strong>4、Ping 受管节点</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible all -m ping</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">192.168.56.180 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">192.168.56.132 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922101829925.png" alt="image-20220922101829925"></p><h3 id="3-3-创建-Inventory"><a href="#3-3-创建-Inventory" class="headerlink" title="3.3 创建 Inventory"></a>3.3 创建 Inventory</h3><p>Inventory 文件位于 Control node 节点上（即安装 ansible 的主机）。使用清单文件，Ansible 可以通过单个命令管理大量主机，我们也可以直接将受管节点添加到<code>/etc/ansible/hosts</code>文件中，来实现批量主机管理。在 Inventory 文件编写中，其语法格式可以是<code>INI</code>或<code>YAML</code>格式，建立一个 Inventory 的基本步骤如下：</p><ul><li>在您的控制节点上打开一个终端窗口。</li><li>在任何目录中创建一个新的库存文件<code>inventory.yaml</code>并打开它进行编辑。</li><li>为您的主机添加一个新组，然后使用该字段指定每个受管节点的 IP 地址或完全限定域名 (FQDN) <code>ansible_host</code>。</li></ul><p><strong>1、创建名为 inventory.yaml 的 Inventory</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat inventory.yaml</span><br><span class="line"></span><br><span class="line">mywebhost:</span><br><span class="line">  hosts:</span><br><span class="line">    vm01:</span><br><span class="line">      ansible_host: 192.168.56.132</span><br><span class="line">    vm02:</span><br><span class="line">      ansible_host: 192.168.56.180</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">说明：mywebhost 为组名</span></span><br></pre></td></tr></table></figure><p><strong>2、验证 Inventory</strong></p><blockquote><p>如果你在主目录以外的目录中创建了清单，请使用该<code>-i</code>选项指定完整路径。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-inventory -i inventory.yaml --list</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922104607536.png" alt="image-20220922104607536"></p><p><strong>2、ping 清单中的受管节点</strong></p><blockquote><p>在此示例中，组名称是<code>mywebhost</code>，此时可以使用<code>ansible</code>命令。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible mywebhost -m ping -i inventory.yaml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vm01 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">vm02 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922104904636.png" alt="image-20220922104904636"></p><p>&#x3D;&#x3D;注意 Inventory 与 hosts 文件的区别：&#x3D;&#x3D;</p><p>Ansible 的主机清单是 Inventory，我们可以通过创建 <code>*.yaml</code> 文件来作为我们的主机清单（Inventory）文件，如果你没有创建这个 yaml 文件，那 Ansible 的默认主机清单文件就是 hosts，这个文件在安装 Ansible 时默认存在 的。当找不到 *.yaml 主机清单文件时，就会去找 hosts 文件。</p><p>由于 hosts 文件是默认的主机清单文件，如果你想使用你自定义的其他主机清单文件，需通过 <code>-i</code> 参数指定，如 <code>ansible mywebhost -m ping -i inventory.yaml</code>，否则它会默认去找 hosts 文件。</p><h3 id="3-4-创建-playbook"><a href="#3-4-创建-playbook" class="headerlink" title="3.4 创建 playbook"></a>3.4 创建 playbook</h3><p><code>YAML</code>剧本是 Ansible 用于部署和配置托管节点的自动化蓝图。看看几个重要元素：</p><ul><li><p><strong>Playbook</strong></p><p>定义 Ansible 从上到下执行操作以实现总体目标的顺序的剧本列表。</p></li><li><p><strong>Play</strong></p><p>映射到清单中的受管节点的有序任务列表。</p></li><li><p><strong>Task</strong></p><p>定义 Ansible 执行的操作的一个或多个模块的列表。</p></li><li><p><strong>Module</strong></p><p>Ansible 在托管节点上运行的代码或二进制单元。</p></li></ul><p>&#x3D;&#x3D;创建一个 playbook 的步骤如下：&#x3D;&#x3D;</p><ul><li><p>在控制节点上打开一个终端窗口。</p></li><li><p>在任何目录中创建一个新的 playbook 文件<code>playbook.yaml</code>并打开它进行编辑。</p></li></ul><p><strong>1、创建 playbook</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">playbook.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">My</span> <span class="string">first</span> <span class="string">play</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">mywebhost</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Ping</span> <span class="string">my</span> <span class="string">hosts</span></span><br><span class="line">     <span class="attr">ansible.builtin.ping:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">message</span></span><br><span class="line">     <span class="attr">ansible.builtin.debug:</span></span><br><span class="line">       <span class="attr">msg:</span> <span class="string">Hello</span> <span class="string">world</span></span><br><span class="line">       </span><br><span class="line"><span class="comment"># 可看到我的主机清单指定的是mywebhost组，而这个组是在我自定义的Inventory文件中定义的</span></span><br><span class="line"><span class="comment"># 因此我在运行playbook时需要-i指定自定义的Inventory文件，如果不指定，ansible就回去找默认的hosts文件，而这个文件中根本没有mywebhost这个组名，所以会报错。</span></span><br></pre></td></tr></table></figure><p><strong>2、运行 playbook</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">-i</span> <span class="string">inventory.yaml</span> <span class="string">playbook.yaml</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922112600610.png" alt="image-20220922112600610"></p><p>&#x3D;&#x3D;剧本的执行过程：&#x3D;&#x3D;</p><ul><li>任务隐式运行。默认情况下，Ansible 会收集可以在 playbook 中使用的库存信息（Inventory），<code>Gather Facts</code>。</li><li>每个任务的状态。每个任务都有一个状态，<code>ok</code>这意味着它运行成功。</li><li>对每个主机的剧本中所有任务的结果进行总结的剧本回顾。在此示例中，共有三个任务，因此<code>ok=3</code>表明每个任务都运行成功。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ansible </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K8s 探针</title>
      <link href="/2023/03/23/01/K8s%20%E6%8E%A2%E9%92%88/"/>
      <url>/2023/03/23/01/K8s%20%E6%8E%A2%E9%92%88/</url>
      
        <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/k8s-cert.png" alt="k8s-cert"></p><p><a href="https://huaweicloud.csdn.net/63311d87d3efff3090b52a95.html?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-5-123894868-blog-126919159.pc_relevant_3mothn_strategy_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-5-123894868-blog-126919159.pc_relevant_3mothn_strategy_recovery&utm_relevant_index=10">参考1</a></p><p><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">官方参考文档</a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>玩过 <code>Docker Swarm</code> 的应该都知道，有一种功能叫<code>自愈功能</code>，当集群检测到节点或服务故障时回进行自动故障转移，从而保障业务的可用性。而 K8s 集群相对于其他集群体系，其自愈能力更加强大，这也是 K8s 容器编排引擎的一重要特性。自愈从某种角度上来讲，其实现了以下几几种功能特性：</p><ul><li>零停机部署；</li><li>避免无效镜像；</li><li>实现滚动升级与回退。</li></ul><p>K8s 有三种探针，分别是：<code>存活（Liveness）</code>、<code>就绪（Readiness）</code>和<code>启动（Startup）</code></p><ul><li><p><strong>存活（Liveness）</strong>：kubelet 使用存活探针来确定什么时候要重启容器。 例如，存活探针可以探测到应用死锁（应用程序在运行，但是无法继续执行后面的步骤）情况。 重启这种状态下的容器有助于提高应用的可用性，即使其中存在缺陷。</p></li><li><p><strong>就绪（Readiness）</strong>：kubelet 使用就绪探针可以知道容器何时准备好接受请求流量。当一个 Pod 内的所有容器都就绪时，才能认为该 Pod 就绪。 这种信号的一个用途就是控制哪个 Pod 作为 Service 的后端。 若 Pod 尚未就绪，会被从 Service 的负载均衡器中剔除。</p></li><li><p><strong>启动（Startup）</strong>：kubelet 使用启动探针来了解应用容器何时启动。 如果配置了这类探针，你就可以控制容器在启动成功后再进行存活性和就绪态检查， 确保这些存活、就绪探针不会影响应用的启动。 启动探针可以用于对慢启动容器进行存活性检测，避免它们在启动运行之前就被杀掉。</p></li></ul><p>K8s 探针有三种探测方式，分别是：<code>ExecAction</code>、<code>HTTPGetAction</code> 和 <code>TCPSocketAction</code>，这三种探测方式只能同时使用一种，不能两种或三种同时使用。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ExecAction：      <span class="comment"># 在容器中执行指定的命令，如果执行成功，退出码为0则探测成功。</span></span><br><span class="line">HTTPGetAction：   <span class="comment"># 通过容器的IP地址、端口号及路径调用HTTP Get方法，如果响应的状态码大于等于200且小于400，则认为容器健康。</span></span><br><span class="line">TCPSocketAction： <span class="comment"># 通过容器的IP地址和端口号执行TCP检查，如果能够建立TCP连接，则表明容器健康。</span></span><br></pre></td></tr></table></figure><blockquote><p>探针探测的结果有以下值：</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Success：  <span class="comment"># 表示通过检测。</span></span><br><span class="line">Failure：  <span class="comment"># 表示未通过检测。</span></span><br><span class="line">Unknown：  <span class="comment"># 表示检测没有正常进行。</span></span><br></pre></td></tr></table></figure><h2 id="一、默认健康检测"><a href="#一、默认健康检测" class="headerlink" title="一、默认健康检测"></a>一、默认健康检测</h2><h3 id="1-1-restartPolicy"><a href="#1-1-restartPolicy" class="headerlink" title="1.1 restartPolicy"></a>1.1 restartPolicy</h3><p>了解 Docker 的都知道，每个容器启动时都会执行一个进程，该进程由 Dockerfile 的 CMD 或 ENTRYPOINT 指定。如果进程退出或返回状态码为非零时，则认为容器发生故障，这个时候 K8s 就会根据 <code>restartPolicy</code> 重启容器。<code>restartPolicy</code> 有三种重启策略：</p><ul><li><p><strong>Always</strong></p><p>Pod 中容器不论如何停止都将自动重启；</p></li><li><p><strong>OnFailure</strong><br>Pod 中容器非正常停止会自动重启，正常停止不会重启；</p></li><li><p><strong>Never</strong><br>Pod 中容器不论以任何方式停止，都不会自动重启。</p></li></ul><p>K8s 的  <code>restartPolicy</code>  默认为 <code>Always</code>。如果探针超过失败重试的次数，则 Pod 就会根据 restartPolicy 策略进行选择是否重启。</p><h3 id="1-2-测试案例"><a href="#1-2-测试案例" class="headerlink" title="1.2 测试案例"></a>1.2 测试案例</h3><p>1、创建一个 Pod</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    <span class="built_in">test</span>: healthcheck</span><br><span class="line">  name: healthcheck</span><br><span class="line">spec:</span><br><span class="line">  restartPolicy: OnFailure</span><br><span class="line">  containers:</span><br><span class="line">  - name: healthcheck</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - /bin/sh</span><br><span class="line">    - -c</span><br><span class="line">    - <span class="built_in">sleep</span> 10;<span class="built_in">exit</span> 1</span><br></pre></td></tr></table></figure><p>2、观察 Pod 状态</p><p>这个容器启动 10s 后会发生故障，接下来执行 <code>kubectl apply</code> 创建 Pod，Pod Name 为 healthcheck。过几分钟后看看 Pod 的状态：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221222110433382.png" alt="image-20221222110433382"></p><p>可看到已经重启了三次，该案例中容器进程返回值为非零，k8s 则认为容器发生故障，需要重启。但可能有些情况下发生了故障进程不退出的现象，如访问 Web 服务器时返回 500 错误代码，这可能是系统负荷较大或资源锁死，此时 httpd 进程并没有异常退出，这种情况下可直接重启容器。而 K8s 的 Liveness 机制刚好能解决此类问题（即出现此类问题会直接 Kill 掉容器并重新启动）。</p><h2 id="二、Liveness"><a href="#二、Liveness" class="headerlink" title="二、Liveness"></a>二、Liveness</h2><p>Liveness 探针让用户可以自定义判断容器是否健康的条件，如果探测失败，K8s 就会重启容器，如下案例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    <span class="built_in">test</span>: liveness</span><br><span class="line">  name: liveness-exec</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: liveness</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - /bin/sh</span><br><span class="line">    - -c</span><br><span class="line">    - <span class="built_in">touch</span> /tmp/healthy; <span class="built_in">sleep</span> 30; <span class="built_in">rm</span> -f /tmp/healthy; <span class="built_in">sleep</span> 600</span><br><span class="line">    livenessProbe:</span><br><span class="line">      <span class="built_in">exec</span>:</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - <span class="built_in">cat</span></span><br><span class="line">        - /tmp/healthy</span><br><span class="line">      initialDelaySeconds: 5</span><br><span class="line">      periodSeconds: 5</span><br></pre></td></tr></table></figure><p>在这个配置文件中，可以看到 Pod 中只有一个 <code>Container</code>。 <code>periodSeconds</code> 字段指定了 kubelet 应该每 5 秒执行一次存活探测。 <code>initialDelaySeconds</code> 字段告诉 kubelet 在执行第一次探测前应该等待 5 秒（即 5 秒后才开始启动探针）。 kubelet 在容器内执行命令 <code>cat /tmp/healthy</code> 来进行探测。 如果命令执行成功并且返回值为 0，kubelet 就会认为这个容器是健康存活的。 如果这个命令返回非 0 值，kubelet 会杀死这个容器并重新启动它。当容器启动时，会执行如下的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/sh -c &quot;touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600&quot;</span><br></pre></td></tr></table></figure><p>这个容器生命的前 30 秒，<code>/tmp/healthy</code> 文件是存在的。 所以在这最开始的 30 秒内，执行命令 <code>cat /tmp/healthy</code> 会返回成功代码。 30 秒之后，执行命令 <code>cat /tmp/healthy</code> 就会返回失败代码。</p><p>执行 <code>kubectl apply</code> 创建 Pod 。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f liveness.yml</span><br></pre></td></tr></table></figure><p>查看 Pod 启动日志：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pod liveness-exec</span><br></pre></td></tr></table></figure><p>前 30s <code>/tmp/healthy</code> 文件是存在的：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221222113744208.png" alt="image-20221222113744208"></p><p>35s 后检测到<code>/tmp/healthy</code> 文件已经不存在：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221222114051362.png" alt="image-20221222114051362"></p><p>再过十几秒后容器被重启：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221222114308594.png" alt="image-20221222114308594"></p><h2 id="三、Readiness"><a href="#三、Readiness" class="headerlink" title="三、Readiness"></a>三、Readiness</h2><p>除了可以自定义判断容器是否健康的条件外，用户也可以通过 <code>Readiness</code> 探针告诉 K8s 什么时候可以重启容器实现自愈，<code>Readiness</code> 探针则告诉 K8s 什么时候可以将容器加入到 Service 负载均衡池中，对外提供服务。就绪探针的配置和存活探针的配置相似。 唯一区别就是要使用 <code>readinessProbe</code> 字段，而不是 <code>livenessProbe</code> 字段。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    <span class="built_in">test</span>: readiness</span><br><span class="line">  name: readiness-exec</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: liveness</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - /bin/sh</span><br><span class="line">    - -c</span><br><span class="line">    - <span class="built_in">touch</span> /tmp/healthy; <span class="built_in">sleep</span> 30; <span class="built_in">rm</span> -f /tmp/healthy; <span class="built_in">sleep</span> 600</span><br><span class="line">    readinessProbe:</span><br><span class="line">      <span class="built_in">exec</span>:</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - <span class="built_in">cat</span></span><br><span class="line">        - /tmp/healthy</span><br><span class="line">      initialDelaySeconds: 5</span><br><span class="line">      periodSeconds: 5</span><br></pre></td></tr></table></figure><p>看看启动日志，与 <code>Liveness</code> 探针类似</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pod readiness-exec</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221222121220005.png" alt="image-20221222121220005"></p><p>Probe 有很多配置字段，可以使用这些字段精确地控制启动、存活和就绪检测的行为：</p><ul><li><code>initialDelaySeconds</code>：容器启动后要等待多少秒后才启动启动、存活和就绪探针， 默认是 0 秒，最小值是 0。</li><li><code>periodSeconds</code>：执行探测的时间间隔（单位是秒）。默认是 10 秒。最小值是 1。</li><li><code>timeoutSeconds</code>：探测的超时后等待多少秒。默认值是 1 秒。最小值是 1。</li><li><code>successThreshold</code>：探针在失败后，被视为成功的最小连续成功数。默认值是 1。 存活和启动探测的这个值必须是 1。最小值是 1。</li><li><code>failureThreshold</code>：当探测失败时，Kubernetes 的重试次数。 对存活探测而言，放弃就意味着重新启动容器。 对就绪探测而言，放弃意味着 Pod 会被打上未就绪的标签。默认值是 3。最小值是 1。</li></ul><p><mark>注意</mark>：存活探针 <strong>不等待</strong> 就绪性探针成功。如果要在执行存活探针之前等待就绪性探针，应该使用 <code>initialDelaySeconds</code> 或 <code>startupProbe</code>。</p><h2 id="四、Startup"><a href="#四、Startup" class="headerlink" title="四、Startup"></a>四、Startup</h2><p>Startup 是 <code>k8s 1.16+</code> 版本后新加的探测方式，用于判断容器内应用程序是否已经启动，如果同时配置了 <code>startuprobe</code>、<code>Livenessprobe</code>、<code>Readinessprobe</code>，K8s 就会先禁用其他的探针，而首先使用 <code>startuprobe </code>探测直到它成功为止，成功后将不再进行探测。</p><p><strong>startupProbe 探针与另两种区别？</strong></p><ul><li><p>如果三个探针同时存在，先执行startupProbe探针，其他两个探针将会被暂时禁用，直到pod满足startupProbe探针配置的条件，其他2个探针启动，如果不满足按照规则重启容器。</p></li><li><p>另外两种探针在容器启动后，会按照配置，直到容器消亡才停止探测，而startupProbe探针只是在容器启动后按照配置满足一次后，不在进行后续的探测。</p></li></ul><p><mark>那 Startup 存在的意义又是什么呢？</mark></p><p>试想一个问题，如果启动一个服务需要 1 分钟，如果没有 <code>Startup</code> 的情况下，且假设我们配置了 <code>livenessProbe</code> 探针，具体如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /test</span><br><span class="line">    prot: 80</span><br><span class="line">failureThreshold: 6</span><br><span class="line">initialDelay：40</span><br><span class="line">periodSeconds: 5</span><br></pre></td></tr></table></figure><p>我们设置了失败重试次数为 6，每 5 秒探测一次，加上我们探测前等待的 40 秒，总时间就是：40 + 6 x 5 &#x3D; 70s，这样 Pod 确实能够启动起来。那问题又来了，如果这个配置用于生产配置上，将会导致我们比较晚的收到服务不可用的情况，也就是说我的服务可能在 5s 时已经不可用，但是由于我们探测机制（有 6 次失败重试的机会），我们在至少 6 x 5 &#x3D; 30s 才会发现服务不可用的情况，这在生产上一般是不被允许的。<strong>那该如何解决类似这样的问题呢？</strong>答案就是 <code>startupProbe</code>。</p><blockquote><p>注意上面这个案例，如果 <code>failureThreshold</code> 设置为 1 或 2，那这个服务是永远起不起来的，因为你把 <code>initialDelay</code> 的时间算上也不足 1 分钟，因为我们说启动至少需要 1 分钟，那超过失败重试次数后，就会根据 Pod 的 <code>restartPolicy</code> 来重启容器。</p></blockquote><p>接着我们引入 <code>startupProbe</code>，继续优化：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /test</span><br><span class="line">    prot: 80</span><br><span class="line">failureThreshold: 1</span><br><span class="line">initialDelaySeconds：5</span><br><span class="line">periodSeconds: 5</span><br><span class="line"></span><br><span class="line">startupProbe:</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /test</span><br><span class="line">    prot: 80</span><br><span class="line">failureThreshold: 60</span><br><span class="line">initialDelaySeconds：5</span><br><span class="line">periodSeconds: 5</span><br></pre></td></tr></table></figure><p>前面说了，<code>startupProbe</code> 会在探测成功后停止探测，而其他两种探针则是随着 Pod 的生命周期一直在探测的。因此上面的配置功能就是：K8s 部署服务后会在 5s 后启动 <code>startupProbe</code>，在 5 x 60 &#x3D; 300s 的时间内只要成功探测到服务则停止探测（否则需接受 Pod 的重启策略进行重启），并启用 <code>livenessProbe</code> 探针，此时<code>livenessProbe</code> 探针就会伴随着 Pod 的生命周期每 5s 检测一次，且我们只设置了 1 次失败重试的机会，这就意味着我们只需要在 1 x 5 &#x3D; 5s 时间就可以发现服务不可用。因此，你配置了 <code>startupProbe</code>，那其他2种探针如果配置了<code>initialDelaySeconds</code>，建议时间就不要给太长。<mark>这就是 Startup 探针存在的意义。</mark></p><h2 id="五、应用场景"><a href="#五、应用场景" class="headerlink" title="五、应用场景"></a>五、应用场景</h2><p>从上面的实验来看，探针的作用是很明显的，那这些探针在实际工作中是如何应用的呢？</p><h3 id="5-1-在-Scale-Up-中的应用"><a href="#5-1-在-Scale-Up-中的应用" class="headerlink" title="5.1 在 Scale Up 中的应用"></a>5.1 在 Scale Up 中的应用</h3><p>当我们执行 <code>Scale Up</code> 操作时（如新增副本数），新副本会作为 backend 被添加到 Service 的负载均衡中，与已有的副本一起处理客户的请求。考虑到应用启动通常都需要一个准备阶段，如加载缓存数据、连接数据库等，也就是说从容器启动到真正能够提供服务是需要一段时间的，此时，我们就可以通过 Readiness 探测判断容器是否就绪，避免将请求发送到还没准备好的 backend。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: web</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: web</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: web</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: web</span><br><span class="line">        image: httpd</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            scheme: HTTP</span><br><span class="line">            path: /</span><br><span class="line">            port: 80</span><br><span class="line">          initialDelaySeconds: 5</span><br><span class="line">          periodSeconds: 5</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: web-svc</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    run: web</span><br><span class="line">  ports:</span><br><span class="line">  - protocol: TCP</span><br><span class="line">    port: 80</span><br><span class="line">    targetPort: 80</span><br></pre></td></tr></table></figure><blockquote><p>查看 Pod 是否正常</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227102346704.png" alt="image-20221227102346704"></p><blockquote><p>查看 Service 资源</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227102527625.png" alt="image-20221227102527625"></p><blockquote><p>集群请求验证</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227102754960.png" alt="image-20221227102754960"></p><p>因此不难看出，就绪探针的好处就是，只有等待 Pod 完全就绪后才会接收来自客户端的请求。</p><p>完整流程就是：</p><ul><li>容器启动 5s 后开始进行就绪探测；</li><li>如果 GET 请求的 <a href="http://container_ip/">http://container_ip:80/</a> 返回代码不是 200~400，则表示容器没就绪，此时该容器不接收 Service web-svc 的请求；</li><li>之后会每隔 5s 探测一次；</li><li>直到 GET 请求的 <a href="http://container_ip/">http://container_ip:80/</a> 返回代码为 200~400，则表示容器已经就绪，此时该容器将加入到 web-svc 的负载均衡中，开始处理客户的请求；</li><li>探针还会继续以 5s 的时间间隔探测，如果连续发生 3 次失败（YAML 文件中未指定，默认为 3 次，可通过 <code>failureThreshold</code> 来指定），容器又会从负载均衡中移除，直到下次探测成功再重新加入。</li></ul><p><mark>注意，这里我没有做 NodePort 类型哦，但并不影响我们的实验。</mark></p><h3 id="5-2-在滚动更新中的应用"><a href="#5-2-在滚动更新中的应用" class="headerlink" title="5.2 在滚动更新中的应用"></a>5.2 在滚动更新中的应用</h3><p>还有一个比较重要的应用场景就是<code>滚动更新（Rolling Update）</code>，试想一下，现有一个正常运行的多副本应用，接下来对应用进行更新（如升级镜像版本），K8s 会启动新副本，就会存在一下两种情况：</p><ul><li>正常情况下新副本需要 10s 来完成准备工作，在此期间是无法响应业务请求的；</li><li>由于人为配置错误，副本始终无法完成准备工作（如无法连接后端数据库）。</li></ul><p>那如果出现以上的两种情况，且又没有配置探针的话，会出现什么问题呢？</p><p>新副本本身没有异常退出，那默认的健康检查机制就会认为容器已经就绪，进而就会逐步用新的副本替换现有的副本。最终结果就是：所有旧副本都被替换后，整个应用将无法对外提供服务，那这在生产上是绝对不允许的。</p><p>那如果配置了对应的探针机制后，新副本只有通过了 Readiness 探测才会被添加到 Service 中，如果没有通过探测，则现有副本就不会被全部替换（根据比例可能会替换部分），业务仍然正常进行。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim app-v1.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: app</span><br><span class="line">spec:</span><br><span class="line">  replicas: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: app</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: app</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: app</span><br><span class="line">        image: busybox</span><br><span class="line">        args:</span><br><span class="line">        - /bin/sh</span><br><span class="line">        - -c</span><br><span class="line">        - <span class="built_in">sleep</span> 10; <span class="built_in">touch</span> /tmp/healthy; <span class="built_in">sleep</span> 30000</span><br><span class="line">        readinessProbe:</span><br><span class="line">          <span class="built_in">exec</span>:</span><br><span class="line">            <span class="built_in">command</span>:</span><br><span class="line">            - <span class="built_in">cat</span></span><br><span class="line">            - /tmp/healthy</span><br><span class="line">          initialDelaySeconds: 10</span><br><span class="line">          periodSeconds: 5</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f app-v1.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可看到10s后副本通过readinessProbe探测</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227121011463.png" alt="image-20221227121011463"></p><p>接下来进行滚动更新应用。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim app-v2.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: app</span><br><span class="line">spec:</span><br><span class="line">  replicas: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: app</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: app</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: app</span><br><span class="line">        image: busybox</span><br><span class="line">        args:</span><br><span class="line">        - /bin/sh</span><br><span class="line">        - -c</span><br><span class="line">        - <span class="built_in">sleep</span> 3000</span><br><span class="line">        readinessProbe:</span><br><span class="line">          <span class="built_in">exec</span>:</span><br><span class="line">            <span class="built_in">command</span>:</span><br><span class="line">            - <span class="built_in">cat</span></span><br><span class="line">            - /tmp/healthy</span><br><span class="line">          initialDelaySeconds: 10</span><br><span class="line">          periodSeconds: 5</span><br></pre></td></tr></table></figure><p>很显然，本次的更新的新副本中并没有 <code>/tmp/healthy</code> 文件，因此是无法通过 <code>readiness</code> 探测的，开始更新服务。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f app-v1.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227141219466.png" alt="image-20221227141219466"></p><p><mark>从 kubectl get pod 输出结果分析：</mark></p><ul><li>从启动时间（AGE）可判断，开头 5 个是新副本，出于 NOTREADY 状态；</li><li>旧副本从最初的 10 个减少到 8 个。</li></ul><p><mark>从 kubectl get deployment app 输出结果分析：</mark></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227141624890.png" alt="image-20221227141624890"></p><ul><li>READY：就绪个数&#x2F;期望个数；</li><li>UP-TO-DATE：为了达到期望状态，已经更新的副本数；</li><li>AVAILABLE：可供用户使用的副本数。</li></ul><p>在我们的设定中，新副本始终都无法通过 Readiness 探测，所以这个状态会一直持续下去。对于 K8s 健康检查机制来说，它帮我们屏蔽了有缺陷的副本，同时保留了大部分旧副本，业务没有因为更新失败受到影响。</p><p><mark>为什么新创建的副本数是 5 个，同时只销毁了 2 个旧副本？</mark></p><p>原因是：滚动更新通过参数 <code>maxSurge</code> 和 <code>maxUnavailable</code> 来控制副本替换的数量。</p><p><strong>maxSurge</strong></p><p>此参数控制滚动更新过程中副本总数超过 <code>READY</code> 期望数的上限。maxSurge 可以是具体的整数，也可以是百分比，向上取整。若不指定，则 maxSurge 的默认值为 25%。</p><p>在上面的例子中，期望是 10，那副本总数的最大值为：10 + 10 x 25% &#x3D; 13，所以我们看到的 Pod 数为 13 个就是这么来的。</p><p><strong>maxUnavailable</strong></p><p>此参数控制滚动更新过程中，不可用的副本数占期望数的最大比例。maxUnavailable 可以是整数，也可以是百分比，向下取整。若不指定，则 maxUnavailable 的默认值为 25%。</p><p>在上面的例子中，期望是 10，那可用的副本数至少要为：10 - 10 x 25% &#x3D; 8，所以我们看到的 Pod 中只有 8 个是可用的。</p><p><mark>因此，理想情况下，我们这个案例的滚动更新过程是这样的：</mark></p><ul><li>创建 3 个新副本，使副本总数达到 13 个；</li><li>销毁 2 个旧副本，使可用副本数降到 8 个；</li><li>当 2 个旧副本销毁成功后，再创建 2 个新副本，使副本数保持为 13 个；</li><li>当新副本通过 Readiness 探测后，会使可用副本数增加，超过 8 个；</li><li>进而可继续销毁更多的旧副本，使可用副本数回到 8 个；</li><li>旧副本的销毁会使副本总数低于 13，这样就允许创建更多的新副本；</li><li>这个过程会持续进行，直到所有的旧副本都被新副本替换，滚动更新才完成。</li></ul><p>而上面案例中，我们在第四步就卡主了，因为新的副本无法通过 Readiness 探测。这个过程可通过 Deployment 日志部分来查看。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe deployment app</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227150137960.png" alt="image-20221227150137960"></p><p>因此，对于上面的滚动更新失败案例，我们想要恢复原来正常提供的服务，我们只需要进行回滚操作即可。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先看看可回滚的历史版本（revision）</span></span><br><span class="line">kubectl rollout <span class="built_in">history</span> deployment app</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227150540721.png" alt="image-20221227150540721"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看revision的详情</span></span><br><span class="line">kubectl rollout <span class="built_in">history</span> deployment app --revision=1</span><br><span class="line">kubectl rollout <span class="built_in">history</span> deployment app --revision=2</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227150744680.png" alt="image-20221227150744680"></p><p>很明显，<code>revision = 1</code> 就是我们最初的版本，我们只需要回滚到这个版本上即可。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment app --to-revision=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可看到，之前被销毁的两个Pod已经启动且为可用状态</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221227151243160.png" alt="image-20221227151243160"></p><p><mark>如何在 YAML 文件中指定 maxSurge 和 maxUnavailable？</mark></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: app</span><br><span class="line">spec:</span><br><span class="line">  strategy:</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxSurge: 35%</span><br><span class="line">      maxUnavailable: 35%</span><br><span class="line">  replicas: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      run: app</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        run: app</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: app</span><br><span class="line">        image: busybox</span><br><span class="line">        args:</span><br><span class="line">        - /bin/sh</span><br><span class="line">        - -c</span><br><span class="line">        - <span class="built_in">sleep</span> 10; <span class="built_in">touch</span> /tmp/healthy; <span class="built_in">sleep</span> 30000</span><br><span class="line">        readinessProbe:</span><br><span class="line">          <span class="built_in">exec</span>:</span><br><span class="line">            <span class="built_in">command</span>:</span><br><span class="line">            - <span class="built_in">cat</span></span><br><span class="line">            - /tmp/healthy</span><br><span class="line">          initialDelaySeconds: 10</span><br><span class="line">          periodSeconds: 5</span><br></pre></td></tr></table></figure><hr>]]></content>
      
      
      
        <tags>
            
            <tag> K8s </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
