<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rabcnops</title>
  
  <subtitle>Welcome to my tech blog</subtitle>
  <link href="https://blog.rabcnops.cn/atom.xml" rel="self"/>
  
  <link href="https://blog.rabcnops.cn/"/>
  <updated>2023-03-30T06:36:48.636Z</updated>
  <id>https://blog.rabcnops.cn/</id>
  
  <author>
    <name>Rab</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hexo + GitHub 个人博客部署</title>
    <link href="https://blog.rabcnops.cn/posts/articles/2d762e62.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/2d762e62.html</id>
    <published>2023-03-30T05:20:54.000Z</published>
    <updated>2023-03-30T06:36:48.636Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330132102576.png" alt="image-20230330132102576"></p><p><strong>官网</strong>：<a href="https://hexo.io/">https://hexo.io/</a><br><strong>Auth</strong>：rab</p><hr><h2 id="一、Hexo-运行环境"><a href="#一、Hexo-运行环境" class="headerlink" title="一、Hexo 运行环境"></a>一、Hexo 运行环境</h2><p><strong>1、运行平台</strong></p><ul><li><strong>本地环境</strong>：Windows 10</li><li><strong>线上环境</strong>：Github</li></ul><p><strong>2、运行软件环境</strong></p><blockquote><p>本地环境：Windows 10</p></blockquote><ul><li><strong>NodeJS</strong>：18.15.0(包含 npm 9.5.0)</li><li><strong>Npm</strong>：9.05</li><li><strong>Git</strong>：2.36.1</li></ul><h2 id="二、Hexo-项目初始化"><a href="#二、Hexo-项目初始化" class="headerlink" title="二、Hexo 项目初始化"></a>二、Hexo 项目初始化</h2><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><p>1、安装 Hexo</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322164752092.png" alt="image-20230322164752092"></p><p>2、查看安装的 Hexo 版本</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322164656592.png" alt="image-20230322164656592"></p><p>3、创建工程并初始化</p><blockquote><p><code>hexo-blog</code> 项目名可自定义</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init hexo-blog</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322164432235.png" alt="image-20230322164432235"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> hexo-blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322164550392.png" alt="image-20230322164550392"></p><blockquote><p>初始化完成后的目录结构如下图所示</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322170606051.png" alt="image-20230322170606051"></p><h3 id="2-2-启动"><a href="#2-2-启动" class="headerlink" title="2.2 启动"></a>2.2 启动</h3><p>1、启动 Hexo 项目</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo -g      <span class="comment"># 更新文件至pubulic</span></span><br><span class="line">hexo server  <span class="comment"># 启动hexo服务</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322164341471.png" alt="image-20230322164341471"></p><p>2、本地浏览器访问</p><blockquote><p><a href="http://localhost:4000/">http://localhost:4000/</a></p><p>下图为 Hexo 的默认 Home</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322170028665.png" alt="image-20230322170028665"></p><h3 id="2-3-主题"><a href="#2-3-主题" class="headerlink" title="2.3 主题"></a>2.3 主题</h3><blockquote><p>本次主题：<a href="https://butterfly.js.org/">Butterfly</a></p><p>更多官网主题：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></p></blockquote><h4 id="2-3-1-主题下载"><a href="#2-3-1-主题下载" class="headerlink" title="2.3.1 主题下载"></a>2.3.1 主题下载</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> hexo-blog</span><br><span class="line">git <span class="built_in">clone</span> -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly</span><br></pre></td></tr></table></figure><h4 id="2-3-2-主题应用"><a href="#2-3-2-主题应用" class="headerlink" title="2.3.2 主题应用"></a>2.3.2 主题应用</h4><blockquote><p>修改 Hexo 根目录下的 <code>_config.yml</code>，把主题改为 <code>butterfly</code></p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: butterfly</span><br></pre></td></tr></table></figure><ul><li><p>修改前</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322173612968.png" alt="image-20230322173612968"></p></li><li><p>修改后</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322173653676.png" alt="image-20230322173653676"></p></li></ul><h4 id="2-3-3-安装插件"><a href="#2-3-3-安装插件" class="headerlink" title="2.3.3 安装插件"></a>2.3.3 安装插件</h4><blockquote><p>如果你沒有 pug 以及 stylus 的渲染器，请下载安装</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> hexo-blog</span><br><span class="line">npm install hexo-renderer-pug hexo-renderer-stylus --save</span><br></pre></td></tr></table></figure><h4 id="2-3-4-升级建议"><a href="#2-3-4-升级建议" class="headerlink" title="2.3.4 升级建议"></a>2.3.4 升级建议</h4><blockquote><p>摘至插件操作文档：<a href="https://butterfly.js.org/">Butterfly</a></p></blockquote><p>为了減少升级主题后带来的不便，请使用以下方法（建议，可以不做）。</p><p>在 hexo 的根目录创建一个文件 <code>_config.butterfly.yml</code>，并把主题目录的 <code>_config.yml</code> 内容复制到 <code>_config.butterfly.yml</code> 去。</p><blockquote><p>注意: 复制的是主题的 <code>_config.yml</code> ,而不是 hexo 的 <code>_config.yml</code>。</p><p>注意： 不要把主题目录的 <code>_config.yml</code> 刪掉。</p></blockquote><p>注意：以后只需要在 <code>_config.butterfly.yml</code> 进行配置就行。</p><p>如果使用了 <code>_config.butterfly.yml</code>， 配置主题的 <code>_config.yml</code> 将不会有效果。</p><p>Hexo 会自动合并主题中的 <code>_config.yml</code> 和 <code>_config.butterfly.yml</code> 里的配置，如果存在同名配置，会使用 <code>_config.butterfly.yml</code> 的配置，其优先级较高。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322180036589.png" alt="image-20230322180036589"></p><h4 id="2-3-5-启动-Hexo"><a href="#2-3-5-启动-Hexo" class="headerlink" title="2.3.5 启动 Hexo"></a>2.3.5 启动 Hexo</h4><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230322180135166.png" alt="image-20230322180135166"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hxeo server</span><br></pre></td></tr></table></figure><p>本地浏览器访问</p><blockquote><p><a href="http://localhost:4000/">http://localhost:4000/</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323100500616.png" alt="image-20230323100500616"></p><h2 id="三、GitHub-部署-Hexo"><a href="#三、GitHub-部署-Hexo" class="headerlink" title="三、GitHub 部署 Hexo"></a>三、GitHub 部署 Hexo</h2><p>以上的操作是在我们的 Windows 环境下实现的，我们需要发布到 GitHub 上让任何人都可以访问。</p><h3 id="3-1-创建-Git-仓库"><a href="#3-1-创建-Git-仓库" class="headerlink" title="3.1 创建 Git 仓库"></a>3.1 创建 Git 仓库</h3><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323093845546.png" alt="image-20230323093845546"></p><h3 id="3-2-Git-客户端配置"><a href="#3-2-Git-客户端配置" class="headerlink" title="3.2 Git 客户端配置"></a>3.2 Git 客户端配置</h3><p>1、windows 本地配置并推送</p><blockquote><p>create a new repository on the command line</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;# rabcnops.github.io&quot;</span> &gt;&gt; README.md</span><br><span class="line">git init</span><br><span class="line">git add README.md</span><br><span class="line">git commit -m <span class="string">&quot;first commit&quot;</span></span><br><span class="line">git branch -M main</span><br><span class="line">git remote add origin https://github.com/rabcnops/rabcnops.github.io.git</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><blockquote><p>or push an existing repository from the command line</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin https://github.com/rabcnops/rabcnops.github.io.git</span><br><span class="line">git branch -M main</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323093941950.png" alt="image-20230323093941950"></p><p>2、推送后查看 GitHuab 详情</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323095255306.png" alt="image-20230323095255306"></p><h3 id="3-3-发布项目至-GitHub"><a href="#3-3-发布项目至-GitHub" class="headerlink" title="3.3 发布项目至 GitHub"></a>3.3 发布项目至 GitHub</h3><p>1、下载 hexo-deployer-git</p><blockquote><p>目的是能在 Hexo 主配置中定义 GitHub 的远程仓库</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> hexo-blog</span><br><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure><blockquote><p>或者直接将 <code>public</code> 目录下的所有文件和目录推送至 <code>GitHub</code> 仓库中。</p></blockquote><p>2、修改 <code>_config.yml</code> 配置文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo: https://github.com/rabcnops/rabcnops.github.io.git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323094703457.png" alt="image-20230323094703457"></p><p>3、将 Hexo 项目发布至 Git 仓库</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean  <span class="comment"># 清理缓存</span></span><br><span class="line">hexo g      <span class="comment"># 生成文件</span></span><br><span class="line">hexo d      <span class="comment"># 上传Git仓库</span></span><br></pre></td></tr></table></figure><p>4、最后看看推送结果</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323101017404.png" alt="image-20230323101017404"></p><p>5、查看最终 Pages 地址</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323101258269.png" alt="image-20230323101258269"></p><h3 id="3-4-访问-GitHub-Pages"><a href="#3-4-访问-GitHub-Pages" class="headerlink" title="3.4 访问 GitHub Pages"></a>3.4 访问 GitHub Pages</h3><p>在浏览器访问测试。</p><blockquote><p><a href="https://rabcnops.github.io/">https://rabcnops.github.io/</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230323101508913.png" alt="image-20230323101508913"></p><p><mark>至此，我们的博客系统已经发布至我们的 GitHub 上了。</mark></p><h2 id="四、自定义域名"><a href="#四、自定义域名" class="headerlink" title="四、自定义域名"></a>四、自定义域名</h2><p><strong>注意</strong>：这一步看你的实际情况来，这是可选的。如果你需要拥有自己的个性化域名，那你可以去<a href="https://www.aliyun.com/">阿里云</a>、<a href="https://cloud.tencent.com/">腾讯云</a>等云厂商购买域名并做域名解析配置即可。</p><h3 id="4-1-购买域名"><a href="#4-1-购买域名" class="headerlink" title="4.1 购买域名"></a>4.1 购买域名</h3><p>1、购买域名</p><p><a href="https://wanwang.aliyun.com/domain/searchresult/#/?keyword=rabcnops&suffix=cn">域名查询结果_域名信息_域名交易-万网-阿里云旗下品牌 (aliyun.com)</a></p><p>2、进入域名控制台查看购买的域名</p><p><a href="https://dc.console.aliyun.com/?spm=a2c4g.11186623.0.0.34943d96sbKudn#/domain-list/all">进入域名控制台 (aliyun.com)</a></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330122756957.png" alt="image-20230330122756957"></p><h3 id="4-2-域名解析"><a href="#4-2-域名解析" class="headerlink" title="4.2 域名解析"></a>4.2 域名解析</h3><p>1、对购买的域名进行 DNS 解析</p><p><a href="https://dns.console.aliyun.com/?spm=5176.100251.top-nav.4.307d4f15LtAcK7#/dns/domainList">云解析 DNS (aliyun.com)</a></p><p>2、操作步骤</p><ul><li><p>添加域名</p><blockquote><p>一般不用添加（会自动在列表中），除非你是在别的云平台购买的域名。</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330122950530.png" alt="image-20230330122950530"></p></li><li><p>添加解析记录</p><blockquote><p>记录类型：CNAME</p><p>主机记录：自定义。比如你想你的网站叫 <a href="http://www.rabcnops.cn,那就填写/">www.rabcnops.cn，那就填写</a> www</p><p>记录值：也就是 Github 的 Pages 地址（最好不要填IP，因为IP可能会改变，除非是你自己的云服务器）</p><p>TTL：默认 10 分钟即可</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330123239185.png" alt="image-20230330123239185"></p></li><li><p>完成之后，你就会看到一条解析记录</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330125651673.png" alt="image-20230330125651673"></p></li></ul><h3 id="4-3-SSL-证书"><a href="#4-3-SSL-证书" class="headerlink" title="4.3 SSL 证书"></a>4.3 SSL 证书</h3><p>如果你有强迫症，不想看到 URL <code>不安全</code> 标志，如下图，那你就需要配置 SSL 数字证书。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330130031143.png" alt="image-20230330130031143"></p><p>1、进入数字证书控制台</p><p><a href="https://yundun.console.aliyun.com/?spm=5176.100251.top-nav.37.307d4f15LtAcK7&p=cas#/certExtend/free">数字证书管理服务管理控制台 - SSL 证书 (aliyun.com)</a></p><p>2、创建证书</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330130235706.png" alt="image-20230330130235706"></p><p>3、申请证书</p><blockquote><p>点击<code>申请证书</code></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330130313125.png" alt="image-20230330130313125"></p><p>4、填写申请</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330130609494.png" alt="image-20230330130609494"></p><p>5、等待下发证书即可</p><blockquote><p>查看状态：已签发</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330130724457.png" alt="image-20230330130724457"></p><p><mark>到这里，你的域名+SSL数字证书的准备工作已经完成！</mark></p><h3 id="4-4-Github-配置自定义域名"><a href="#4-4-Github-配置自定义域名" class="headerlink" title="4.4 Github 配置自定义域名"></a>4.4 Github 配置自定义域名</h3><p>去到你项目的 <code>GitHub Pages</code> 去添加你的域名，并强制启用 HTTPS。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330131357888.png"></p><h2 id="五、Hexo-主题"><a href="#五、Hexo-主题" class="headerlink" title="五、Hexo 主题"></a>五、Hexo 主题</h2><blockquote><p>本次主题：<a href="https://butterfly.js.org/">Butterfly</a></p><p>更多 Hexo 官网主题：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></p></blockquote><p>剩下的主题配置就不一步步演示了（内容太多了），更多配置看<a href="https://butterfly.js.org/">主题插件文档</a>，根据文档一步步操作即可。</p><p><mark>—END—</mark></p>]]></content>
    
    
    <summary type="html">Hexo + GitHub 个人博客部署，包括自定义个人域名 + SSL 数字证书的详细配置。</summary>
    
    
    
    <category term="Hexo" scheme="https://blog.rabcnops.cn/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://blog.rabcnops.cn/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus - SSL 证书过期监控 - 钉钉告警</title>
    <link href="https://blog.rabcnops.cn/posts/articles/462c3ed6.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/462c3ed6.html</id>
    <published>2023-03-30T03:40:54.000Z</published>
    <updated>2023-03-30T04:08:35.887Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上次博客《Prometheus - SSL 证书过期监控》已经配置了 Grafana 如何展示 SSL 过期监控面板，本次接着将<code>告警</code>功能加上，这才是我们的最终目的。</p><h2 id="一、配置-Prometheus-告警规则"><a href="#一、配置-Prometheus-告警规则" class="headerlink" title="一、配置 Prometheus 告警规则"></a>一、配置 Prometheus 告警规则</h2><p><strong>1、先确定好 Prometheus 的规则文件路径</strong></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330110201021.png" alt="image-20230330110201021"></p><p><strong>2、编写告警规则</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/prometheus/rules/ssl_cert_alerts.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">groups</span>:</span><br><span class="line">- name: <span class="string">&quot;SSL证书过期提醒&quot;</span></span><br><span class="line">  rules:</span><br><span class="line">  - alert: <span class="string">&quot;证书过期时间&lt;30天&quot;</span></span><br><span class="line">    <span class="built_in">expr</span>: probe_ssl_earliest_cert_expiry&#123;job=<span class="string">&quot;SSL证书时间&quot;</span>&#125; - time() &lt; 86400 * 30</span><br><span class="line">    <span class="keyword">for</span>: 0s</span><br><span class="line">    labels:</span><br><span class="line">      severity: <span class="string">&quot;提示&quot;</span></span><br><span class="line">    annotations:</span><br><span class="line">      summary: <span class="string">&quot;&#123;&#123; <span class="variable">$labels</span>.instance &#125;&#125; SSL 证书将在30天后过期，请注意及时续费！&quot;</span></span><br><span class="line">      description: <span class="string">&quot;&#123;&#123; <span class="variable">$labels</span>.instance &#125;&#125; SSL 证书将在30天后过期，请注意及时续费！&quot;</span></span><br><span class="line">  - alert: <span class="string">&quot;证书过期时间&lt;7天&quot;</span></span><br><span class="line">    <span class="built_in">expr</span>: probe_ssl_earliest_cert_expiry&#123;job=<span class="string">&quot;SSL证书时间&quot;</span>&#125; - time() &lt; 86400 * 7</span><br><span class="line">    <span class="keyword">for</span>: 0s</span><br><span class="line">    labels:</span><br><span class="line">      severity: <span class="string">&quot;告警&quot;</span></span><br><span class="line">    annotations:</span><br><span class="line">      summary: <span class="string">&quot;&#123;&#123; <span class="variable">$labels</span>.instance &#125;&#125; SSL 证书将在7天后过期，请注意及时续费！&quot;</span></span><br><span class="line">      description: <span class="string">&quot;&#123;&#123; <span class="variable">$labels</span>.instance &#125;&#125; SSL 证书将在7天后过期，请注意及时续费！&quot;</span></span><br><span class="line">  - alert: <span class="string">&quot;证书过期时间&lt;1天&quot;</span></span><br><span class="line">    <span class="built_in">expr</span>: probe_ssl_earliest_cert_expiry&#123;job=<span class="string">&quot;SSL证书时间&quot;</span>&#125; - time() &lt; 86400 * 1</span><br><span class="line">    <span class="keyword">for</span>: 0s</span><br><span class="line">    labels:</span><br><span class="line">      severity: <span class="string">&quot;灾难&quot;</span></span><br><span class="line">    annotations:</span><br><span class="line">      summary: <span class="string">&quot;&#123;&#123; <span class="variable">$labels</span>.instance &#125;&#125; SSL 证书将在1天后过期，请注意及时续费！&quot;</span></span><br><span class="line">      description: <span class="string">&quot;&#123;&#123; <span class="variable">$labels</span>.instance &#125;&#125; SSL 证书将在1天后过期，请注意及时续费！&quot;</span></span><br></pre></td></tr></table></figure><p><strong>3、重启 Prometheus</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart prometheus</span><br></pre></td></tr></table></figure><h2 id="二、配置-Alertmanager"><a href="#二、配置-Alertmanager" class="headerlink" title="二、配置 Alertmanager"></a>二、配置 Alertmanager</h2><p><strong>1、修改配置文件</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/alertmanager/conf/config.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">route:</span><br><span class="line">  group_wait: 0s</span><br><span class="line">  group_interval: 5s</span><br><span class="line">  repeat_interval: 1m</span><br><span class="line">  group_by: [<span class="string">&#x27;instance&#x27;</span>]</span><br><span class="line">  receiver: <span class="string">&#x27;web.hook.prometheusalert&#x27;</span></span><br><span class="line"></span><br><span class="line">receivers:</span><br><span class="line">- name: <span class="string">&#x27;web.hook.prometheusalert&#x27;</span></span><br><span class="line">  webhook_configs:</span><br><span class="line">  - url: <span class="string">&#x27;http://YourDingTalk_IP:8060/dingtalk/webhook1/send&#x27;</span></span><br></pre></td></tr></table></figure><p><strong>2、重启 Alertmanager</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart alertmanager</span><br></pre></td></tr></table></figure><h2 id="三、配置-DingTalk"><a href="#三、配置-DingTalk" class="headerlink" title="三、配置 DingTalk"></a>三、配置 DingTalk</h2><p><strong>1、配置文件</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/dingtalk/conf/config.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">templates:</span><br><span class="line">  - /etc/prometheus-webhook-dingtalk/templates/default.tmpl</span><br><span class="line">targets:</span><br><span class="line">  webhook1:</span><br><span class="line">    url: https://oapi.dingtalk.com/robot/send?access_token=8cf8d025f***a4537b22</span><br><span class="line">    secret: SECb***95fbab</span><br><span class="line">    mention:</span><br><span class="line">      all: <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><strong>2、模板文件</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/dingtalk/templates/default.tmpl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：这里的templates路径为什么与上面的templates路径不对应，那是因为我是用容器起的DingTalk，取的是容器内部路径</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">&#123;&#123;/* Firing */&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">&quot;default.__text_alert_list&quot;</span> &#125;&#125;&#123;&#123; range . &#125;&#125;</span><br><span class="line"></span><br><span class="line">**触发时间:** &#123;&#123; dateInZone <span class="string">&quot;2006.01.02 15:04:05&quot;</span> (.StartsAt) <span class="string">&quot;Asia/Shanghai&quot;</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">**摘要:** &#123;&#123; .Annotations.summary &#125;&#125;</span><br><span class="line"></span><br><span class="line">**描述:** &#123;&#123; .Annotations.description &#125;&#125;</span><br><span class="line"></span><br><span class="line">**监控:** [grafana](http://grafana_ip:8000/grafana/d/GuJ5DHMnz/fu-wu-qi-jian-kong-tu-biao?orgId=1)</span><br><span class="line"></span><br><span class="line">**详情:**</span><br><span class="line">&#123;&#123; range .Labels.SortedPairs &#125;&#125;&#123;&#123; <span class="keyword">if</span> and (ne (.Name) <span class="string">&quot;severity&quot;</span>) (ne (.Name) <span class="string">&quot;summary&quot;</span>) &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Resolved */&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123; define <span class="string">&quot;default.__text_resolved_list&quot;</span> &#125;&#125;&#123;&#123; range . &#125;&#125;</span><br><span class="line"></span><br><span class="line">**触发时间:** &#123;&#123; dateInZone <span class="string">&quot;2006.01.02 15:04:05&quot;</span> (.StartsAt) <span class="string">&quot;Asia/Shanghai&quot;</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">**解除时间:** &#123;&#123; dateInZone <span class="string">&quot;2006.01.02 15:04:05&quot;</span> (.EndsAt) <span class="string">&quot;Asia/Shanghai&quot;</span> &#125;&#125;</span><br><span class="line"></span><br><span class="line">**摘要:** &#123;&#123; .Annotations.summary &#125;&#125;</span><br><span class="line"></span><br><span class="line">**监控:** [grafana](http://grafana_ip:8000/grafana/d/GuJ5DHMnz/fu-wu-qi-jian-kong-tu-biao?orgId=1)</span><br><span class="line"></span><br><span class="line">**详情:**</span><br><span class="line">&#123;&#123; range .Labels.SortedPairs &#125;&#125;&#123;&#123; <span class="keyword">if</span> and (ne (.Name) <span class="string">&quot;severity&quot;</span>) (ne (.Name) <span class="string">&quot;summary&quot;</span>) &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><strong>3、重启 DingTalk</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart dingtalk</span><br></pre></td></tr></table></figure><h2 id="四、模拟告警与恢复"><a href="#四、模拟告警与恢复" class="headerlink" title="四、模拟告警与恢复"></a>四、模拟告警与恢复</h2><p><strong>1、钉钉告警通知</strong></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330111655592.png" alt="image-20230330111655592"></p><p><strong>2、钉钉解除告警通知</strong></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230330112013249.png" alt="image-20230330112013249"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>整体来说都比较简单，重点是要理清楚整个过程链，配置过程中仔细点即可，接下来会继续剖析告警的原理&#x2F;告警的时机。</p>]]></content>
    
    
    <summary type="html">上次博客《Prometheus - SSL 证书过期监控》已经配置了 Grafana 如何展示 SSL 过期监控面板，本次接着将告警功能加上，这才是我们的最终目的。</summary>
    
    
    
    <category term="监控系统" scheme="https://blog.rabcnops.cn/categories/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="Prometheus" scheme="https://blog.rabcnops.cn/categories/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/Prometheus/"/>
    
    
    <category term="Linux" scheme="https://blog.rabcnops.cn/tags/Linux/"/>
    
    <category term="Prometheus" scheme="https://blog.rabcnops.cn/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>Ansible 部署 Wordpress</title>
    <link href="https://blog.rabcnops.cn/posts/articles/1c8d3a9.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/1c8d3a9.html</id>
    <published>2023-03-29T02:51:14.000Z</published>
    <updated>2023-03-29T03:29:44.412Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、规划"><a href="#一、规划" class="headerlink" title="一、规划"></a>一、规划</h2><ul><li>Linux 环境：CentOS 7.9</li><li>ansible 控制节点：192.168.56.152</li><li>ansible 被管理节点：192.168.56.153</li><li>Wordpress 版本：4.9.4</li></ul><h2 id="二、部署"><a href="#二、部署" class="headerlink" title="二、部署"></a>二、部署</h2><h3 id="2-1-定义-inventory"><a href="#2-1-定义-inventory" class="headerlink" title="2.1 定义 inventory"></a>2.1 定义 inventory</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim inventory.yaml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mywebhost:</span><br><span class="line">  hosts:</span><br><span class="line">    vm01:</span><br><span class="line">      ansible_host: 192.168.56.153</span><br><span class="line"></span><br><span class="line"><span class="comment"># 说明：mywebhost 为组名</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-2-定义-playbook"><a href="#2-2-定义-playbook" class="headerlink" title="2.2 定义 playbook"></a>2.2 定义 playbook</h3><p>1、下载 wordpress 安装包</p><p>下载地址<a href="https://cn.wordpress.org/download/releases/">https://cn.wordpress.org/download/releases/</a></p><p>2、上传安装包至 ansible 控制节点</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /home/data/ansible</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230328233159669.png" alt="image-20230328233159669"></p><p>3、ansible 控制节点编写 playbook</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim wordpress.yml</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">- hosts: mywebhost</span><br><span class="line">  remote_user: root</span><br><span class="line">  vars:</span><br><span class="line">    db_pkgs:</span><br><span class="line">      - mariadb</span><br><span class="line">      - mariadb-server</span><br><span class="line">    web_pkgs:</span><br><span class="line">      - httpd</span><br><span class="line">      - php</span><br><span class="line">      - php-gd</span><br><span class="line">      - php-mysql</span><br><span class="line">      - gd</span><br><span class="line">  tasks:</span><br><span class="line">    - name: install mariadb</span><br><span class="line">      yum: name=&#123;&#123; db_pkgs &#125;&#125; state=latest</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;wordpress&#x27;</span></span><br><span class="line">    - name: install webserver</span><br><span class="line">      yum: name=&#123;&#123; web_pkgs &#125;&#125; state=latest</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;wordpress&#x27;</span></span><br><span class="line">    - name: start mariadb</span><br><span class="line">      service: name=mariadb state=started</span><br><span class="line">      notify: create_db</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;wordpress&#x27;</span>      </span><br><span class="line">    - name: start webserver</span><br><span class="line">      service: name=httpd state=started</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;wordpress&#x27;</span></span><br><span class="line">      </span><br><span class="line">    - name: to package</span><br><span class="line">      unarchive: src=/home/data/ansible/wordpress-4.9.4-zh_CN.tar.gz dest=/var/www/html</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;wordpress&#x27;</span>   </span><br><span class="line">    - name: <span class="built_in">chown</span></span><br><span class="line">      file: owner=apache group=apache recurse=<span class="built_in">yes</span> path=/var/www/html</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;wordpress&#x27;</span>     </span><br><span class="line">  handlers:</span><br><span class="line">    - name: create_db</span><br><span class="line">      shell: mysql -e <span class="string">&quot;create database wordpress;grant all on *.* to &#x27;remote&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;;flush privileges;&quot;</span></span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;wordpress&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="2-3-运行-playbook"><a href="#2-3-运行-playbook" class="headerlink" title="2.3 运行 playbook"></a>2.3 运行 playbook</h3><p>1、运行前三部曲</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查错误</span></span><br><span class="line">ansible-playbook wordpress.yml -i inventory.yaml --syntax-check</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有任务</span></span><br><span class="line">ansible-playbook wordpress.yml -i inventory.yaml --list-task</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出在那些机器执行</span></span><br><span class="line">ansible-playbook wordpress.yml -i inventory.yaml --list-hosts</span><br></pre></td></tr></table></figure><p>2、运行</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook wordpress.yml -i inventory.yaml</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329103140769.png" alt="image-20230329103140769"></p><h3 id="2-4-安装-wordpress"><a href="#2-4-安装-wordpress" class="headerlink" title="2.4 安装 wordpress"></a>2.4 安装 wordpress</h3><p>1、浏览器访问</p><blockquote><p><a href="http://192.168.56.153/wordpress">http://192.168.56.153/wordpress</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329095308748.png" alt="image-20230329095308748"></p><p>2、配置数据库</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329095739451.png" alt="image-20230329095739451"></p><p>3、开始安装 wordpress</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329110018596.png" alt="image-20230329110018596"></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329110415294.png" alt="image-20230329110415294"></p><h3 id="2-5-登录-wordpress"><a href="#2-5-登录-wordpress" class="headerlink" title="2.5 登录 wordpress"></a>2.5 登录 wordpress</h3><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329110544631.png" alt="image-20230329110544631"></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329110715387.png" alt="image-20230329110715387"></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329110829054.png" alt="image-20230329110829054"></p><p><mark>说明：我这里为了演示，就在一台服务器上进行安装 wordpress 了，如果你想把你的数据库&#x2F;nginx等分开在不同的服务器部署，那也是可以的，只需要指定 playbook 文件中的 <code>ansible_nodename</code> 为你对应的主机名即可，具体一份案例如下。</mark></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line"><span class="comment"># 功能：ansible搭建LAMP环境及WordPress项目部署</span></span><br><span class="line"><span class="comment"># 对所有主机操作（即通过ansible机器向web:155和database:156机器进行批量操作）</span></span><br><span class="line"><span class="comment"># hosts: 后面可写主机组名或主机名</span></span><br><span class="line">- hosts: mywebhost</span><br><span class="line">  remote_user: root</span><br><span class="line">  <span class="comment"># 定义变量</span></span><br><span class="line">  vars:</span><br><span class="line">    db_pkgs:</span><br><span class="line">      <span class="comment"># 以下的-为变量“值”，也就是在引用db_pkgs变量时，可取变量中的值</span></span><br><span class="line">      - mariadb</span><br><span class="line">      - mariadb-server</span><br><span class="line">    web_pkgs:</span><br><span class="line">      - httpd</span><br><span class="line">      - php</span><br><span class="line">      - php-gd</span><br><span class="line">      - php-mysql</span><br><span class="line">      - gd</span><br><span class="line">  <span class="comment"># tasks：ansible机器要执行操作的任务列表（依次执行）</span></span><br><span class="line">  tasks:</span><br><span class="line">    <span class="comment"># 安装mariadb</span></span><br><span class="line">    - name: install mariadb</span><br><span class="line">    <span class="comment"># 引用变量时使用&#123;&#123;&#125;&#125;</span></span><br><span class="line">      yum: name=&#123;&#123; db_pkgs &#125;&#125; state=latest</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;database&#x27;</span></span><br><span class="line">    <span class="comment"># 安装webserver相关服务（httpd、php）</span></span><br><span class="line">    - name: install webserver</span><br><span class="line">      yum: name=&#123;&#123; web_pkgs &#125;&#125; state=latest</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;web&#x27;</span></span><br><span class="line">    <span class="comment"># 启动mariadb</span></span><br><span class="line">    - name: start mariadb</span><br><span class="line">      service: name=mariadb state=started</span><br><span class="line">      <span class="comment"># 触发（类似c语言的中断信号），触发后会去handlers执行相关操作</span></span><br><span class="line">      notify: create_db</span><br><span class="line">      <span class="comment"># when判断，用来针对某主机执行的操作，比如这里是指定对database组里的机器进行操作</span></span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;database&#x27;</span></span><br><span class="line">    <span class="comment"># 启动webserver相关服务</span></span><br><span class="line">    - name: start webserver</span><br><span class="line">      service: name=httpd state=started</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;web&#x27;</span></span><br><span class="line">    <span class="comment"># 将项目包发送到指定机器（及解包）  </span></span><br><span class="line">    - name: to package</span><br><span class="line">      unarchive: src=/home/data/ansible/wordpress-4.9.4-zh_CN.tar.gz dest=/var/www/html</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;web&#x27;</span></span><br><span class="line">    <span class="comment"># 修改指定机器网站发布目录属组/主</span></span><br><span class="line">    - name: <span class="built_in">chown</span></span><br><span class="line">      file: owner=apache group=apache recurse=<span class="built_in">yes</span> path=var/www/html</span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;web&#x27;</span></span><br><span class="line">      </span><br><span class="line">  handlers:</span><br><span class="line">    <span class="comment"># 注意：这里的name名字必须和notify的触发名称保持一致</span></span><br><span class="line">    - name: create_db</span><br><span class="line">      <span class="comment"># 调用shell解释器执行相关命令</span></span><br><span class="line">      shell: mysql -e <span class="string">&quot;create database wordpress;grant all on *.* to &#x27;remote&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;;flush privileges;&quot;</span></span><br><span class="line">      <span class="comment"># 同样这里是针对database这个主机组里的机器</span></span><br><span class="line">      when: ansible_nodename == <span class="string">&#x27;database&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="三、FAQ"><a href="#三、FAQ" class="headerlink" title="三、FAQ"></a>三、FAQ</h2><p>1、普通用户连接失败</p><p><code>ERROR 1045 (28000): Access denied for user &#39;remote&#39;@&#39;localhost</code></p><p>2、原因分析与解决方案</p><p>这里注意数据库 MariaDB 的匿名用户问题，匿名用户会导致我们普通用户无法登录（连接）数据库，如下这些红框部分就是匿名用户：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329111136989.png" alt="image-20230329111136989"></p><p>因此我们需要删除这些匿名用户：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">user &#x27;&#x27;@&#x27;localhost&#x27;;</span><br><span class="line">user &#x27;&#x27;@&#x27;wordpress&#x27;;</span><br><span class="line">flush privileges</span><br></pre></td></tr></table></figure><blockquote><p>如下图，确保数据库中不存在匿名用户</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230329111747894.png" alt="image-20230329111747894"></p><p><mark>至此，问题已经解决。</mark></p>]]></content>
    
    
    <summary type="html">Ansible 搭建 LAMP 环境并部署 WordPress 项目。</summary>
    
    
    
    <category term="自动化运维" scheme="https://blog.rabcnops.cn/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    <category term="Ansible" scheme="https://blog.rabcnops.cn/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/Ansible/"/>
    
    
    <category term="Ansible" scheme="https://blog.rabcnops.cn/tags/Ansible/"/>
    
    <category term="Linux" scheme="https://blog.rabcnops.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>基于 Docker 的 Prometheus 监控方案</title>
    <link href="https://blog.rabcnops.cn/posts/articles/e36de20c.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/e36de20c.html</id>
    <published>2023-03-28T07:51:14.000Z</published>
    <updated>2023-03-28T07:52:38.491Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/prometheus.jpeg" alt="prometheus"></p><p><font color=Brown><strong>Author</strong>：rab</font><br><font color=Brown><strong>Date</strong>：2022&#x2F;07&#x2F;18</font><br><font color=Brown><strong>Blog</strong>：<a href="https://blog.csdn.net/IT_ZRS?type=blog"><font color=Brown>https://blog.csdn.net/IT_ZRS?type&#x3D;blog</font></a></font></p><hr><h2 id="一、规划"><a href="#一、规划" class="headerlink" title="一、规划"></a>一、规划</h2><h3 id="1-1-架构图"><a href="#1-1-架构图" class="headerlink" title="1.1 架构图"></a>1.1 架构图</h3><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/architecture.png" alt="architecture"></p><p>我们将按照架构图来实现。</p><h3 id="1-2-主机规划"><a href="#1-2-主机规划" class="headerlink" title="1.2 主机规划"></a>1.2 主机规划</h3><blockquote><p>由于主机资源问题，暂且以两台服务器进行演示。</p></blockquote><table><thead><tr><th>Host</th><th>server</th><th>备注</th></tr></thead><tbody><tr><td>192.168.56.141</td><td>Prometheus、Node_exporter</td><td>Prometheus 服务、采集插件</td></tr><tr><td>192.168.56.142</td><td>Grafana、Alertmanager、Node_exporter、DingTalk</td><td>监控展示、告警服务、采集插件</td></tr></tbody></table><p>版本：</p><ul><li><p>CentOS：7.9</p></li><li><p>Prometheus：2.37.0</p></li><li><p>Grafana：9.0.3</p></li><li><p>Alertmanager：0.20.0</p></li><li><p>node-exporter：1.4.0</p></li><li><p>Dingding：1.4.0</p></li></ul><p>下载：</p><ul><li>Prometheus：<a href="https://prometheus.io/docs/prometheus/latest/installation/">https://prometheus.io/docs/prometheus/latest/installation/</a></li><li>Grafana：<a href="https://grafana.com/grafana/download">https://grafana.com/grafana/download</a></li><li>Alertmanager：</li><li>node-exporter：</li></ul><h2 id="二、部署"><a href="#二、部署" class="headerlink" title="二、部署"></a>二、部署</h2><blockquote><p>相关组件下载地址：<a href="https://prometheus.io/download/">https://prometheus.io/download/</a></p><p>前提：已经对服务器做了相关初始化，且安装了 docker 容器引擎。</p></blockquote><h3 id="2-1-Prometheus"><a href="#2-1-Prometheus" class="headerlink" title="2.1 Prometheus"></a>2.1 Prometheus</h3><blockquote><p>官方文档：<a href="https://prometheus.io/docs/introduction/overview/">https://prometheus.io/docs/introduction/overview/</a></p></blockquote><p>1、pull 镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull bitnami/prometheus:2.37.0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">本次采用最新稳定版</span></span><br></pre></td></tr></table></figure><p>2、创建监控用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">groupadd -g 2000 monitor</span><br><span class="line">useradd -u 2000 -g monitor monitor</span><br></pre></td></tr></table></figure><p>3、创建相关目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/data/prometheus/&#123;etc,data,rules&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">etc：配置文件目录</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">data：数据目录</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">rules：规则目录</span></span><br></pre></td></tr></table></figure><p>4、创建配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/prometheus/etc/prometheus.yml</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或先启动临时容器再copy也是可以的</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">my global config</span></span><br><span class="line">global:</span><br><span class="line">  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.</span><br><span class="line">  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">scrape_timeout is <span class="built_in">set</span> to the global default (10s).</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Alertmanager configuration</span></span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      # - alertmanager:9093</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Load rules once and periodically evaluate them according to the global <span class="string">&#x27;evaluation_interval&#x27;</span>.</span></span><br><span class="line">rule_files:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">- <span class="string">&quot;first_rules.yml&quot;</span></span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">- <span class="string">&quot;second_rules.yml&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">A scrape configuration containing exactly one endpoint to scrape:</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Here it<span class="string">&#x27;s Prometheus itself.</span></span></span><br><span class="line">scrape_configs:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="string">The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span></span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line"></span><br><span class="line">    # metrics_path defaults to &#x27;/metrics&#x27;</span><br><span class="line">    # scheme defaults to &#x27;http&#x27;.</span><br><span class="line"></span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;localhost:9090&#x27;]</span><br></pre></td></tr></table></figure><p>5、目录授权</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown monitor. -R /home/data/prometheus</span><br></pre></td></tr></table></figure><p>6、启动容器</p><blockquote><p>运行容器前，先看看这个镜像容器启动后会执行什么命令</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect -f &#x27;&#123;&#123;.Config.Cmd&#125;&#125;&#x27; bitnami/prometheus:2.37.0</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924181619392.png" alt="image-20220924181619392"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --user root \</span><br><span class="line">    --name=prometheus \</span><br><span class="line">    --privileged=true \</span><br><span class="line">    --restart=always \</span><br><span class="line">    -p 9090:9090 \</span><br><span class="line">    -v /home/data/prometheus/etc/prometheus.yml:/etc/prometheus/prometheus.yml \</span><br><span class="line">    -v /home/data/prometheus/rules:/etc/prometheus/rules \</span><br><span class="line">    -v /home/data/prometheus/data:/data/prometheus \</span><br><span class="line">    -v /etc/localtime:/etc/localtime \</span><br><span class="line">    bitnami/prometheus:2.37.0 \</span><br><span class="line">    --config.file=&quot;/etc/prometheus/prometheus.yml&quot; \</span><br><span class="line">    --storage.tsdb.path=&quot;/data/prometheus&quot; \</span><br><span class="line">    --web.console.libraries=/opt/bitnami/prometheus/conf/console_libraries \</span><br><span class="line">    --web.console.templates=/opt/bitnami/prometheus/conf/consoles \</span><br><span class="line">    --web.enable-lifecycle \</span><br><span class="line">    --web.enable-admin-api</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">至于为什么跟什么--参数，在我前面 docker 原理中有讲到</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker inspect &lt;image&gt;   <span class="comment"># 查看CMD参数</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">想要使用热加载，需指定--web.enable-lifecycle参数</span></span><br></pre></td></tr></table></figure><p>7、访问验证</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220718122145247.png" alt="image-20220718122145247">8、热更新</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://192.168.56.141:9090/-/reload</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我docker方式部署的热加载无效，正在找原因</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">原因已经找到，我自己大意，没看镜像的相关信息，已解决</span></span><br></pre></td></tr></table></figure><p>9、语法检测</p><blockquote><p>这一点的好处在于检测你更新配置后是否有语法错误</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec prometheus promtool check config /etc/prometheus/prometheus.yml</span><br></pre></td></tr></table></figure><p>确保无误后即可重启或热更新 Prometheus。 </p><h3 id="2-2-Grafana"><a href="#2-2-Grafana" class="headerlink" title="2.2 Grafana"></a>2.2 Grafana</h3><blockquote><p>官方文档：<a href="https://grafana.com/docs/">https://grafana.com/docs/</a></p></blockquote><p>1、pull 镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull grafana/grafana:9.0.3</span><br></pre></td></tr></table></figure><p>2、创建监控用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">groupadd -g 2000 monitor</span><br><span class="line">useradd -u 2000 -g monitor monitor</span><br></pre></td></tr></table></figure><p>3、创建相关目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/data/grafana/data</span><br><span class="line">mkdir -p /home/data/grafana/logs</span><br></pre></td></tr></table></figure><p>4、启动临时容器（copy相关配置文件）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3000:3000 --name=tmp grafana/grafana:9.0.3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制配置文件</span></span><br><span class="line">docker cp tmp:/etc/grafana/ /home/data/grafana/</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">退出临时容器</span></span><br><span class="line">exit</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改文件名</span></span><br><span class="line">mv /home/data/grafana/grafana /home/data/grafana/etc</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除临时容器</span></span><br><span class="line">docker stop tmp</span><br><span class="line">docker rm tmp</span><br></pre></td></tr></table></figure><p>5、目录授权</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R monitor. /home/data/grafana</span><br><span class="line">chmod 777 -R /home/data/grafana</span><br></pre></td></tr></table></figure><p>6、启动容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --user root \</span><br><span class="line">    --name=grafana \</span><br><span class="line">    --privileged=true \</span><br><span class="line">    --restart=always \</span><br><span class="line">    -p 3000:3000 \</span><br><span class="line">    -v /home/data/grafana/etc:/etc/grafana \</span><br><span class="line">    -v /home/data/grafana/data:/var/lib/grafana \</span><br><span class="line">    -v /home/data/grafana/logs:/var/log/grafana \</span><br><span class="line">    -v /etc/localtime:/etc/localtime \</span><br><span class="line">    grafana/grafana:9.0.3</span><br></pre></td></tr></table></figure><p>7、登录验证</p><blockquote><p>默认用户：admin</p><p>默认密码：admin</p><p>输入完成之后，会提示你再次输入新的登录密码。</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220718134653471.png" alt="image-20220718134653471"></p><p>功能界面</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220718134806098.png" alt="image-20220718134806098"></p><p>8、忘记密码</p><blockquote><p>如果忘记密码，如何重置？</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">语法：grafana-cli &lt;登录用户&gt; reset-admin-password &lt;新密码&gt;</span></span><br><span class="line"></span><br><span class="line">docker exec grafana grafana-cli admin reset-admin-password admin@123</span><br></pre></td></tr></table></figure><p>9、插件安装</p><ul><li><p>在线安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker exec grafana grafana-cli plugins list-remote | more   # 查看远程可用插件</span><br><span class="line">id: abhisant-druid-datasource version: 0.0.6</span><br><span class="line">id: aceiot-svg-panel version: 0.0.11</span><br><span class="line">id: ae3e-plotly-panel version: 0.5.0</span><br><span class="line">id: agenty-flowcharting-panel version: 0.9.1</span><br><span class="line">id: aidanmountford-html-panel version: 0.0.2</span><br><span class="line">id: akumuli-datasource version: 1.3.12</span><br><span class="line">id: alexanderzobnin-zabbix-app version: 4.2.10</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>根据这些远程可用插件即可进行安装</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">案例：grafana-cli plugins install &lt;插件名&gt; &lt;插件版本号&gt;</span></span><br><span class="line">grafana-cli plugins install alexanderzobnin-zabbix-app 4.2.10</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">指定安装路径</span></span><br><span class="line">grafana-cli --pluginsDir=/data/grafana/plugins plugins install alexanderzobnin-zabbix-app 4.1.5</span><br></pre></td></tr></table></figure><blockquote><p>安装语法</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">COMMANDS:</span><br><span class="line">   install                  install &lt;plugin id&gt; &lt;plugin version (optional)&gt;</span><br><span class="line">   list-remote              list remote available plugins</span><br><span class="line">   list-versions            list-versions &lt;plugin id&gt;</span><br><span class="line">   update, upgrade          update &lt;plugin id&gt;</span><br><span class="line">   update-all, upgrade-all  update all your installed plugins</span><br><span class="line">   ls                       list all installed plugins</span><br><span class="line">   uninstall, remove        uninstall &lt;plugin id&gt;</span><br><span class="line">   help, h                  Shows a list of commands or help for one command</span><br></pre></td></tr></table></figure></li><li><p>手动安装</p><blockquote><p>如果在线安装失败，可进行手动安装</p></blockquote><p>第一步：访问grafana官网 <a href="https://grafana.com/grafana/plugins?orderBy=weight&direction=asc">https://grafana.com/grafana/plugins?orderBy=weight&direction=asc</a></p><p>第二步：查找要下载的插件，如：Pie Chart</p><p>第三步：根据安官网提供的装步骤下载即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在线下载zip包</span></span><br><span class="line">wget -nv https://grafana.com/api/plugins/grafana-piechart-panel/versions/latest/download -O /tmp/grafana-piechart-panel.zip</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或上传</span></span><br><span class="line">unzip -q /tmp/grafana-piechart-panel.zip -d /tmp</span><br><span class="line">mv /tmp/grafana-piechart-panel-* /var/lib/grafana/plugins/grafana-piechart-panel</span><br><span class="line">sudo service grafana-server restar</span><br></pre></td></tr></table></figure></li></ul><h3 id="2-3-Node-Exporter"><a href="#2-3-Node-Exporter" class="headerlink" title="2.3 Node_Exporter"></a>2.3 Node_Exporter</h3><p><code>node_exporter</code> 作为 Prometheus 的 agent 端，部署在被采集数据的 Host 上，其负责采集数据供 Prometheus 进行抓取。这里采用二进制方式部署即可。</p><p>1、下载二进制包</p><p><a href="https://github.com/prometheus/node_exporter">https://github.com/prometheus/node_exporter</a></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924165651183.png" alt="image-20220924165651183"></p><p>2、配置 systemd 管理</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/node_exporter.service</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Node Exporter</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=prometheus</span><br><span class="line">ExecStart=/home/data/prometheus/exporters/node_exporter/node_exporter --collector.textfile.directory /home/data/node_texfile --collector.systemd --collector.systemd.unit-include=&quot;(docker|sshd).service&quot;</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=default.target</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">具体参数参考我有道云笔记《Exporter+Promethue+Grafana监控平台》部分</span></span><br></pre></td></tr></table></figure><p>3、启动并设置开机自启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start node_exporter.service</span><br><span class="line">systemctl enable node_exporter.service</span><br></pre></td></tr></table></figure><p>5、验证</p><blockquote><p>这里以 141 服务器演示</p><p>浏览器访问：<a href="http://192.168.56.141:9100/metrics">http://192.168.56.141:9100/metrics</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924170321058.png" alt="image-20220924170321058"></p><p>&#x3D;&#x3D;这里用 Host 的方式部署即可，当然你也可以通过 Docker 的防暑部署。&#x3D;&#x3D;</p><p>pull 镜像：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull prom/node-exporter:latest</span><br></pre></td></tr></table></figure><p>运行容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name=node-exporter \</span><br><span class="line">  --restart=always \</span><br><span class="line">  --privileged=true \</span><br><span class="line">  --hostname=harbor-nexus \</span><br><span class="line">  -p 9100:9100 \</span><br><span class="line">  -v /proc:/host/proc:ro \</span><br><span class="line">  -v /sys:/host/sys:ro \</span><br><span class="line">  -v /:/rootfs:ro \</span><br><span class="line">  prom/node-exporter:latest</span><br></pre></td></tr></table></figure><p>Prometheus 添加配置即可（这里不再演示）</p><h3 id="2-4-Alertmanager"><a href="#2-4-Alertmanager" class="headerlink" title="2.4 Alertmanager"></a>2.4 Alertmanager</h3><blockquote><p>官方文档：<a href="https://prometheus.io/docs/alerting/latest/alertmanager/">https://prometheus.io/docs/alerting/latest/alertmanager/</a></p></blockquote><p>告警采用 Alertmanager 进行管理，其告警原理可简单概括为：当采集数据值达到告警阈值时（在prometheus设定的告警规则），就会触发 Alertmanager 进行告警（经过分组、删除重复等处理），告警通过可邮件等方式发送给相应的运维人员。主要配置步骤：</p><ul><li>设置和配置 Alertmanager；</li><li>配置 Prometheus 与 Alertmanager 之间的对话；</li><li>在 Prometheus 中创建警报规则。</li></ul><p><code>prometheus---&gt;触发阈值---&gt;超出持续时间---&gt;alertmanager---&gt;分组|抑制|静默---&gt;媒体类型---&gt;邮件|钉钉|微信等。</code></p><p>&#x3D;&#x3D;这里我采用单节点部署，一般我们生产环境中 Alertmanager 采用集群部署。&#x3D;&#x3D;</p><h4 id="2-4-1-部署与配置"><a href="#2-4-1-部署与配置" class="headerlink" title="2.4.1 部署与配置"></a>2.4.1 部署与配置</h4><p>1、先看容器启动时会加载哪些参数</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924193728233.png" alt="image-20220924193728233"></p><p>2、创建本地持久化目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/data/alertmanager/&#123;conf,data,template&#125;</span><br></pre></td></tr></table></figure><p>3、创建配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/alertmanager/conf/config.yml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">  smtp_smarthost: &#x27;smtp.163.com:465&#x27;                # 邮箱服务器</span><br><span class="line">  smtp_from: &#x27;zhurongsen_admin@163.com&#x27;             # 邮箱地址（发送用户）</span><br><span class="line">  smtp_auth_username: &#x27;zhurongsen_admin@163.com&#x27;    # 邮箱登录地址</span><br><span class="line">  smtp_auth_password: &#x27;DYKIFIZYKUOXRPFV&#x27;            # 邮箱授权码（注意是授权码，不是登录密码）</span><br><span class="line">  smtp_require_tls: false</span><br><span class="line"></span><br><span class="line">templates:</span><br><span class="line">- &#x27;/etc/alertmanager/template/*.tmpl&#x27;</span><br><span class="line"></span><br><span class="line">route:</span><br><span class="line">  group_by: [&#x27;alertname&#x27;]</span><br><span class="line">  group_wait: 20s</span><br><span class="line">  group_interval: 5m</span><br><span class="line">  repeat_interval: 3h</span><br><span class="line">  receiver: &#x27;ops&#x27;</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="built_in">continue</span>: <span class="literal">false</span></span></span><br><span class="line">  routes:</span><br><span class="line">  - match:</span><br><span class="line">      severity: critical</span><br><span class="line">    receiver: &#x27;dev&#x27;</span><br><span class="line">    # continue: true</span><br><span class="line">  - match_re:</span><br><span class="line">      severity: ^(warning|critical)$</span><br><span class="line">    receiver: &#x27;test&#x27;</span><br><span class="line"></span><br><span class="line">receivers:</span><br><span class="line">- name: &#x27;ops&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;2564395767@qq.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line"></span><br><span class="line">- name: &#x27;dev&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;2318099451@qq.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line">    </span><br><span class="line">- name: &#x27;test&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;zhurongsen_admin@126.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line"></span><br><span class="line">inhibit_rules:</span><br><span class="line">  - source_match:</span><br><span class="line">      severity: &#x27;critical&#x27;</span><br><span class="line">    target_match:</span><br><span class="line">      severity: &#x27;warning&#x27;</span><br><span class="line">    equal: [&#x27;alertname&#x27;, &#x27;dev&#x27;, &#x27;instance&#x27;]</span><br></pre></td></tr></table></figure><p>4、运行容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --restart=always \</span><br><span class="line">  --name=alertmanager \</span><br><span class="line">  --privileged=true \</span><br><span class="line">  -p 9093:9093 \</span><br><span class="line">  -v /home/data/alertmanager/conf/config.yml:/etc/alertmanager/alertmanager.yml \</span><br><span class="line">  -v /home/data/alertmanager/template:/etc/alertmanager/template \</span><br><span class="line">  -v /etc/localtime:/etc/localtime \</span><br><span class="line">  docker.io/prom/alertmanager:latest</span><br></pre></td></tr></table></figure><p>5、web 验证</p><blockquote><p>浏览器访问：<a href="http://192.168.56.142:9093/">http://192.168.56.142:9093/</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924201055281.png" alt="image-20220924201055281"></p><p>6、Prometheus 配置</p><blockquote><p>配置与 Alertmanager 通信</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Alertmanager configuration</span></span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      - 192.168.56.142:9093</span><br><span class="line">...</span><br></pre></td></tr></table></figure><blockquote><p>Alertmanager 自身也进行了数据采集，自然也可以进行状态监控</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924204227389.png" alt="image-20220924204227389"></p><h4 id="2-4-2-告警规则"><a href="#2-4-2-告警规则" class="headerlink" title="2.4.2 告警规则"></a>2.4.2 告警规则</h4><p>Alertmanager 配置完成后，还需要在 prometheus 配置文件中进行告警配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rule_files:</span><br><span class="line">  - &quot;first_rules.yml&quot;      # 记录规则</span><br><span class="line">  - &quot;second_rules.yml&quot;     # 告警规则</span><br></pre></td></tr></table></figure><blockquote><p>修改 Prometheus 配置文件，定义这两个文件得路径</p><p>docker 目录映射规则：&#x2F;home&#x2F;data&#x2F;prometheus&#x2F;rules:&#x2F;etc&#x2F;prometheus&#x2F;rules</p><p>所以我只需要在 &#x2F;home&#x2F;data&#x2F;prometheus&#x2F;rules 目录下创建规则即可</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">rule_files:</span><br><span class="line">  - &#x27;/etc/prometheus/rules/*_rules.yml&#x27;</span><br><span class="line">  - &#x27;/etc/prometheus/rules/*_alerts.yml&#x27;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h5 id="2-4-2-1-记录规则"><a href="#2-4-2-1-记录规则" class="headerlink" title="2.4.2.1 记录规则"></a>2.4.2.1 记录规则</h5><blockquote><p>新建记录规则文件：简单测试被采集服务器得健康状况</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home/data/prometheus/rules</span><br><span class="line">vim host_rules.yml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: host.rules</span><br><span class="line">  rules:</span><br><span class="line">    - record: instance:node_stat:up</span><br><span class="line">      expr: up&#123;job=&quot;linux&quot;&#125; == 0</span><br></pre></td></tr></table></figure><h5 id="2-4-2-2-告警规则"><a href="#2-4-2-2-告警规则" class="headerlink" title="2.4.2.2 告警规则"></a>2.4.2.2 告警规则</h5><blockquote><p>主机节点基础告警</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home/data/prometheus/rules</span><br><span class="line">vim host_alerts.yml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">groups:</span><br><span class="line">- name: host.alter</span><br><span class="line">  rules:</span><br><span class="line">    - alert: host_up</span><br><span class="line">      expr: instance:node_stat:up == 0</span><br><span class="line">      for: 20s</span><br><span class="line">      labels:</span><br><span class="line">        severity: warning</span><br><span class="line">      annotations:</span><br><span class="line">        summary: &quot;&#123;&#123; $labels.instance &#125;&#125; 已停止运行超过20s！请手动检查服务健康状态&quot;</span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;在 Prometheus 服务上可看见定义的告警规则&#x3D;&#x3D;</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924232204472.png" alt="image-20220924232204472"></p><h4 id="2-4-3-告警验证"><a href="#2-4-3-告警验证" class="headerlink" title="2.4.3 告警验证"></a>2.4.3 告警验证</h4><p>以上记录规则和告警规则都完成后，现在就模拟服务器故障，看是否发送告警。</p><p>1、先看看健康状态</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924231451970.png" alt="image-20220924231451970"></p><p>2、停掉 141 服务器的 node_exporter 插件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">141</span></span><br><span class="line">systemctl stop node_exporter.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">142</span></span><br><span class="line">systemctl stop node_exporter.service</span><br></pre></td></tr></table></figure><p>下图是我 126 邮箱收到的信息，原因是根据 Alertmanager 的路由策略来分发的，即当收到 wornning 告警时会匹配到该邮件并发送邮件。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924233102780.png" alt="image-20220924233102780"></p><h2 id="三、应用案例"><a href="#三、应用案例" class="headerlink" title="三、应用案例"></a>三、应用案例</h2><h3 id="3-1-主机发现"><a href="#3-1-主机发现" class="headerlink" title="3.1 主机发现"></a>3.1 主机发现</h3><h4 id="3-1-1-静态配置"><a href="#3-1-1-静态配置" class="headerlink" title="3.1.1 静态配置"></a>3.1.1 静态配置</h4><p><code>node_exporter</code> 部署完成后，还需要在 Prometheus 服务配置文件中进行配置，以此来 pull node_exporter 采集的数据。</p><p>什么是静态配置？所谓的静态配置就是在 Prometheus 配置文件中直接指定目标 Host。</p><p>1、修改 Prometheus 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">    # - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line"></span><br><span class="line">  - job_name: &#x27;linux&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#x27;192.168.56.141:9100&#x27;, &#x27;192.168.56.142:9100&#x27;]</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>2、Prometheus 服务热更新或重启</p><blockquote><p>先检测语法是否错误再重启或热加载，否则你也是启动不了的。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart prometheus</span><br></pre></td></tr></table></figure><h4 id="3-1-2-动态配置"><a href="#3-1-2-动态配置" class="headerlink" title="3.1.2 动态配置"></a>3.1.2 动态配置</h4><h5 id="3-1-2-1-基于本地文件"><a href="#3-1-2-1-基于本地文件" class="headerlink" title="3.1.2.1 基于本地文件"></a>3.1.2.1 基于本地文件</h5><p>动态配置是将被采集的目标 Host 写入一个 json 文件中，Prometheus 服务会定期去扫描其中的目标主机，如果有新的主机添加，则 Prometheus 自动获取无需热更或重启 Prometheus 服务。</p><p>1、修改 Prometheus 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">  - job_name: &#x27;linux&#x27;</span><br><span class="line">    file_sd_configs:</span><br><span class="line">      - files:</span><br><span class="line">        - /data/prometheus/target/nodes/*.json</span><br><span class="line">        refresh_interval: 1m</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这个 json 文件可以是一个泛文件：<code>/data/prometheus/target/nodes/*.json</code> 表示 Prometheus 或每隔 1 分钟查找 <code>/data/prometheus/target/nodes/</code> 目录下的所有以 <code>.json</code> 结尾的文件。</p><p>2、编写 json 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建存放json目录（对于docker部署的Prometheus，该目录在容器内部必须能读取得到）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上面得配置文件中/data/prometheus/目录已经被映射到/home/data/prometheus/data/目录下了</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">所以直接在/home/data/prometheus/data/目录下创建相关文件即可</span></span><br><span class="line">mkdir -p /home/data/prometheus/data/target/nodes</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在*.json文件中添加目标主机IP</span></span><br><span class="line">vim host.json</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  &quot;targets&quot;: [</span><br><span class="line">    &quot;192.168.56.141:9100&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先写一台Host IP进行测试，成功再添加另一台</span></span><br></pre></td></tr></table></figure><p>3、Prometheus 语法检测</p><p>4、等 1 分钟时间后再去验证一下</p><blockquote><p>可看到 141 服务器已经被添加上来了</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924173134729.png" alt="image-20220924173134729"></p><p>我再次添加 142 主机 IP，再次验证是否自动添加，同样修改配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  &quot;targets&quot;: [</span><br><span class="line">    &quot;192.168.56.141:9100&quot;,</span><br><span class="line">    &quot;192.168.56.142:9100&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><p>再次验证：可看到在 1 分钟后 142 服务器被自动添加</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220924173427913.png" alt="image-20220924173427913"></p><p><mark>如何给主机节点添加标签？</mark></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  &quot;targets&quot;: [&quot;192.168.56.141:9100&quot;],</span><br><span class="line">  &quot;labels&quot;: &#123;</span><br><span class="line">    &quot;instance&quot;: &quot;192.168.56.141&quot;,</span><br><span class="line">    &quot;Hostname&quot;: &quot;prometheus&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;, &#123;</span><br><span class="line">  &quot;targets&quot;: [&quot;192.168.56.142:9100&quot;],</span><br><span class="line">  &quot;labels&quot;: &#123;</span><br><span class="line">    &quot;instance&quot;: &quot;192.168.56.142&quot;,</span><br><span class="line">    &quot;Hostname&quot;: &quot;grafana&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><h5 id="3-1-2-2-基于-DNS"><a href="#3-1-2-2-基于-DNS" class="headerlink" title="3.1.2.2 基于 DNS"></a>3.1.2.2 基于 DNS</h5><p>1、Prometheus 配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- job_name: &#x27;webapp&#x27;</span><br><span class="line">  dns_sd_configs:</span><br><span class="line">    - names: [&#x27;app.scedutek.com&#x27;]  # 域名，保证该域名需做了解析</span><br><span class="line">      refresh_interval: 5m         # 5每分钟执行（刷新）一次</span><br><span class="line">      type: A</span><br><span class="line">      port: 80</span><br></pre></td></tr></table></figure><p>2、热更或重启 prometheus</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart prometheus</span><br></pre></td></tr></table></figure><h3 id="3-2-钉钉集成"><a href="#3-2-钉钉集成" class="headerlink" title="3.2 钉钉集成"></a>3.2 钉钉集成</h3><h4 id="3-2-1-钉钉机器人配置"><a href="#3-2-1-钉钉机器人配置" class="headerlink" title="3.2.1 钉钉机器人配置"></a>3.2.1 钉钉机器人配置</h4><blockquote><p>进入钉钉应用进行相关配置</p></blockquote><p>1、创建项目群</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007102952619.png" alt="image-20221007102952619"></p><p>2、群聊添加告警机器人</p><ul><li><p>项目群中点击设置</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007103334618.png" alt="image-20221007103334618"></p></li><li><p>点击群智能助手</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007103440941.png" alt="image-20221007103440941"></p></li><li><p>添加机器人</p><blockquote><p>点击添加机器人</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007103654901.png" alt="image-20221007103654901"></p><blockquote><p>进一步点击设置进行添加</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007103802892.png" alt="image-20221007103802892"></p></li><li><p>添加自定义机器人</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007104024684.png" alt="image-20221007104024684"></p></li></ul><p>3、配置认证（加签）</p><blockquote><ol><li>自定义机器人名字；</li><li>将机器人添加到群组；</li><li>安全设置处加签，并记录加签值（钉钉插件配置文件会用到）</li></ol></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007104211324.png" alt="image-20221007104211324"></p><p>4、获取机器人 <code>webhook</code></p><blockquote><p>钉钉插件配置文件会用到</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007104600830.png" alt="image-20221007104600830"></p><h4 id="3-2-2-部署钉钉插件"><a href="#3-2-2-部署钉钉插件" class="headerlink" title="3.2.2 部署钉钉插件"></a>3.2.2 部署钉钉插件</h4><p>1、准备配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建</span></span><br><span class="line">mkdir -p /home/data/dingtalk/conf/&#123;conf,templates&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动临时容器</span></span><br><span class="line">docker run --rm --name=tmp timonwong/prometheus-webhook-dingtalk:latest</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">复制相关配置文件至Host</span></span><br><span class="line">cd /home/data/dingtalk/conf &amp;&amp; docker cp tmp:/etc/prometheus-webhook-dingtalk/config.yml .</span><br><span class="line">cd /home/data/dingtalk/templates &amp;&amp; docker cp dingtalk:/etc/prometheus-webhook-dingtalk/templates/default.tmpl .</span><br></pre></td></tr></table></figure><p>2、准备告警模板</p><blockquote><p>可以先简单测试一下</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /home/data/dingtalk/templates/default.tmpl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123; define &quot;ding.link.content&quot; &#125;&#125;</span><br><span class="line">&#123;&#123; if gt (len .Alerts.Firing) 0 -&#125;&#125;</span><br><span class="line">告警列表:</span><br><span class="line">&#123;&#123; template &quot;__text_alert_list&quot; .Alerts.Firing &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123; if gt (len .Alerts.Resolved) 0 -&#125;&#125;</span><br><span class="line">恢复列表:</span><br><span class="line">&#123;&#123; template &quot;__text_resolve_list&quot; .Alerts.Resolved &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>以上测试无误后，以下为最终模板</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /home/data/dingtalk/templates/default.tmpl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123; template &quot;ding.link.content&quot; . &#125;&#125;&#123;&#123; define &quot;__subject&quot; &#125;&#125;[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;] &#123;&#123; .GroupLabels.SortedPairs.Values | join &quot; &quot; &#125;&#125; &#123;&#123; if gt (len .CommonLabels) (len .GroupLabels) &#125;&#125;(&#123;&#123; with .CommonLabels.Remove .GroupLabels.Names &#125;&#125;&#123;&#123; .Values | join &quot; &quot; &#125;&#125;&#123;&#123; end &#125;&#125;)&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; define &quot;__alertmanagerURL&quot; &#125;&#125;&#123;&#123; $alertURL := &quot;http://192.168.56.142:9093&quot; &#125;&#125; &#123;&#123;- $alertURL -&#125;&#125;/#/alerts?receiver=&#123;&#123; .Receiver &#125;&#125;&amp;tmp=&#123;&#123; .ExternalURL &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line"> </span><br><span class="line">&#123;&#123; define &quot;__text_alert_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;</span><br><span class="line">**Labels**</span><br><span class="line">&#123;&#123; range .Labels.SortedPairs &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;</span><br><span class="line">**Annotations**</span><br><span class="line">&#123;&#123; range .Annotations.SortedPairs &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;</span><br><span class="line">**Source:** [&#123;&#123; .GeneratorURL &#125;&#125;](&#123;&#123; .GeneratorURL &#125;&#125;)</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line"> </span><br><span class="line">&#123;&#123;/* Firing */&#125;&#125;</span><br><span class="line"> </span><br><span class="line">&#123;&#123; define &quot;default.__text_alert_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;</span><br><span class="line"> </span><br><span class="line">**触发时间:** &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125;</span><br><span class="line"></span><br><span class="line">**摘要:** &#123;&#123; .Annotations.summary &#125;&#125;</span><br><span class="line"></span><br><span class="line">**描述:** &#123;&#123; .Annotations.description &#125;&#125;</span><br><span class="line"></span><br><span class="line">**监控:** [grafana](http://192.168.25.10:3000/grafana/d/GuJ5DHMnz/fu-wu-qi-jian-kong-tu-biao?orgId=1)</span><br><span class="line"></span><br><span class="line">**详情:**</span><br><span class="line">&#123;&#123; range .Labels.SortedPairs &#125;&#125;&#123;&#123; if and (ne (.Name) &quot;severity&quot;) (ne (.Name) &quot;summary&quot;) &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line"> </span><br><span class="line">&#123;&#123;/* Resolved */&#125;&#125;</span><br><span class="line"> </span><br><span class="line">&#123;&#123; define &quot;default.__text_resolved_list&quot; &#125;&#125;&#123;&#123; range . &#125;&#125;</span><br><span class="line"> </span><br><span class="line">**触发时间:** &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.StartsAt) &quot;Asia/Shanghai&quot; &#125;&#125;</span><br><span class="line"></span><br><span class="line">**解除时间:** &#123;&#123; dateInZone &quot;2006.01.02 15:04:05&quot; (.EndsAt) &quot;Asia/Shanghai&quot; &#125;&#125;</span><br><span class="line"> </span><br><span class="line">**摘要:** &#123;&#123; .Annotations.summary &#125;&#125;</span><br><span class="line">**监控:** [grafana](http://192.168.25.10:8000/grafana/d/GuJ5DHMnz/fu-wu-qi-jian-kong-tu-biao?orgId=1)</span><br><span class="line">**详情:**</span><br><span class="line">&#123;&#123; range .Labels.SortedPairs &#125;&#125;&#123;&#123; if and (ne (.Name) &quot;severity&quot;) (ne (.Name) &quot;summary&quot;) &#125;&#125;&gt; - &#123;&#123; .Name &#125;&#125;: &#123;&#123; .Value | markdown | html &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Default */&#125;&#125;</span><br><span class="line">&#123;&#123; define &quot;default.title&quot; &#125;&#125;&#123;&#123; template &quot;__subject&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; define &quot;default.content&quot; &#125;&#125;#### \[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;\] **[&#123;&#123; index .GroupLabels &quot;alertname&quot; &#125;&#125;](&#123;&#123; template &quot;__alertmanagerURL&quot; . &#125;&#125;)**</span><br><span class="line">&#123;&#123; if gt (len .Alerts.Firing) 0 -&#125;&#125;</span><br><span class="line"></span><br><span class="line">![Firing-img](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic1.zhimg.com%2F50%2Fv2-6cf86cca04090c375720cd5a90cb9156_720w.jpg%3Fsource%3D1940ef5c&amp;refer=http%3A%2F%2Fpic1.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=auto?sec=1658461957&amp;t=25a208eae036691050ea197ccfbb3a7b)</span><br><span class="line"></span><br><span class="line">**告警通知**</span><br><span class="line">&#123;&#123; template &quot;default.__text_alert_list&quot; .Alerts.Firing &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123; if gt (len .Alerts.Resolved) 0 -&#125;&#125;</span><br><span class="line"></span><br><span class="line">![Resolved-img](https://t10.baidu.com/it/u=3212103844,163082301&amp;fm=30&amp;app=106&amp;f=JPEG?w=640&amp;h=480&amp;s=03801B6418732B8E0C9D2DDA030010A2)</span><br><span class="line"></span><br><span class="line">**告警解除**</span><br><span class="line">&#123;&#123; template &quot;default.__text_resolved_list&quot; .Alerts.Resolved &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Legacy */&#125;&#125;</span><br><span class="line">&#123;&#123; define &quot;legacy.title&quot; &#125;&#125;&#123;&#123; template &quot;__subject&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; define &quot;legacy.content&quot; &#125;&#125;#### \[&#123;&#123; .Status | toUpper &#125;&#125;&#123;&#123; if eq .Status &quot;firing&quot; &#125;&#125;:&#123;&#123; .Alerts.Firing | len &#125;&#125;&#123;&#123; end &#125;&#125;\] **[&#123;&#123; index .GroupLabels &quot;alertname&quot; &#125;&#125;](&#123;&#123; template &quot;__alertmanagerURL&quot; . &#125;&#125;)**</span><br><span class="line">&#123;&#123; template &quot;__text_alert_list&quot; .Alerts.Firing &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;&#123;/* Following names for compatibility */&#125;&#125;</span><br><span class="line">&#123;&#123; define &quot;ding.link.title&quot; &#125;&#125;&#123;&#123; template &quot;default.title&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123; define &quot;ding.link.content&quot; &#125;&#125;&#123;&#123; template &quot;default.content&quot; . &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">                                                                          </span><br></pre></td></tr></table></figure><p>3、修改配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /home/data/dingtalk/conf/config.yml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">templates:</span><br><span class="line">  - /etc/prometheus-webhook-dingtalk/templates/default.tmpl</span><br><span class="line">targets:</span><br><span class="line">  webhook1:</span><br><span class="line">    url: https://oapi.dingtalk.com/robot/send?access_token=8cf8d025f4cffb1c140129360bd373c6fa64a74dc29d6a41fcd07bb5a4537b22 </span><br><span class="line">    secret: SECb7e604e38d9d58456f4811c29daaa8953f39f3bfc5b98cccb664325a1d95fbab</span><br><span class="line">    mention:                            </span><br><span class="line">      all: true</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">参数说明：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">templates：指定模板位置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">webhook1：指定钉钉的Token</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">securet：机器人加签的值</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mention：告警时提醒对象</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   all：提醒所有人</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   mobiles: [<span class="string">&#x27;152***&#x27;</span>, <span class="string">&#x27;134***&#x27;</span>]  提醒指定钉钉用户</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012134825735.png" alt="image-20221012134825735"></p><p>3、运行钉钉插件容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name=dingtalk \</span><br><span class="line">  --restart always \</span><br><span class="line">  -p 8060:8060 \</span><br><span class="line">  -v /home/data/dingtalk/conf/config.yml:/etc/prometheus-webhook-dingtalk/config.yml \</span><br><span class="line">  -v /home/data/dingtalk/templates/default.tmpl:/etc/prometheus-webhook-dingtalk/templates/default.tmpl \</span><br><span class="line">  timonwong/prometheus-webhook-dingtalk:latest --web.enable-ui --config.file=/etc/prometheus-webhook-dingtalk/config.yml</span><br></pre></td></tr></table></figure><p><mark>以上钉钉是通过加签的方式进行认证，接下来介绍通过 IP 的方式进行认证</mark></p><p>同样在钉钉告警机器人处设置，添加 IP，下图解释很清楚，只有同个网络下的请求才能被处理，有一定的局限性，加签的方式却没有这些局限。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012133219719.png" alt="image-20221012133219719"></p><p><mark>此时钉钉的配置文件如下：</mark></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /home/data/dingtalk/conf/config.yml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">templates:</span><br><span class="line">  - /etc/prometheus-webhook-dingtalk/templates/default.tmpl</span><br><span class="line">targets:</span><br><span class="line">  webhook1:</span><br><span class="line">    url: https://oapi.dingtalk.com/robot/send?access_token=8cf8d025f4cffb1c140129360bd373c6fa64a74dc29d6a41fcd07bb5a4537b22</span><br><span class="line">    mention:</span><br><span class="line">      all: true</span><br><span class="line">      </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">参数说明：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">templates：指定模板位置</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">webhook1：指定钉钉的Token</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">mention：告警时提醒对象</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   all：提醒所有人</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">   mobiles: [<span class="string">&#x27;152***&#x27;</span>, <span class="string">&#x27;134***&#x27;</span>]  提醒指定钉钉用户</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012133818087.png" alt="image-20221012133818087"></p><p>修改完配置重启即可！</p><h4 id="3-2-3-Alertmanager-配置"><a href="#3-2-3-Alertmanager-配置" class="headerlink" title="3.2.3 Alertmanager 配置"></a>3.2.3 Alertmanager 配置</h4><blockquote><p>设置<code>alertmanager</code> 的yml的<code>route</code>与<code>receivers</code></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">route:</span><br><span class="line">  group_wait: 25s</span><br><span class="line">  group_interval: 30s</span><br><span class="line">  repeat_interval: 1m</span><br><span class="line">  group_by: [&#x27;instance&#x27;]</span><br><span class="line">  receiver: &#x27;web.hook.prometheusalert&#x27;</span><br><span class="line"></span><br><span class="line">receivers:</span><br><span class="line">- name: &#x27;web.hook.prometheusalert&#x27;</span><br><span class="line">  webhook_configs:</span><br><span class="line">  - url: &#x27;http://192.168.56.142:8060/dingtalk/webhook1/send&#x27;</span><br><span class="line">    send_resolved: true</span><br></pre></td></tr></table></figure><blockquote><p>上面的配置是，无论什么的告警级别，都会向钉钉发送告警。而下面的配置则会根据告警级别选择性发送告警</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">route:</span><br><span class="line">  group_by: [&#x27;alertname&#x27;]</span><br><span class="line">  group_wait: 20s</span><br><span class="line">  group_interval: 30s</span><br><span class="line">  repeat_interval: 1m</span><br><span class="line">  receiver: &#x27;ops&#x27;</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="built_in">continue</span>: <span class="literal">false</span></span></span><br><span class="line">  routes:</span><br><span class="line">  - match:</span><br><span class="line">      severity: critical</span><br><span class="line">    receiver: &#x27;dev&#x27;</span><br><span class="line">    # continue: true</span><br><span class="line">  - match_re:</span><br><span class="line">      severity: ^(warning|critical)$</span><br><span class="line">    receiver: &#x27;webhook&#x27;</span><br><span class="line"></span><br><span class="line">receivers:</span><br><span class="line">- name: &#x27;dev&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;2222222@qq.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line">- name: &#x27;webhook&#x27;</span><br><span class="line">  webhook_configs:</span><br><span class="line">  - url: http://192.168.56.142:8060/dingtalk/webhook1/send</span><br><span class="line">    send_resolved: true</span><br></pre></td></tr></table></figure><p>比如：一般信息告警 ——&gt; 普通告警 ——&gt; 灾难告警，不同的告警分别发送给不同的用户。为了快速测试，我选择了无论什么告警我都发送告警。</p><h4 id="3-2-4-告警测试验证"><a href="#3-2-4-告警测试验证" class="headerlink" title="3.2.4 告警测试验证"></a>3.2.4 告警测试验证</h4><h5 id="3-2-4-1-默认告警模板"><a href="#3-2-4-1-默认告警模板" class="headerlink" title="3.2.4.1 默认告警模板"></a>3.2.4.1 默认告警模板</h5><p>如果钉钉配置文件不指定 templates 的位置，则使用默认告警模板。</p><p>1、告警</p><blockquote><p>故意停掉 node_exporter 进程</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221004231759335.png" alt="image-20221004231759335"></p><p>2、恢复</p><blockquote><p>恢复 node_exporter 进程</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221004232000604.png" alt="image-20221004232000604"></p><h5 id="3-2-4-2-自定义告警模板"><a href="#3-2-4-2-自定义告警模板" class="headerlink" title="3.2.4.2 自定义告警模板"></a>3.2.4.2 自定义告警模板</h5><p>1、告警</p><blockquote><p>故意停掉 node_exporter 进程</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012134640168.png" alt="image-20221012134640168"></p><p>2、恢复</p><blockquote><p>恢复 node_exporter 进程</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012134722471.png" alt="image-20221012134722471"></p><h3 id="3-3-企业微信集成"><a href="#3-3-企业微信集成" class="headerlink" title="3.3 企业微信集成"></a>3.3 企业微信集成</h3><h4 id="3-3-1-应用告警"><a href="#3-3-1-应用告警" class="headerlink" title="3.3.1 应用告警"></a>3.3.1 应用告警</h4><h5 id="3-3-1-1-创建应用"><a href="#3-3-1-1-创建应用" class="headerlink" title="3.3.1.1 创建应用"></a>3.3.1.1 创建应用</h5><p>1、windows 登录企业微信后台创建应用</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007095158587.png" alt="image-20221007095158587"></p><blockquote><ol><li>上传 logo；</li><li>填写应用名；</li><li>应用介绍（可选）；</li><li>选择可见范围（即哪些部门&#x2F;成员可使用）。</li></ol></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007095324360.png" alt="image-20221007095324360"></p><p>2、记录应用的 <code>AgentId</code>、<code>Secret</code></p><blockquote><p><strong>AgentId</strong>：<code>1000002</code></p><p><strong>Secret</strong>：<code>EKmMR_DieISGXZDallbdnFb1OGaV2kADrrjN_UCj56Y</code></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007095829708.png" alt="image-20221007095829708"></p><p>3、记录企业 ID</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007100654570.png" alt="image-20221007100654570"></p><p>4、记录部门 ID</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221007114732172.png" alt="image-20221007114732172"></p><h5 id="3-3-1-2-Alertmanager-配置"><a href="#3-3-1-2-Alertmanager-配置" class="headerlink" title="3.3.1.2 Alertmanager 配置"></a>3.3.1.2 Alertmanager 配置</h5><p>看官方配置：<a href="https://prometheus.io/docs/alerting/latest/configuration/#wechat_config">https://prometheus.io/docs/alerting/latest/configuration/#wechat_config</a></p><p>1、配置说明</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Whether to notify about resolved alerts.</span></span><br><span class="line">[ send_resolved: &lt;boolean&gt; | default = false ]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The API key to use when talking to the WeChat API.</span></span><br><span class="line">[ api_secret: &lt;secret&gt; | default = global.wechat_api_secret ]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The WeChat API URL.</span></span><br><span class="line">[ api_url: &lt;string&gt; | default = global.wechat_api_url ]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">The corp <span class="built_in">id</span> <span class="keyword">for</span> authentication.</span></span><br><span class="line">[ corp_id: &lt;string&gt; | default = global.wechat_api_corp_id ]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">API request data as defined by the WeChat API.</span></span><br><span class="line">[ message: &lt;tmpl_string&gt; | default = &#x27;&#123;&#123; template &quot;wechat.default.message&quot; . &#125;&#125;&#x27; ]</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Type of the message <span class="built_in">type</span>, supported values are `text` and `markdown`.</span></span><br><span class="line">[ message_type: &lt;string&gt; | default = &#x27;text&#x27; ]</span><br><span class="line">[ agent_id: &lt;string&gt; | default = &#x27;&#123;&#123; template &quot;wechat.default.agent_id&quot; . &#125;&#125;&#x27; ]</span><br><span class="line">[ to_user: &lt;string&gt; | default = &#x27;&#123;&#123; template &quot;wechat.default.to_user&quot; . &#125;&#125;&#x27; ]</span><br><span class="line">[ to_party: &lt;string&gt; | default = &#x27;&#123;&#123; template &quot;wechat.default.to_party&quot; . &#125;&#125;&#x27; ]</span><br><span class="line">[ to_tag: &lt;string&gt; | default = &#x27;&#123;&#123; template &quot;wechat.default.to_tag&quot; . &#125;&#125;&#x27; ]</span><br></pre></td></tr></table></figure><p>2、消息模板定义，用于格式化消息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /home/data/alertmanager/conf &amp;&amp; vim wechat.tmpl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123; define &quot;wechat.default.message&quot; &#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len .Alerts.Firing) 0 -&#125;&#125;</span><br><span class="line">&#123;&#123;- range $index, $alert := .Alerts -&#125;&#125;</span><br><span class="line">&#123;&#123;- if eq $index 0 -&#125;&#125;</span><br><span class="line">告警类型: &#123;&#123; $alert.Labels.alertname &#125;&#125;</span><br><span class="line">告警级别: &#123;&#123; $alert.Labels.severity &#125;&#125;</span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">===告警详情===</span><br><span class="line">告警详情: &#123;&#123; $alert.Annotations.message &#125;&#125;</span><br><span class="line">故障时间: &#123;&#123; $alert.StartsAt.Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;</span><br><span class="line">===参考信息===</span><br><span class="line">&#123;&#123; if gt (len $alert.Labels.instance) 0 -&#125;&#125;故障实例ip: &#123;&#123; $alert.Labels.instance &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len $alert.Labels.namespace) 0 -&#125;&#125;故障实例所在namespace: &#123;&#123; $alert.Labels.namespace &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len $alert.Labels.node) 0 -&#125;&#125;故障物理机ip: &#123;&#123; $alert.Labels.node &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len $alert.Labels.pod_name) 0 -&#125;&#125;故障pod名称: &#123;&#123; $alert.Labels.pod_name &#125;&#125;&#123;&#123;- end &#125;&#125;</span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len .Alerts.Resolved) 0 -&#125;&#125;</span><br><span class="line">&#123;&#123;- range $index, $alert := .Alerts -&#125;&#125;</span><br><span class="line">&#123;&#123;- if eq $index 0 -&#125;&#125;</span><br><span class="line">告警类型: &#123;&#123; $alert.Labels.alertname &#125;&#125;</span><br><span class="line">告警级别: &#123;&#123; $alert.Labels.severity &#125;&#125;</span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">===告警详情===</span><br><span class="line">告警详情: &#123;&#123; $alert.Annotations.message &#125;&#125;</span><br><span class="line">故障时间: &#123;&#123; $alert.StartsAt.Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;</span><br><span class="line">恢复时间: &#123;&#123; $alert.EndsAt.Format &quot;2006-01-02 15:04:05&quot; &#125;&#125;</span><br><span class="line">===参考信息===</span><br><span class="line">&#123;&#123; if gt (len $alert.Labels.instance) 0 -&#125;&#125;故障实例ip: &#123;&#123; $alert.Labels.instance &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len $alert.Labels.namespace) 0 -&#125;&#125;故障实例所在namespace: &#123;&#123; $alert.Labels.namespace &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len $alert.Labels.node) 0 -&#125;&#125;故障物理机ip: &#123;&#123; $alert.Labels.node &#125;&#125;;&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- if gt (len $alert.Labels.pod_name) 0 -&#125;&#125;故障pod名称: &#123;&#123; $alert.Labels.pod_name &#125;&#125;;&#123;&#123;- end &#125;&#125;</span><br><span class="line">=====================</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br></pre></td></tr></table></figure><p>3、修改 Alertmanager 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /home/data/alertmanager/template &amp;&amp; vim config.yml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">  smtp_smarthost: &#x27;smtp.163.com:465&#x27;                # 邮箱服务器</span><br><span class="line">  smtp_from: &#x27;zhurongsen_admin@163.com&#x27;             # 邮箱地址（发送用户）</span><br><span class="line">  smtp_auth_username: &#x27;zhurongsen_admin@163.com&#x27;    # 邮箱登录地址</span><br><span class="line">  smtp_auth_password: &#x27;DYKIFIZYKUOXRPFV&#x27;            # 邮箱授权码（注意是授权码，不是登录密码）</span><br><span class="line">  smtp_require_tls: false</span><br><span class="line">  wechat_api_url: &#x27;https://qyapi.weixin.qq.com/cgi-bin/&#x27;   # 企业微信URL</span><br><span class="line">  wechat_api_corp_id: &#x27;wwb5ef1460edf62593&#x27;                 # 企业ID</span><br><span class="line"></span><br><span class="line">templates:</span><br><span class="line">- &#x27;/etc/alertmanager/template/*.tmpl&#x27;                  # 消息模板的位置</span><br><span class="line"></span><br><span class="line">route:</span><br><span class="line">  group_by: [&#x27;alertname&#x27;]</span><br><span class="line">  group_wait: 25s</span><br><span class="line">  group_interval: 30s</span><br><span class="line">  repeat_interval: 1m</span><br><span class="line">  receiver: &#x27;ops&#x27;</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash"><span class="built_in">continue</span>: <span class="literal">false</span></span></span><br><span class="line">  routes:</span><br><span class="line">  - match:</span><br><span class="line">      severity: critical</span><br><span class="line">    receiver: &#x27;dev&#x27;</span><br><span class="line">    # continue: truea</span><br><span class="line">  - match:</span><br><span class="line">      severity: warning</span><br><span class="line">    receiver: &#x27;wechat&#x27;</span><br><span class="line">  - match_re:</span><br><span class="line">      severity: ^(warning|critical)$</span><br><span class="line">    receiver: &#x27;dingtalk&#x27;</span><br><span class="line">    </span><br><span class="line">receivers:</span><br><span class="line">- name: &#x27;ops&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;2564395767@qq.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line">- name: &#x27;dev&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;2318099451@qq.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line">- name: &#x27;test&#x27;</span><br><span class="line">  email_configs:</span><br><span class="line">  - to: &#x27;zhurongsen_admin@126.com&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line">- name: &#x27;dingtalk&#x27;</span><br><span class="line">  webhook_configs:</span><br><span class="line">  - url: http://192.168.56.142:8060/dingtalk/webhook1/send</span><br><span class="line">    send_resolved: true</span><br><span class="line">- name: &#x27;wechat&#x27;</span><br><span class="line">  wechat_configs:</span><br><span class="line">  - send_resolved: true</span><br><span class="line">    to_user: &#x27;@all&#x27;    # 所有用户</span><br><span class="line">    message: &#x27;&#123;&#123; template &quot;wechat.default.message&quot; . &#125;&#125;&#x27;</span><br><span class="line">    agent_id: &#x27;1000002&#x27;                                           # 应用的 AgentId</span><br><span class="line">    api_secret: &#x27;EKmMR_DieISGXZDallbdnFb1OGaV2kADrrjN_UCj56Y&#x27;     # 应用的 Secret</span><br><span class="line"></span><br><span class="line">inhibit_rules:</span><br><span class="line">  - source_match:</span><br><span class="line">      severity: &#x27;critical&#x27;</span><br><span class="line">    target_match:</span><br><span class="line">      severity: &#x27;warning&#x27;</span><br><span class="line">    equal: [&#x27;alertname&#x27;, &#x27;dev&#x27;, &#x27;instance&#x27;]</span><br></pre></td></tr></table></figure><p>4、重启 Alertmanager</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart alertmanager</span><br></pre></td></tr></table></figure><p><mark>我这里的企业微信无法完成认证（企业认证），先暂时搁置。</mark>其实完全可以用机器人来实现。</p><h4 id="3-3-2-机器人告警"><a href="#3-3-2-机器人告警" class="headerlink" title="3.3.2 机器人告警"></a>3.3.2 机器人告警</h4><h5 id="3-3-2-1-添加机企业微信器人"><a href="#3-3-2-1-添加机企业微信器人" class="headerlink" title="3.3.2.1 添加机企业微信器人"></a>3.3.2.1 添加机企业微信器人</h5><p>1、登录企业微信管理后台启用机器人</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017163651760.png" alt="image-20221017163651760"></p><p>2、启用机器人</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017163732481.png" alt="image-20221017163732481"></p><p>3、在客户端对应的群聊中添加机器人</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017153756504.png" alt="image-20221017153756504"></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017153928431.png" alt="image-20221017153928431"></p><p>4、复制生成的 webhook 地址</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=6bce5460-be7e-4f33-8de9-8b5f0b1c9b9a</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017154037011.png" alt="image-20221017154037011"></p><p>至此机器人添加完成！</p><h5 id="3-3-2-2-安装企业微信报警插件"><a href="#3-3-2-2-安装企业微信报警插件" class="headerlink" title="3.3.2.2 安装企业微信报警插件"></a>3.3.2.2 安装企业微信报警插件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name wechat \</span><br><span class="line">  --restart always \</span><br><span class="line">  -p 8880:80 \</span><br><span class="line">  guyongquan/webhook-adapter:latest \</span><br><span class="line">  --adapter=/app/prometheusalert/wx.js=/wx=&lt;你的webhook地址&gt;</span><br></pre></td></tr></table></figure><h5 id="3-3-2-3-Alertmanager-配置"><a href="#3-3-2-3-Alertmanager-配置" class="headerlink" title="3.3.2.3 Alertmanager 配置"></a>3.3.2.3 Alertmanager 配置</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">global:</span><br><span class="line">  resolve_timeout: 5m</span><br><span class="line">route:</span><br><span class="line">  group_wait: 0s</span><br><span class="line">  group_interval: 5s</span><br><span class="line">  repeat_interval: 1m</span><br><span class="line">  group_by: [&#x27;instance&#x27;]</span><br><span class="line">  receiver: &#x27;web.hook.prometheusalert&#x27;</span><br><span class="line">...</span><br><span class="line">- name: &#x27;web.hook.prometheusalert&#x27;</span><br><span class="line">  webhook_configs:</span><br><span class="line">  - url: &#x27;http://192.168.56.142:8880/adapter/wx&#x27;</span><br><span class="line">    send_resolved: true</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017155618326.png" alt="image-20221017155618326"></p><h5 id="3-3-2-4-机器人告警验证"><a href="#3-3-2-4-机器人告警验证" class="headerlink" title="3.3.2.4 机器人告警验证"></a>3.3.2.4 机器人告警验证</h5><p>1、触发告警</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017161205328.png" alt="image-20221017161205328"></p><p>2、解除告警</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221017161311414.png" alt="image-20221017161311414"></p><h3 id="3-4-Grafana-模板导入"><a href="#3-4-Grafana-模板导入" class="headerlink" title="3.4 Grafana 模板导入"></a>3.4 Grafana 模板导入</h3><blockquote><p>官方参考模板：<a href="https://grafana.com/grafana/dashboards/">https://grafana.com/grafana/dashboards/</a></p></blockquote><p>1、添加数据源为 Prometheus</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221005203521799.png" alt="image-20221005203521799"></p><p>2、导入模板</p><blockquote><p>我此处的模板是官方模板：11074</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221005203718190.png" alt="image-20221005203718190"></p><p>3、数据展示</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221005203029392.png" alt="image-20221005203029392"></p><p>&#x3D;&#x3D;该模板展示了 node 节点的基本情况，在大多数情况下已经够用了，当然你也可以根据自己公司的实际情况进行自定义配置。&#x3D;&#x3D;</p><h3 id="3-5-容器监控"><a href="#3-5-容器监控" class="headerlink" title="3.5 容器监控"></a>3.5 容器监控</h3><p>为了解决 <code>docker stats</code> 的问题(存储、展示)，谷歌开源的 <code>cadvisor</code> 诞生了，&#96;&#96;cadvisor<code>不仅可以搜集一台机器上所有运行的容器信息，还提供基础查询界面和</code>http<code>接口，方便其他组件如</code>Prometheus<code>进行数据抓取，或者</code>cadvisor + influxdb + grafna&#96; 搭配使用。</p><h4 id="3-5-1-Cadvisor-部署"><a href="#3-5-1-Cadvisor-部署" class="headerlink" title="3.5.1 Cadvisor 部署"></a>3.5.1 Cadvisor 部署</h4><p>1、pull 镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull google/cadvisor:latest</span><br></pre></td></tr></table></figure><p>2、启动容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">docker run \</span><br><span class="line">  -itd -u root \</span><br><span class="line">  --privileged=true \</span><br><span class="line">  --detach=true \</span><br><span class="line">  --name=cadvisor \</span><br><span class="line">  --restart always \</span><br><span class="line">  -v /:/rootfs:ro \</span><br><span class="line">  -v /var/run:/var/run:rw \</span><br><span class="line">  -v /sys:/sys:ro \</span><br><span class="line">  -v /var/lib/docker/:/var/lib/docker:ro \</span><br><span class="line">  -v /dev/disk/:/dev/disk:ro \</span><br><span class="line">  -p 8080:8080 \</span><br><span class="line">  google/cadvisor:latest</span><br></pre></td></tr></table></figure><p>3、验证</p><blockquote><p><a href="http://192.168.56.142:8080/containers/">http://192.168.56.142:8080/containers/</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221005210013965.png" alt="image-20221005210013965"></p><p>4、监控指标展示（TXT）</p><blockquote><p><a href="http://192.168.56.142:8080/metrics">http://192.168.56.142:8080/metrics</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221005215249368.png" alt="image-20221005215249368"></p><h4 id="3-5-2-Prometheus-配置"><a href="#3-5-2-Prometheus-配置" class="headerlink" title="3.5.2 Prometheus 配置"></a>3.5.2 Prometheus 配置</h4><p>通过监控指标展示（TXT），类似于 <code>noed_export</code> 我们可以在 Prometheus 进行配置。</p><p>1、配置JOB</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">my global config</span></span><br><span class="line">global:</span><br><span class="line">  scrape_interval:     15s</span><br><span class="line">  evaluation_interval: 15s</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">scrape_timeout is <span class="built_in">set</span> to the global default (10s).</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Alertmanager configuration</span></span><br><span class="line">alerting:</span><br><span class="line">  alertmanagers:</span><br><span class="line">  - static_configs:</span><br><span class="line">    - targets:</span><br><span class="line">      - 192.168.56.142:9093</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Load rules once and periodically evaluate them according to the global <span class="string">&#x27;evaluation_interval&#x27;</span>.</span></span><br><span class="line">rule_files:</span><br><span class="line">  - &#x27;/etc/prometheus/rules/*.yml&#x27;</span><br><span class="line"></span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#x27;prometheus&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;192.168.56.141:9090&#x27;]</span><br><span class="line">  - job_name: &#x27;Alertmanager&#x27;</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#x27;192.168.56.142:9093&#x27;]</span><br><span class="line">  - job_name: &#x27;Linux节点监控&#x27;</span><br><span class="line">    file_sd_configs:</span><br><span class="line">      - files:</span><br><span class="line">        - /data/prometheus/target/nodes/*.json</span><br><span class="line">        refresh_interval: 1m</span><br><span class="line">  - job_name: &#x27;容器监控&#x27;</span><br><span class="line">    file_sd_configs:</span><br><span class="line">      - files:</span><br><span class="line">        - /data/prometheus/target/container/*.json</span><br><span class="line">        refresh_interval: 1m</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2、添加主机发现</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/prometheus/data/target/container/Cadvisor.json</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">        &quot;targets&quot;: [&quot;192.168.56.141:8080&quot;],</span><br><span class="line">        &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;instance&quot;: &quot;192.168.56.141&quot;,</span><br><span class="line">                &quot;Hostname&quot;: &quot;prometheus&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;container&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;, &#123;</span><br><span class="line">        &quot;targets&quot;: [&quot;192.168.56.142:8080&quot;],</span><br><span class="line">        &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;instance&quot;: &quot;192.168.56.142&quot;,</span><br><span class="line">                &quot;Hostname&quot;: &quot;grafana&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;container&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;, &#123;</span><br><span class="line">        &quot;targets&quot;: [&quot;192.168.56.180:8080&quot;],</span><br><span class="line">        &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;instance&quot;: &quot;192.168.56.180&quot;,</span><br><span class="line">                &quot;Hostname&quot;: &quot;habor-nexus&quot;,</span><br><span class="line">                &quot;type&quot;: &quot;container&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012145115351.png" alt="image-20221012145115351"></p><p>3、验证</p><blockquote><p>Prometheus 服务上查看健康状态</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012144650621.png" alt="image-20221012144650621"></p><p>4、容器的 grafana 模板</p><blockquote><p>导入模板ID：14282</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221012145310021.png" alt="image-20221012145310021"></p><p>&#x3D;&#x3D;Prometheus 数据持久化存储方案会在后续介绍，本次就简单介绍到这里，欢迎大家进行补充。&#x3D;&#x3D;</p><h2 id="四、FAQ"><a href="#四、FAQ" class="headerlink" title="四、FAQ"></a>四、FAQ</h2><h3 id="4-1-钉钉配置"><a href="#4-1-钉钉配置" class="headerlink" title="4.1 钉钉配置"></a>4.1 钉钉配置</h3><p>1、错误描述</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">level=error ts=2022-10-04T14:08:53.510Z caller=dingtalk.go:103 component=web target=webhook1 msg=&quot;Failed to send notification to DingTalk&quot; respCode=310000 respMsg=description:关键词不匹配;solution:请联系群管理员查看此机器人的关键词，并在发送的信息中包含此关键词;</span><br></pre></td></tr></table></figure><p>2、解决方案</p><p>在钉钉机器人配置处加签，如下图：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221004222615046.png" alt="image-20221004222615046"></p><h3 id="4-2-其他"><a href="#4-2-其他" class="headerlink" title="4.2 其他"></a>4.2 其他</h3><p>暂时没遇到其他问题，欢迎大家进行补充。</p>]]></content>
    
    
    <summary type="html">基于 Docker 的 Prometheus 监控方案及应用。</summary>
    
    
    
    <category term="监控系统" scheme="https://blog.rabcnops.cn/categories/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="Prometheus" scheme="https://blog.rabcnops.cn/categories/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/Prometheus/"/>
    
    
    <category term="Linux" scheme="https://blog.rabcnops.cn/tags/Linux/"/>
    
    <category term="Prometheus" scheme="https://blog.rabcnops.cn/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus - SSL 证书过期监控</title>
    <link href="https://blog.rabcnops.cn/posts/articles/2f967c8.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/2f967c8.html</id>
    <published>2023-03-28T02:56:54.000Z</published>
    <updated>2023-03-28T02:58:44.969Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230328101307841.png" alt="image-20230328101307841"></p><hr><h2 id="一、环境"><a href="#一、环境" class="headerlink" title="一、环境"></a>一、环境</h2><ol><li><p>数据采集：</p><blockquote><p>Exporter：blackbox_exporter</p><p>Version：0.22.0</p><p>Exporter 下载：<a href="https://prometheus.io/download/#blackbox_exporter">https://prometheus.io/download/#blackbox_exporter</a></p></blockquote></li><li><p>数据存储：</p><blockquote><p>Aplica：Prometheus</p><p>Version：2.37.0</p></blockquote></li><li><p>数据展示：</p><blockquote><p>Aplica：Grafana</p><p>Version：9.0.3</p><p>Dashboards：<a href="https://grafana.com/grafana/dashboards/">https://grafana.com/grafana/dashboards/</a></p><p>Dashboard ID（SSL 证书监控）：13230</p><p>Dashboard ID（HTTP 状态监控）：13659</p><p>Dashboard ID（SSL TCP HTTP 监控）：9965</p></blockquote></li></ol><h2 id="二、部署-Exporter"><a href="#二、部署-Exporter" class="headerlink" title="二、部署 Exporter"></a>二、部署 Exporter</h2><h3 id="2-1-配置-blackbox-exporter"><a href="#2-1-配置-blackbox-exporter" class="headerlink" title="2.1 配置 blackbox_exporter"></a>2.1 配置 blackbox_exporter</h3><p>1、下载 blackbox_exporter 并上传至服务器</p><p>2、解压 blackbox_exporter</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar xzf blackbox_exporter-0.22.0.linux-amd64.tar.gz -C /home/data/prometheus/exporters/</span><br><span class="line"><span class="built_in">cd</span> /home/data/prometheus/exporters/</span><br><span class="line"><span class="built_in">mv</span> blackbox_exporter-0.22.0.linux-amd64 blackbox_exporter</span><br></pre></td></tr></table></figure><p>3、修改配置文件</p><blockquote><p>blackbox_exporter 以模块的方式工作，如果你仅仅是获取 SSL 证书过期时间，那部署在任意节点即可。</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/data/prometheus/exporters/blackbox_exporter</span><br><span class="line">vim blackbox.yml  <span class="comment"># 启用http_2xx模块</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">modules:</span><br><span class="line">  http_2xx:</span><br><span class="line">    prober: http</span><br><span class="line">    <span class="built_in">timeout</span>: 30s</span><br><span class="line">    http:</span><br><span class="line">      valid_http_versions: [<span class="string">&quot;HTTP/1.1&quot;</span>, <span class="string">&quot;HTTP/2&quot;</span>]</span><br><span class="line">      valid_status_codes: [200]</span><br><span class="line">      method: GET</span><br><span class="line">      preferred_ip_protocol: <span class="string">&quot;ip4&quot;</span></span><br></pre></td></tr></table></figure><p>4、配置 systemd 管理</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/blackbox_exporter.service</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=blackbox_exporter</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=prometheus</span><br><span class="line">Group=prometheus</span><br><span class="line">WorkingDirectory=/home/data/prometheus/exporters/blackbox_exporter</span><br><span class="line">ExecStart=/home/data/prometheus/exporters/blackbox_exporter/blackbox_exporter</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>5、启动 blackbox_exporter</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start blackbox_exporter.service</span><br><span class="line">systemctl <span class="built_in">enable</span> blackbox_exporter.service</span><br><span class="line">systemctl status blackbox_exporter.service</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230328102210764.png" alt="image-20230328102210764"></p><h3 id="2-2-配置-Prometheus"><a href="#2-2-配置-Prometheus" class="headerlink" title="2.2 配置 Prometheus"></a>2.2 配置 Prometheus</h3><p>1、修改配置文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /home/data/prometheus/etc/prometheus.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加JOB</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">  - job_name: <span class="string">&#x27;blackbox_http_2xx&#x27;</span></span><br><span class="line">    metrics_path: /probe</span><br><span class="line">    params:</span><br><span class="line">      module: [http_2xx]</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets:</span><br><span class="line">        - https://blog.rabcnops.cn</span><br><span class="line">        - https://www.baidu.com</span><br><span class="line">        ...</span><br><span class="line">    relabel_configs:</span><br><span class="line">      - source_labels: [__address__]</span><br><span class="line">        target_label: __param_target</span><br><span class="line">      - source_labels: [__param_target]</span><br><span class="line">        target_label: instance</span><br><span class="line">      - target_label: __address__</span><br><span class="line">        replacement: 192.168.56.141:9115</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>2、重启（或热加载）Prometheus</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart prometheus</span><br></pre></td></tr></table></figure><h3 id="2-3-Grafana-监控面板"><a href="#2-3-Grafana-监控面板" class="headerlink" title="2.3 Grafana 监控面板"></a>2.3 Grafana 监控面板</h3><p>1、导入模板（在文章开头已经给出模板 ID）</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230328104918498.png" alt="image-20230328104918498"></p><p>2、查看最终效果</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230328101307841.png" alt="image-20230328101307841"></p><p><mark>SSL 证书过期告警部分后面在进行配置！</mark></p>]]></content>
    
    
    <summary type="html">Prometheus - SSL 证书过期监控面板搭建。</summary>
    
    
    
    <category term="监控系统" scheme="https://blog.rabcnops.cn/categories/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="Prometheus" scheme="https://blog.rabcnops.cn/categories/%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/Prometheus/"/>
    
    
    <category term="Linux" scheme="https://blog.rabcnops.cn/tags/Linux/"/>
    
    <category term="Prometheus" scheme="https://blog.rabcnops.cn/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>Docker 容器文件（数据）共享</title>
    <link href="https://blog.rabcnops.cn/posts/articles/7dd3df1e.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/7dd3df1e.html</id>
    <published>2023-03-23T04:18:21.000Z</published>
    <updated>2023-03-27T09:21:43.364Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908134844265.png" alt="image-20220908134844265"></p><p><font color=Brown><strong>Author</strong>：rab</font></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>有这样一个场景，当我们的服务都是通过容器化方式时，不仅要考虑数据持久化的问题，在 web 集群的时候也要考虑到数据共享的问题，如我需要负载均衡多个 web 服务（这些 web 主要是作为前端展示），且这些 web 服务的功能完全一致，那这时就可用到我们的文件共享技术了。而文件共享又分为两种情况：<code>容器与 Host 共享</code>、<code>容器间数据共享</code>，接下来分别介绍以下这两种文件（数据）共享方式。</p><h2 id="一、共享"><a href="#一、共享" class="headerlink" title="一、共享"></a>一、共享</h2><h3 id="1-1-容器与-Host-共享"><a href="#1-1-容器与-Host-共享" class="headerlink" title="1.1 容器与 Host 共享"></a>1.1 容器与 Host 共享</h3><p>对于容器与 Host 共享间进行数据共享也是比较常用的，比如，当我们运行某个容器的时候，我们需要获取到该容器的配置文件（实现动态配置和持久化），我们一般的做法就是去该服务的官网去下载配置文件或 copy 容器中的配置文件到 Host（其实这就实现了文档的共享了）。</p><p>以 Nginx 为例，看看容器的文件如何共享到 Host 上。</p><p>1、先运行一个 nginx 容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=my-web nginx:1.20.2</span><br></pre></td></tr></table></figure><p>2、将容器数据复制到 Host</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker cp my-web:/etc/nginx/nginx.conf .</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这样就将nginx容器的配置文件复制到Host的当前目录下</span></span><br></pre></td></tr></table></figure><p>3、将 Host 的数据复制到容器内部</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在Host上创建一个测试文件</span></span><br><span class="line">touch web.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将创建的文件copy到容器内部</span></span><br><span class="line">docker cp web.conf my-web:/etc/nginx/conf.d/</span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;这样就实现了容器与 Host 间的数据共享了，准确说不叫共享，应该叫做容器和 Host 之间可以互相传输文件或实现 Docker 容器的持久化存储。&#x3D;&#x3D;</p><h3 id="1-2-容器间共享"><a href="#1-2-容器间共享" class="headerlink" title="1.2 容器间共享"></a>1.2 容器间共享</h3><h4 id="1-2-1-bind-mount"><a href="#1-2-1-bind-mount" class="headerlink" title="1.2.1 bind mount"></a>1.2.1 bind mount</h4><p>这种共享方式是多个容器共享 Host 上的数据，即将共享数据放在 bind mount 中，然后将其 mount 到多个容器中，我们以 nginx 容器为例进行演示。</p><p>1、创建共享数据（目录或文件）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/web/conf.d</span><br><span class="line">touch /data/web/conf.d/web.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我就以一个目录为共享数据</span></span><br></pre></td></tr></table></figure><p>2、运行 nginx 容器（并将共享数据 mount 到容器中）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=web-1 -v /data/web/conf.d:/etc/nginx/conf.d nginx:1.20.2</span><br><span class="line">docker run -itd --name=web-2 -v /data/web/conf.d:/etc/nginx/conf.d nginx:1.20.2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">运行两个容器，且这两个容器共享同一个Host数据（目录或文件）</span></span><br></pre></td></tr></table></figure><p>3、验证数据是否 mount 到容器中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@shop ~]# docker exec -it web-1 bash</span><br><span class="line">root@5d3c487a409a:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br><span class="line">root@5d3c487a409a:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@shop ~]# docker exec -it web-2 bash</span><br><span class="line">root@fdbb7e98d971:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908115951256.png" alt="image-20220908115951256"></p><p>&#x3D;&#x3D;这样就实现了多个容器共享同个数据。&#x3D;&#x3D;</p><h4 id="1-2-2-volume-container"><a href="#1-2-2-volume-container" class="headerlink" title="1.2.2 volume container"></a>1.2.2 volume container</h4><p>上面是多个容器共享 Host 里面的数据（目录或文件），而这个方式共享则是多个容器共享同个容器中的数据卷（该数据卷类型可以是 bind mount，也可以是 managed volume）。</p><p>1、创建共享容器的数据卷</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/conf.d</span><br><span class="line">touch /root/conf.d/web.conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我就以一个目录为共享数据</span></span><br></pre></td></tr></table></figure><p>2、运行共享容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker create --name=share_data -v /root/conf.d:/etc/nginx/conf.d busybox</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意：提供数据共享的这个容器是可以不需要运行的，因此只需创建即可</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908124543366.png" alt="image-20220908124543366"></p><p>3、其他容器共享刚创建的容器数据卷</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=web-1 --volumes-from share_data nginx:1.20.2</span><br><span class="line">docker run -itd --name=web-2 --volumes-from share_data nginx:1.20.2</span><br></pre></td></tr></table></figure><p>4、验证数据是否被共享</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@shop ~]# docker exec -it web-1 bash</span><br><span class="line">root@5daf7ba565cd:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br><span class="line">root@5daf7ba565cd:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@shop ~]# docker exec -it web-2 bash</span><br><span class="line">root@5510e1b6b4cb:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908124816867.png" alt="image-20220908124816867"></p><p>&#x3D;&#x3D;这有什么好处？其实对于多个容器共享数据（或数据持久化时），在运行容器时不需要指定 Host 的共享目录，而只需指定提供共享数据的容器的容器名即可，这样的话更便于管理。&#x3D;&#x3D;</p><p>还有这样一种场景，如果我需要做容器应用数据迁移（如将容器 web-1 从主机 A 迁移至主机 B），对于以上的数据共享策略来说，还没真正实现数据随容器的迁移而迁移，于是我们可以将数据直接持久化到某个镜像中，这样在做数据迁移的时候就会随镜像的迁移而迁移，而这类方法只适用于数据存储较小或数据改动不是很大容器服务（如配置文件、静态文件等）。要实现这样的功能，就需要我们制作自定义镜像（如 Dockerfile），将数据 copy 到镜像中。</p><p>5、创建 Dockerfile </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/dockerfile &amp;&amp; cd /root/dockerfile</span><br><span class="line">touch web.conf</span><br><span class="line">vim Dockerfile</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908131305346.png" alt="image-20220908131305346"></p><p>6、构建镜像</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t share:v1 .</span><br></pre></td></tr></table></figure><p>7、创建共享容器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker create --name=share_data-1 share:v1</span><br></pre></td></tr></table></figure><p>8、运行 web 容器并进行数据共享</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --name=web-1 --volumes-from share_data-1 nginx:1.20.2</span><br><span class="line">docker run -itd --name=web-2 --volumes-from share_data-1 nginx:1.20.2</span><br></pre></td></tr></table></figure><p>9、验证数据是否被共享</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@shop dockerfile]# docker exec -it web-1 bash</span><br><span class="line">root@34a7c0d48078:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br><span class="line">root@34a7c0d48078:/# exit</span><br><span class="line">exit</span><br><span class="line">[root@shop dockerfile]# docker exec -it web-2 bash</span><br><span class="line">root@d3a5bcf6b10b:/# ls /etc/nginx/conf.d/</span><br><span class="line">web.conf</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220908131129793.png" alt="image-20220908131129793"></p><p>&#x3D;&#x3D;运行的 web 容器能正确读取 共享容器 volume 中数据，我们可看到，创建的共享容器不依赖于 Host 提供的数据，真正实现了 docker 容器服务的迁移即应用，只需要迁移目标提供 docker 环境即可。&#x3D;&#x3D;</p><h2 id="二、小结"><a href="#二、小结" class="headerlink" title="二、小结"></a>二、小结</h2><p>Docker 容器共享可实现容器与 Host 间共享、容器与容器间共享，其中共享 Host 数据的情况用的比较多，容器间共享也有在使用，如一些数据变动较小的容器服务，就可以采用容器间数据共享。</p>]]></content>
    
    
    <summary type="html">有时候你使用 Docker 部署服务，在你的 Linux 系统上你会发现多出来一些进程，那我们如何通过这些进程 ID 来查看是由谁产生的呢？其实很简单，找到它父进程即可。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 容器间通信</title>
    <link href="https://blog.rabcnops.cn/posts/articles/ffa06faa.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/ffa06faa.html</id>
    <published>2023-03-23T04:18:21.000Z</published>
    <updated>2023-03-27T07:34:35.716Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/docker.png" alt="docker"></p><hr><p>这里分两个部分来讲解，分别为：<code>容器间通信</code>和<code>外部（宿主机外的网络）与容器的通信</code>。</p><h2 id="一、容器间通信"><a href="#一、容器间通信" class="headerlink" title="一、容器间通信"></a>一、容器间通信</h2><h3 id="1-1-IP"><a href="#1-1-IP" class="headerlink" title="1.1 IP"></a>1.1 IP</h3><p>通过 IP 的形式来通信。试想一下，两个容器之间是相互隔离的，因此是无法互相 ping 通的，那如果运行的这两个容器使用的是同一个<code>自定义的网络模式</code>，那是否可以连接呢？答案是可以的。我们来实际测试一下。</p><p>前提条件：</p><ul><li>自定义网络名：net_b</li><li>自定义网络IP段：192.168.4.0&#x2F;244</li></ul><p><strong>创建 A 容器：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --name test_a --network=net_b busybox</span><br><span class="line">/ # ifconfig </span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:04:05  </span><br><span class="line">          inet addr:192.168.4.5  Bcast:192.168.4.255  Mask:255.255.255.0</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:9 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:726 (726.0 B)  TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p><strong>创建 B 容器：</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --name test_b --network=net_b busybox</span><br><span class="line">/ # ifconfig </span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:04:06  </span><br><span class="line">          inet addr:192.168.4.6  Bcast:192.168.4.255  Mask:255.255.255.0</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:6 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:516 (516.0 B)  TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p>B 容器 ping A 容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ # ping 192.168.4.5</span><br><span class="line">PING 192.168.4.5 (192.168.4.5): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.5: seq=0 ttl=64 time=0.117 ms</span><br><span class="line">64 bytes from 192.168.4.5: seq=1 ttl=64 time=0.126 ms</span><br><span class="line">64 bytes from 192.168.4.5: seq=2 ttl=64 time=0.125 ms</span><br></pre></td></tr></table></figure><p>A 容器 ping B 容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ # ping 192.168.4.6</span><br><span class="line">PING 192.168.4.6 (192.168.4.6): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.6: seq=0 ttl=64 time=0.177 ms</span><br><span class="line">64 bytes from 192.168.4.6: seq=1 ttl=64 time=0.132 ms</span><br><span class="line">64 bytes from 192.168.4.6: seq=2 ttl=64 time=0.116 ms</span><br></pre></td></tr></table></figure><p>从结果看，A、B 容器可互相 通信。</p><p><strong>创建 C 容器：</strong></p><p>如果该容器为<code>普通 Bridge 网络模式</code>的容器（如：Nginx），那么容器 A 或容器 B 是否能访问 Nginx 容器呢？<code>答案是不能访问</code>。如何解决不可访问的问题？</p><p>如果 Host 上对每个网络都有一条路由，且 Host 打开了路由转发（net.ipv4.ip_forward &#x3D; 1），那不同网桥上的网络就可互相通信。此时，我在 C 容器上加入一块 A、B 容器的虚拟网卡设备，来实现与 A、B 容器的通信。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker network connect net_b nginx</span><br></pre></td></tr></table></figure><p>Nginx 容器里没有查看 IP 地址的命令，可通过 <code>docker inspect nginx</code> 来查看，如下图，Nginx 容器已经分配了 net_b 网络的一个 IP 地址。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182720975.png" alt="image-20221214182720975"></p><p>Nginx 容器的 index.html 我已经提前更改为：hello zhurs 111</p><p>A 容器 ping 一下 C 容器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/ # ping 192.168.4.4</span><br><span class="line">PING 192.168.4.4 (192.168.4.4): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.4: seq=0 ttl=64 time=0.214 ms</span><br><span class="line">64 bytes from 192.168.4.4: seq=1 ttl=64 time=0.129 ms</span><br><span class="line">64 bytes from 192.168.4.4: seq=2 ttl=64 time=0.225 ms</span><br></pre></td></tr></table></figure><p>A 容器访问 C 容器的 Nginx 内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/ # wget 192.168.4.4</span><br><span class="line">Connecting to 192.168.4.4 (192.168.4.4:80)</span><br><span class="line">saving to &#x27;index.html&#x27;</span><br><span class="line">index.html           100% |**************************************************************************************************************************|    16  0:00:00 ETA</span><br><span class="line">&#x27;index.html&#x27; saved</span><br><span class="line">/ # cat index.html </span><br><span class="line">hello zhurs 111</span><br></pre></td></tr></table></figure><p>从结果看，A 容器可正常访问 C 容器的资源。</p><p><strong>小结：</strong></p><ul><li>结论1：同一个<code>自定义网络（&quot;Driver&quot;: &quot;bridge&quot;）</code>下的所有容器可互相通信。</li><li>结论2：<code>自定义网络（&quot;Driver&quot;: &quot;bridge&quot;）</code> 想与<code>普通 Bridge 网络模式</code>进行通信，可在双方任意一方加入对方的网络模式即可。</li></ul><h3 id="1-2-Docker-DNS-Server"><a href="#1-2-Docker-DNS-Server" class="headerlink" title="1.2 Docker DNS Server"></a>1.2 Docker DNS Server</h3><p>上面提到网络驱动 Driver 为 bridge 的自定义网络模式下的容器可通过 IP 进行通信，但在实际应用场景中，IP 可能并不稳定（除非你自定义 IP），因此，我们可以通过<code>容器名</code>的方式进行通信。</p><p>创建容器名为 dns1：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --network=net_b --name=dns1 busybox</span><br></pre></td></tr></table></figure><p>创建容器名为 dns2：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --network=net_b --name=dns2 busybox</span><br><span class="line">/ # ping dns1</span><br><span class="line">PING dns1 (192.168.4.5): 56 data bytes</span><br><span class="line">64 bytes from 192.168.4.5: seq=0 ttl=64 time=0.107 ms</span><br><span class="line">64 bytes from 192.168.4.5: seq=1 ttl=64 time=0.121 ms</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可见，通过域名可正常通信，该通信方式等效于 IP 通信方式，无非就是一个通过 IP 方式，另一个通过容器名的方式。</p><p>但是需要注意，通过容器名通信的前提是：网络模式必须为<code>自定义网络（&quot;Driver&quot;: &quot;bridge&quot;）</code>模式</p><h3 id="1-3-Joined"><a href="#1-3-Joined" class="headerlink" title="1.3 Joined"></a>1.3 Joined</h3><p>这种模式类似 k8s 中 pod 的多容器情况，在 k8s 中，一个 pod 可有一个或多个容器，一般我们多出的那些容器主要起辅助作用，比如一些日志监控等。Docker 的 Joined 通信类型也类似，该模式的作用是：它可使两个或多个容器共享一个网络栈（网卡、配置信息等），因此 Joined 模式下的所有容器可通过 <code>127.0.0.1</code> 直接通信，你可以将他们想象为是一个整体。</p><p><strong>如何实现？</strong></p><blockquote><p>在运行容器时指定要 joined 的目标容器，成功后将共享目标容器的网络栈。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --name=join-test --network=container:nginx busybox</span><br><span class="line">/ # ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">388: eth1@if389: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue </span><br><span class="line">    link/ether 02:42:c0:a8:04:04 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.4.4/24 brd 192.168.4.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">216: eth0@if217: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue </span><br><span class="line">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>查看 IP 信息，完全共享被 joined 目标容器的网络。</p><h2 id="二、容器与外部通信"><a href="#二、容器与外部通信" class="headerlink" title="二、容器与外部通信"></a>二、容器与外部通信</h2><p>其实这是通过 Host 的 iptables 机制来实现的，如下标红的几个示例，当收到 172.19.0.0&#x2F;16 网段的外出包，就把它交给 MASQUERADE 处理，MASQUERADE 则将外出包的源地址转换为 Host 的地址发送出去，实现了网络的 NAT 转换。这也是容器可以与外部通信的原因。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182740504.png" alt="image-20221214182740504"></p><p>容器能与外界通信，那外部是如何与容器内部通信呢？其实道理是一样的，也是通过 NAT 技术，在结合端口映射的方式实现外部与 Host 下的容器通信。</p><h3 id="2-1-动态端口映射"><a href="#2-1-动态端口映射" class="headerlink" title="2.1 动态端口映射"></a>2.1 动态端口映射</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -itd --name=httpd -p 80 httpd</span><br><span class="line">[root@qcloud ~]# docker port httpd</span><br><span class="line">80/tcp -&gt; 0.0.0.0:1024</span><br></pre></td></tr></table></figure><p>该方式会随机生成一个动态端口，且是用于浏览器访问的端口号。</p><h3 id="2-2-静态端口映射"><a href="#2-2-静态端口映射" class="headerlink" title="2.2 静态端口映射"></a>2.2 静态端口映射</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -itd --name=httpd-1 -p 8686:80 httpd</span><br><span class="line">[root@qcloud ~]# docker port httpd-1</span><br><span class="line">80/tcp -&gt; 0.0.0.0:8686</span><br></pre></td></tr></table></figure><p>该方式会指定一个静态端口，且是用于浏览器访问的端口号。静态端口映射用的居多。</p><p><strong>小结：</strong></p><p>没映射一个端口，Host 都会启动一个 docker-proxy 进程来处理访问容器的流量。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182755401.png" alt="image-20221214182755401"></p><hr><p>附件：容器内&#x2F;外通信图解</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/Docker-network.jpg" alt="Docker-network"></p>]]></content>
    
    
    <summary type="html">这里分两个部分来讲解，分别为：容器间通信和外部（宿主机外的网络）与容器的通信。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Linux 环境下 Docker 容器的 PID 变化情况</title>
    <link href="https://blog.rabcnops.cn/posts/articles/377c1d95.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/377c1d95.html</id>
    <published>2023-03-23T04:18:21.000Z</published>
    <updated>2023-03-27T07:33:30.287Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/docker-docs.webp" alt="docker-docs"></p><p>参考1：<a href="https://www.modb.pro/db/100271">https://www.modb.pro/db/100271</a></p><p>参考2：<a href="http://www.asznl.com/post/31">http://www.asznl.com/post/31</a></p><hr><p>有时候你使用 Docker 部署服务，在你的 Linux 系统上你会发现多出来一些进程，那我们如何通过这些进程 ID 来查看是由谁产生的呢？其实很简单，找到它父进程即可。</p><p>首先查看 Docker 服务本身进程 ID：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep dockerd</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221155349700.png" alt="image-20221221155349700"></p><p>可看到其 Dockerd 服务的子进程 ID 为 31803，父进程 ID 为 1。我们知道，Linux 中有<code>pid 0、pid 1 和 pid 2</code> 三个特殊的进程。</p><ul><li>pid 0：即 <code>“swapper”</code> 进程，是 pid 1 和 pid 2 的父进程；</li><li>pid 1：即 <code>“init”</code> 进程，是用户空间所有进程的父进程；</li><li>pid 2，即 <code>“kthreadd”</code> 进程，是内核空间所有进程的父进程。</li></ul><p>继续查看 <code>31803</code> 的进程信息：</p> <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep 31803</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221155615309.png" alt="image-20221221155615309"></p><p>可以看到作为 <code>31803</code> 的父进程产生了很多子进程，其中就包括所有已经创建的容器进程 ID，可看到我们 Jenkins 容器监听的两个端口进程也是来源于 <code>31803</code>，如下图所示：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221152518700.png" alt="image-20221221152518700"></p><p>这里就出现一个问题，不同容器之间是相互隔离的，实际就是对进程的隔离，那这些容器运行的进程又在哪找呢？</p><p>我们先看看 <code>containerd-shim</code> </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef |grep containerd-shim</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221161405255.png" alt="image-20221221161405255"></p><p>继续看看 949 的 PPID 是多少？</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221174525177.png" alt="image-20221221174525177"></p><p>这个时候，我们可以来看看 Docker 的基本架构图。从 Docker 1.11 版本开始，Docker 容器运行就不是简单通过 Docker Daemon 来启动了，而是通过集成 containerd、runc 等多个组件来完成的。虽然 Docker Daemon 守护进程模块在不停的重构，但是基本功能和定位没有太大的变化，一直都是 CS 架构，守护进程负责和 Docker Client 端交互，并管理 Docker 镜像和容器。现在的架构中组件 containerd 就会负责集群节点上容器的生命周期管理，并向上为 Docker Daemon 提供 gRPC 接口。</p><p>参考图1：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221161634949.png" alt="image-20221221161634949"></p><p>参考图2：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221163546886.png" alt="image-20221221163546886"></p><p>可以根据以下概念截图进程树查看：</p><ul><li><code>docker CLI</code> 命令行工具，是给用户和 docker daemon 建立通信的客户端</li><li><code>dockerd</code>: 是 docker 架构中一个常驻在后台的系统进程，称为 docker daemon，dockerd 实际调用的还是 containerd 的 api 接口。有了 containerd 之后，dockerd 可以独立升级，以此避免之前 dockerd 升级会导致所有容器不可用的问题。</li><li><code>containerd</code> 是 dockerd 和 runc 之间的一个中间交流组件，docker 对容器的管理和操作基本都是通过 containerd 完成的。containerd 的主要功能有：容器生命周期管理、日志管理、镜像管理、存储管理、容器网络接口及网络管理</li><li><code>containerd-shim</code> 是一个真实运行容器的载体，每启动一个容器都会起一个新的containerd-shim的一个进程， 它直接通过指定的三个参数：容器id，boundle目录（containerd 对应某个容器生成的目录，一般位于：&#x2F;var&#x2F;run&#x2F;docker&#x2F;libcontainerd&#x2F;containerID，其中包括了容器配置和标准输入、标准输出、标准错误三个管道文件），运行时二进制（默认为runC）来调用 runc 的 api 创建一个容器，上面的 docker 进程图中可以直观的显示。其主要作用是：<ul><li>它允许容器运行时(即 runC)在启动容器之后退出，简单说就是不必为每个容器一直运行一个容器运行时(runC)；</li><li>即使在 containerd 和 dockerd 都挂掉的情况下，容器的标准 IO 和其它的文件描述符也都是可用的；</li><li>向 containerd 报告容器的退出状态；</li><li>有了它就可以在不中断容器运行的情况下升级或重启 dockerd，对于生产环境来说意义重大。</li><li><code>runC</code> 是 Docker 公司按照 OCI 标准规范编写的一个操作容器的命令行工具，其前身是 libcontainer 项目演化而来，runC 实际上就是 libcontainer 配上了一个轻型的客户端，是一个命令行工具端，根据 OCI（开放容器组织）的标准来创建和运行容器，实现了容器启停、资源隔离等功能。</li></ul></li><li><code>docker-proxy</code>: 用来做端口映射的，其底层是默认使用iptables实现。</li></ul><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221181247275.png" alt="image-20221221181247275"></p><p>以上是 docker 19 的架构，但是到了 docker 20 时，结构就有变化了，貌似不再经过 containerd 了。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221173702572.png" alt="image-20221221173702572"></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pstree -p</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221180909732.png" alt="image-20221221180909732"></p><p>和上图对比可看到少了 <code>containerd</code></p><p>通过 <code>docker inspect</code> 查看容器本身的 PID，如下图：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect &lt;容器名&gt;</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221181913969.png" alt="image-20221221181913969"></p><p>通过该 PID 就可以查看容器在 Host 中产生的 PID</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221221182051790.png" alt="image-20221221182051790"></p>]]></content>
    
    
    <summary type="html">有时候你使用 Docker 部署服务，在你的 Linux 系统上你会发现多出来一些进程，那我们如何通过这些进程 ID 来查看是由谁产生的呢？其实很简单，找到它父进程即可。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Ansible 快速入门</title>
    <link href="https://blog.rabcnops.cn/posts/articles/7fbc334.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/7fbc334.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-28T14:33:50.972Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ansible-快速入门"><a href="#Ansible-快速入门" class="headerlink" title="Ansible 快速入门"></a><center>Ansible 快速入门</center></h1><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/timg.jpg" alt="timg"></p><p><a href="https://docs.ansible.com/ansible/latest/">官方文档</a></p><hr><h2 id="一、Ansible-是什么"><a href="#一、Ansible-是什么" class="headerlink" title="一、Ansible 是什么?"></a>一、Ansible 是什么?</h2><p><code>Ansible</code>它是一个 IT 自动化工具。它可以配置系统、部署软件并协调更高级的 IT 任务，例如持续部署或零停机时间滚动更新等。Ansible 的主要目标是简单和易用，它还非常关注安全性和可靠性，具有最少的移动部件，其使用 <code>OpenSSH</code> 进行传输。</p><h2 id="二、Ansible-安装"><a href="#二、Ansible-安装" class="headerlink" title="二、Ansible 安装"></a>二、Ansible 安装</h2><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><h4 id="2-1-1-Python-方式"><a href="#2-1-1-Python-方式" class="headerlink" title="2.1.1 Python 方式"></a>2.1.1 Python 方式</h4><p>1、安装最新版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user ansible</span><br></pre></td></tr></table></figure><p>2、安装指定版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user ansible-core==2.12.3</span><br></pre></td></tr></table></figure><p>3、升级 Ansible</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --upgrade --user ansible</span><br></pre></td></tr></table></figure><p>4、验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible --version</span><br></pre></td></tr></table></figure><p>5、Ansible 的 shell补全</p><ul><li><p>安装 argcomplete</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user argcomplete</span><br></pre></td></tr></table></figure></li><li><p>配置 argcomplete</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">全局配置：要求 bash 4.2</span></span><br><span class="line">activate-global-python-argcomplete</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果您没有 bash 4.2，则必须单独注册每个脚本</span></span><br><span class="line">eval $(register-python-argcomplete ansible)</span><br><span class="line">eval $(register-python-argcomplete ansible-config)</span><br><span class="line">eval $(register-python-argcomplete ansible-console)</span><br><span class="line">eval $(register-python-argcomplete ansible-doc)</span><br><span class="line">eval $(register-python-argcomplete ansible-galaxy)</span><br><span class="line">eval $(register-python-argcomplete ansible-inventory)</span><br><span class="line">eval $(register-python-argcomplete ansible-playbook)</span><br><span class="line">eval $(register-python-argcomplete ansible-pull)</span><br><span class="line">eval $(register-python-argcomplete ansible-vault)</span><br></pre></td></tr></table></figure></li></ul><h4 id="2-1-2-Yum-方式"><a href="#2-1-2-Yum-方式" class="headerlink" title="2.1.2 Yum 方式"></a>2.1.2 Yum 方式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install epel-release</span><br><span class="line">sudo yum install ansible</span><br></pre></td></tr></table></figure><p>其他特定系统安装请看<a href="https://docs.ansible.com/ansible/latest/installation_guide/installation_distros.html">官方文档</a>。</p><h3 id="2-2-配置"><a href="#2-2-配置" class="headerlink" title="2.2 配置"></a>2.2 配置</h3><p>配置文件位于 <code>/etc/ansible</code> 下，Ansible 中的某些设置可通过配置文件 (ansible.cfg) 进行调整。对于大多数用户来说，Inventory 配置已经足够了。</p><h2 id="三、快速入门"><a href="#三、快速入门" class="headerlink" title="三、快速入门"></a>三、快速入门</h2><h3 id="3-1-三组件"><a href="#3-1-三组件" class="headerlink" title="3.1 三组件"></a>3.1 三组件</h3><p>一个基本的 Ansible 环境包含三个主要组件：<code>Control node</code>、<code>Managed node</code>、<code>Inventory</code></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922100244734.png" alt="image-20220922100244734"></p><p><strong>1、Control node</strong></p><p>安装了 Ansible 的系统，安装完成后，可以在控制节点上运行 Ansible 相关命令，例如<code>ansible</code>或<code>ansible-inventory</code>。</p><p><strong>2、Managed node</strong></p><p>Ansible 控制的远程系统或主机，即接下来要说到的 hosts 文件中的主机清单。</p><p><strong>3、Inventory</strong></p><p>逻辑组织的受管节点列表，在控制节点上创建一个清单以向 Ansible 描述主机部署。</p><h3 id="3-2-基础使用"><a href="#3-2-基础使用" class="headerlink" title="3.2 基础使用"></a>3.2 基础使用</h3><blockquote><p>我的 ansible 机器为：192.168.56.132</p></blockquote><p><strong>1、安装 Ansible</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install --user ansible</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或 yum 安装</span></span><br><span class="line">yum install -y ansible</span><br></pre></td></tr></table></figure><p><strong>2、添加主机列表</strong></p><blockquote><p>通过将一个或多个远程系统的 IP 地址或完全限定域名 (FQDN) 添加到<code>/etc/ansible/hosts</code></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[web]</span><br><span class="line">192.168.56.132</span><br><span class="line">192.168.56.180</span><br></pre></td></tr></table></figure><p><strong>3、验证清单中的主机</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible all --list-hosts</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hosts (2):</span><br><span class="line">  192.168.56.132</span><br><span class="line">  192.168.56.180</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922101103515.png" alt="image-20220922101103515"></p><p><strong>3、设置 SSH 连接</strong></p><blockquote><p>将 <code>Control node</code> 主机的 SSH 公密添加到每个远程系统（主机）上的 <code>authorized_keys</code> 文件中，以便 Ansible 可以连接到受管节点。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id 192.168.56.180</span><br></pre></td></tr></table></figure><p>如果控制节点上的用户名在主机上不同，则需要将<code>-u</code>选项与<code>ansible</code>命令一起传递。</p><p><strong>4、Ping 受管节点</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible all -m ping</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">192.168.56.180 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">192.168.56.132 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922101829925.png" alt="image-20220922101829925"></p><h3 id="3-3-创建-Inventory"><a href="#3-3-创建-Inventory" class="headerlink" title="3.3 创建 Inventory"></a>3.3 创建 Inventory</h3><p>Inventory 文件位于 Control node 节点上（即安装 ansible 的主机）。使用清单文件，Ansible 可以通过单个命令管理大量主机，我们也可以直接将受管节点添加到<code>/etc/ansible/hosts</code>文件中，来实现批量主机管理。在 Inventory 文件编写中，其语法格式可以是<code>INI</code>或<code>YAML</code>格式，建立一个 Inventory 的基本步骤如下：</p><ul><li>在您的控制节点上打开一个终端窗口。</li><li>在任何目录中创建一个新的库存文件<code>inventory.yaml</code>并打开它进行编辑。</li><li>为您的主机添加一个新组，然后使用该字段指定每个受管节点的 IP 地址或完全限定域名 (FQDN) <code>ansible_host</code>。</li></ul><p><strong>1、创建名为 inventory.yaml 的 Inventory</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat inventory.yaml</span><br><span class="line"></span><br><span class="line">mywebhost:</span><br><span class="line">  hosts:</span><br><span class="line">    vm01:</span><br><span class="line">      ansible_host: 192.168.56.132</span><br><span class="line">    vm02:</span><br><span class="line">      ansible_host: 192.168.56.180</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">说明：mywebhost 为组名</span></span><br></pre></td></tr></table></figure><p><strong>2、验证 Inventory</strong></p><blockquote><p>如果你在主目录以外的目录中创建了清单，请使用该<code>-i</code>选项指定完整路径。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-inventory -i inventory.yaml --list</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922104607536.png" alt="image-20220922104607536"></p><p><strong>2、ping 清单中的受管节点</strong></p><blockquote><p>在此示例中，组名称是<code>mywebhost</code>，此时可以使用<code>ansible</code>命令。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible mywebhost -m ping -i inventory.yaml</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vm01 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">vm02 | SUCCESS =&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922104904636.png" alt="image-20220922104904636"></p><p><mark>注意 Inventory 与 hosts 文件的区别：</mark></p><p>Ansible 的主机清单是 Inventory，我们可以通过创建 <code>*.yaml</code> 文件来作为我们的主机清单（Inventory）文件，如果你没有创建这个 yaml 文件，那 Ansible 的默认主机清单文件就是 hosts，这个文件在安装 Ansible 时默认存在 的。当找不到 *.yaml 主机清单文件时，就会去找 hosts 文件。</p><p>由于 hosts 文件是默认的主机清单文件，如果你想使用你自定义的其他主机清单文件，需通过 <code>-i</code> 参数指定，如 <code>ansible mywebhost -m ping -i inventory.yaml</code>，否则它会默认去找 hosts 文件。</p><h3 id="3-4-创建-playbook"><a href="#3-4-创建-playbook" class="headerlink" title="3.4 创建 playbook"></a>3.4 创建 playbook</h3><p><code>YAML</code>剧本是 Ansible 用于部署和配置托管节点的自动化蓝图。看看几个重要元素：</p><ul><li><p><strong>Playbook</strong></p><p>定义 Ansible 从上到下执行操作以实现总体目标的顺序的剧本列表。</p></li><li><p><strong>Play</strong></p><p>映射到清单中的受管节点的有序任务列表。</p></li><li><p><strong>Task</strong></p><p>定义 Ansible 执行的操作的一个或多个模块的列表。</p></li><li><p><strong>Module</strong></p><p>Ansible 在托管节点上运行的代码或二进制单元。</p></li></ul><p><mark>创建一个 playbook 的步骤如下：</mark></p><ul><li><p>在控制节点上打开一个终端窗口。</p></li><li><p>在任何目录中创建一个新的 playbook 文件<code>playbook.yaml</code>并打开它进行编辑。</p></li></ul><p><strong>1、创建 playbook</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">playbook.yaml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">My</span> <span class="string">first</span> <span class="string">play</span></span><br><span class="line">  <span class="attr">hosts:</span> <span class="string">mywebhost</span></span><br><span class="line">  <span class="attr">tasks:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Ping</span> <span class="string">my</span> <span class="string">hosts</span></span><br><span class="line">     <span class="attr">ansible.builtin.ping:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Print</span> <span class="string">message</span></span><br><span class="line">     <span class="attr">ansible.builtin.debug:</span></span><br><span class="line">       <span class="attr">msg:</span> <span class="string">Hello</span> <span class="string">world</span></span><br><span class="line">       </span><br><span class="line"><span class="comment"># 可看到我的主机清单指定的是mywebhost组，而这个组是在我自定义的Inventory文件中定义的</span></span><br><span class="line"><span class="comment"># 因此我在运行playbook时需要-i指定自定义的Inventory文件，如果不指定，ansible就回去找默认的hosts文件，而这个文件中根本没有mywebhost这个组名，所以会报错。</span></span><br></pre></td></tr></table></figure><p><strong>2、运行 playbook</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">ansible-playbook</span> <span class="string">-i</span> <span class="string">inventory.yaml</span> <span class="string">playbook.yaml</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220922112600610.png" alt="image-20220922112600610"></p><p><mark>剧本的执行过程：</mark></p><ul><li>任务隐式运行。默认情况下，Ansible 会收集可以在 playbook 中使用的库存信息（Inventory），<code>Gather Facts</code>。</li><li>每个任务的状态。每个任务都有一个状态，<code>ok</code>这意味着它运行成功。</li><li>对每个主机的剧本中所有任务的结果进行总结的剧本回顾。在此示例中，共有三个任务，因此<code>ok=3</code>表明每个任务都运行成功。</li></ul>]]></content>
    
    
    <summary type="html">Ansible 快速入门。</summary>
    
    
    
    <category term="自动化运维" scheme="https://blog.rabcnops.cn/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/"/>
    
    <category term="Ansible" scheme="https://blog.rabcnops.cn/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/Ansible/"/>
    
    
    <category term="Ansible" scheme="https://blog.rabcnops.cn/tags/Ansible/"/>
    
    <category term="Linux" scheme="https://blog.rabcnops.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Docker Swarm NFS 数据持久化存储</title>
    <link href="https://blog.rabcnops.cn/posts/articles/2499c9dc.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/2499c9dc.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T09:19:40.592Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/mydockerswarm.png" alt="mydockerswarm"></p><hr><h2 id="一、Swarm-集群部署"><a href="#一、Swarm-集群部署" class="headerlink" title="一、Swarm 集群部署"></a>一、Swarm 集群部署</h2><p>可参考我前面的博客<a href="https://blog.csdn.net/IT_ZRS/article/details/126106608?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167341759716800222849511%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=167341759716800222849511&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-126106608-null-null.blog_rank_default&utm_term=swarm&spm=1018.2226.3001.4450">《基于 Linux 的 Docker Swarm 集群部署及应用》</a>。</p><p><strong>本次实验：</strong></p><ul><li><strong>master</strong>：192.168.56.142</li><li><strong>work1</strong>：192.168.56.132</li><li><strong>work2</strong>：192.168.56.180</li></ul><h2 id="二、NFS-服务部署"><a href="#二、NFS-服务部署" class="headerlink" title="二、NFS 服务部署"></a>二、NFS 服务部署</h2><p>可参考我前面的博客<a href="https://blog.csdn.net/IT_ZRS/article/details/109248320?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167341767316800182198924%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=167341767316800182198924&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-109248320-null-null.blog_rank_default&utm_term=NFS&spm=1018.2226.3001.4450">《构建NFS-FTP文件共享存储》</a>。</p><p><strong>本次实验：</strong></p><ul><li><strong>NFS IP</strong>：192.168.56.141</li><li><strong>Shared Dir</strong>：&#x2F;data&#x2F;sharedir</li></ul><h2 id="三、Swarm-使用-NFS"><a href="#三、Swarm-使用-NFS" class="headerlink" title="三、Swarm 使用 NFS"></a>三、Swarm 使用 NFS</h2><blockquote><p>参考1：<a href="https://blog.dahanne.net/2017/11/20/docker-swarm-and-nfs-volumes/">https://blog.dahanne.net/2017/11/20/docker-swarm-and-nfs-volumes/</a></p><p>参考2：<a href="https://blog.csdn.net/lms99251/article/details/108702547">https://blog.csdn.net/lms99251/article/details/108702547</a></p><p>参考3：<a href="https://www.jianshu.com/p/38e1c81af9bd">https://www.jianshu.com/p/38e1c81af9bd</a></p></blockquote><h3 id="3-1-通过-Volume"><a href="#3-1-通过-Volume" class="headerlink" title="3.1 通过 Volume"></a>3.1 通过 Volume</h3><h4 id="3-1-1-创建-Volume"><a href="#3-1-1-创建-Volume" class="headerlink" title="3.1.1 创建 Volume"></a>3.1.1 创建 Volume</h4><p><strong>1、创建 Docker Volume</strong></p><blockquote><p>每个 swarm 节点均创建相同名称的 Docker Volume（名称为 nfsdata）</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker volume create --driver <span class="built_in">local</span> \</span><br><span class="line">  --opt <span class="built_in">type</span>=nfs \</span><br><span class="line">  --opt o=addr=192.168.56.141,rw \</span><br><span class="line">  --opt device=:/data/sharedir \</span><br><span class="line">  nfsdata</span><br></pre></td></tr></table></figure><p><strong>2、查看 Volume 是否创建成功</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker volume <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># swarm集群节点依次进行验证</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111144019356.png" alt="image-20230111144019356"></p><p><strong>3、查看 Volume 详情</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume inspect nfsdata</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111144430328.png" alt="image-20230111144430328"></p><blockquote><p>其中：<code>Mountpoint</code> 为 Host 挂载点，<code>Options</code> 为 NFS 服务共享目录信息。</p></blockquote><h4 id="3-1-2-使用-Volume"><a href="#3-1-2-使用-Volume" class="headerlink" title="3.1.2 使用 Volume"></a>3.1.2 使用 Volume</h4><p>1、在 docker swarm 的 master 节点执行创建服务操作</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker service create \</span><br><span class="line">  --name nginx-nfs-test \</span><br><span class="line">  --publish 1180:80 \</span><br><span class="line">  --mount <span class="built_in">type</span>=volume,<span class="built_in">source</span>=nfsdata,destination=/data/web \</span><br><span class="line">  --replicas 3 \</span><br><span class="line">  nginx:1.20.2</span><br></pre></td></tr></table></figure><p>2、查看 Service 部署情况</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111145635747.png" alt="image-20230111145635747"></p><h4 id="3-1-3-验证数据共享特性"><a href="#3-1-3-验证数据共享特性" class="headerlink" title="3.1.3 验证数据共享特性"></a>3.1.3 验证数据共享特性</h4><p><strong>1、NFS 服务创建测试数据</strong></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111150058510.png" alt="image-20230111150058510"></p><p><strong>2、Service 验证是否共享 NFS 数据</strong></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111150309868.png" alt="image-20230111150309868"></p><p>可见，数据被共享了，当然，你在容器中 <code>/data/web</code> 目录下产生的数据也会被持久化到 NFS 服务上。</p><blockquote><p>当然，Nginx 也是正常运行的</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111151444719.png" alt="image-20230111151444719"></p><h3 id="3-2-通过-Docker-Stack"><a href="#3-2-通过-Docker-Stack" class="headerlink" title="3.2 通过 Docker Stack"></a>3.2 通过 Docker Stack</h3><blockquote><p><a href="https://docs.docker.com/engine/reference/commandline/stack/">Docker Stack CLI</a></p></blockquote><p>通过 Volume 方式，你会发现每台 swarm 集群 work 节点都需要创建 Volume（如果 master 节点也为 work 节点，也要创建 Volume ）。稍显麻烦，我们可通过 Docker Stack 方式来弥补这点不足，也就是使用 Docker Stack 方式时，就不需要手动创建 Docker Volume 了。</p><h4 id="3-2-1-创建-YAML-文件"><a href="#3-2-1-创建-YAML-文件" class="headerlink" title="3.2.1 创建 YAML 文件"></a>3.2.1 创建 YAML 文件</h4><blockquote><p>参考1：<a href="https://docs.docker.com/engine/reference/commandline/compose/">docker compose CLI</a></p><p>参考2：<a href="https://zhuanlan.zhihu.com/p/387840381">docker compose 配置文件主要配置</a></p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim nginx-compose.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下配置文件会创建一个名为myweb_nginx-nfs-test-1的service</span></span><br><span class="line"><span class="comment"># service命名规则：stack名_service名</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">&quot;3&quot;</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  nginx-nfs-test-1:</span><br><span class="line">    image: nginx:1.20.2</span><br><span class="line">    deploy:</span><br><span class="line">      mode: replicated</span><br><span class="line">      replicas: 3</span><br><span class="line">      restart_policy:</span><br><span class="line">        condition: on-failure</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;1181:80&quot;</span></span><br><span class="line">    networks:</span><br><span class="line">      my-overlay-network:</span><br><span class="line">        aliases:</span><br><span class="line">          - nginx-test-net</span><br><span class="line">    volumes:</span><br><span class="line">      - <span class="string">&quot;mountdata:/data/web&quot;</span></span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  mountdata:</span><br><span class="line">    driver: <span class="built_in">local</span></span><br><span class="line">    driver_opts:</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">&quot;nfs&quot;</span></span><br><span class="line">      o: <span class="string">&quot;addr=192.168.56.141,rw&quot;</span></span><br><span class="line">      device: <span class="string">&quot;:/data/sharedir&quot;</span></span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  my-overlay-network:</span><br><span class="line">    driver: overlay</span><br></pre></td></tr></table></figure><p>如果你需要在指定的 Node 节点上运行 Service，可在配置文件中进行指定 Node 节点名（新增 placement 字段）。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">&quot;3&quot;</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  nginx-nfs-test-1:</span><br><span class="line">    image: nginx:1.20.2</span><br><span class="line">    deploy:</span><br><span class="line">      placement:</span><br><span class="line">        constraints:</span><br><span class="line">          - <span class="string">&quot;node.hostname==harbor-nexus&quot;</span></span><br><span class="line">      mode: replicated</span><br><span class="line">      replicas: 3</span><br><span class="line">      restart_policy:</span><br><span class="line">        condition: on-failure</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><blockquote><p>除了可指定节点名外，还可以指定节点 ID、标签等。</p></blockquote><h4 id="3-2-2-使用-YAML-文件"><a href="#3-2-2-使用-YAML-文件" class="headerlink" title="3.2.2 使用 YAML 文件"></a>3.2.2 使用 YAML 文件</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker stack deploy -c nginx-compose.yml myweb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个名为myweb的stack</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111155010050.png" alt="image-20230111155010050"></p><blockquote><p>查看 Service 所在集群节点</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111155249105.png" alt="image-20230111155249105"></p><h4 id="3-2-3-验证数据共享特性"><a href="#3-2-3-验证数据共享特性" class="headerlink" title="3.2.3 验证数据共享特性"></a>3.2.3 验证数据共享特性</h4><p>我在 <code>3.1</code> 小节中已经向 NFS 添加过测试数据了，现在来验证容器内部有没有测试数据。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it myweb_nginx-nfs-test-1.2.dahr1c6am279qgnhf2910449c bash</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20230111155733010.png" alt="image-20230111155733010"></p><p><strong>可见，数据已经同步到 swarm service 容器内部。</strong></p><p><mark>至此，Docker Swarm 的数据持久化问题已经解决。当然，除了 NFS 共享存储外，还有 Ceph、ClusterFS 等存储也能实现。实际生产中大家自行修改使用即可。</mark></p><p><strong>这里你有没有考虑过一个问题：当我们有多个模块的时候，NFS 的共享存储目录要怎么规划呢？</strong></p><p>其实很简单，每个模块依次添加即可，如下案例（假设有 web、center 两个模块）：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">&quot;3&quot;</span></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    image: nginx:1.20.2</span><br><span class="line">    deploy:</span><br><span class="line">      mode: replicated</span><br><span class="line">      replicas: 3</span><br><span class="line">      restart_policy:</span><br><span class="line">        condition: on-failure</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;1080:80&quot;</span></span><br><span class="line">    networks:</span><br><span class="line">      web-net:</span><br><span class="line">        aliases:</span><br><span class="line">          - web-net-test</span><br><span class="line">    volumes:</span><br><span class="line">      - <span class="string">&quot;mywebdata:/data/web&quot;</span></span><br><span class="line">  center:</span><br><span class="line">    image: center:1.20.2</span><br><span class="line">    deploy:</span><br><span class="line">      mode: replicated</span><br><span class="line">      replicas: 3</span><br><span class="line">      restart_policy:</span><br><span class="line">        condition: on-failure</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">&quot;8181:8080&quot;</span></span><br><span class="line">    networks:</span><br><span class="line">      web-net:</span><br><span class="line">        aliases:</span><br><span class="line">          - web-net-test</span><br><span class="line">    volumes:</span><br><span class="line">      - <span class="string">&quot;mycenterdata:/data/center&quot;</span></span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  mywebdata:</span><br><span class="line">    driver: <span class="built_in">local</span></span><br><span class="line">    driver_opts:</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">&quot;nfs&quot;</span></span><br><span class="line">      o: <span class="string">&quot;addr=192.168.56.141,rw&quot;</span></span><br><span class="line">      device: <span class="string">&quot;:/data/sharedir/web&quot;</span></span><br><span class="line">  mycenterdata:</span><br><span class="line">    driver: <span class="built_in">local</span></span><br><span class="line">    driver_opts:</span><br><span class="line">      <span class="built_in">type</span>: <span class="string">&quot;nfs&quot;</span></span><br><span class="line">      o: <span class="string">&quot;addr=192.168.56.141,rw&quot;</span></span><br><span class="line">      device: <span class="string">&quot;:/data/sharedir/center&quot;</span></span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  web-net:</span><br><span class="line">    driver: overlay</span><br></pre></td></tr></table></figure><blockquote><p>注意：要在 NFS 共享目录 &#x2F;data&#x2F;sharedir&#x2F; 下创建对应的目录<br>如：mkdir &#x2F;data&#x2F;sharedir&#x2F;{web,center}<br>之后，容器产生的数据将会存储于对应的目录下。</p></blockquote><hr>]]></content>
    
    
    <summary type="html">Docker Swarm NFS 数据持久化存储。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
    <category term="Docker_Swarm" scheme="https://blog.rabcnops.cn/tags/Docker-Swarm/"/>
    
  </entry>
  
  <entry>
    <title>Docker 应用架构</title>
    <link href="https://blog.rabcnops.cn/posts/articles/ff3ea403.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/ff3ea403.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:35:03.808Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/docker-ct.jpg" alt="docker-ct"></p><p><font color=Brown><strong>Author</strong>：rab</font></p><hr><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Docker 采用 C&#x2F;S 网络应用模型，其核心组件包括：Docker 客户端（Client）、Docker 服务端（Docker Daemon）、Docker 镜像（Image）、Docker 仓库（Registry）及 Docker 容器（Container）。接下来通过架构图，详细说明一下 Docker 架构组件的功能及作用。</p><h2 id="一、架构"><a href="#一、架构" class="headerlink" title="一、架构"></a>一、架构</h2><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/Docker-cs.jpg" alt="Docker-cs"></p><p>&#x3D;&#x3D;流程&#x3D;&#x3D;：Docker 客户端（Client）向 Docker 服务端（Docker Daemon）发起请求（如 docker pull&#x2F;run&#x2F;build … 等），Docker 服务端（Docker Daemon）收到请求后就会做出响应。假如是一个 pull 请求，那 Docker 服务端（Docker Daemon）就会向 Docker 仓库（Registry）拉取指定的镜像至 Host 本地进行存储，最后再根据 Docker 客户端（Client）的请求决定是否运行容器或做其他请求操作。</p><h2 id="二、组件"><a href="#二、组件" class="headerlink" title="二、组件"></a>二、组件</h2><h3 id="2-1-客户端（Client）"><a href="#2-1-客户端（Client）" class="headerlink" title="2.1 客户端（Client）"></a>2.1 客户端（Client）</h3><p><code>Docker 客户端（Client）</code>，即 Docker 的客户端管理命令（如上图所示），Docker 客户端（Client） 可以与 Docker 服务端（Daemon）处于同个 Host 下，也可以分开（然后可通过 socket&#x2F;RESET API 进行交互）。Docker 客户端（Client）向 Docker 服务端（Daemon）发起请求，然后 Docker 服务端（Daemon）负责构建、运行和分发容器。</p><h3 id="2-2-服务端（Daemon）"><a href="#2-2-服务端（Daemon）" class="headerlink" title="2.2 服务端（Daemon）"></a>2.2 服务端（Daemon）</h3><p><code>Docker 服务端（Daemon）</code>，即以 Linux 后台服务方式运行的服务器组件，作为服务端，其为 Docker 客户端（Client）的相关请求提供服务和响应，并为客户端的请求负责创建、运行容器，及镜像构建与存储等。下图为后台运行的状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl status docker.service</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220906111549565.png" alt="image-20220906111549565"></p><p>Docker 服务端（Daemon）只能响应本地 Host 的 Docker 客户端（Client）请求，如果需要运行远程客户端的请求，需要启用 TCP 监听服务，具体步骤如下：</p><p><strong>1、修改 Docker 配置文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/systemd/system/multi-user.target.wants/docker.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">追加 -H tcp://0.0.0.0</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220906111859229.png" alt="image-20220906111859229"></p><p><strong>2、重启 Docker 服务端（Daemon）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker.service</span><br></pre></td></tr></table></figure><p><strong>3、远程请求 Docker 服务端（Daemon）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker -H 10.150.16.95 info</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">10.150.16.95：远程Docker服务端（Daemon）的IP地址</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220906112508384.png" alt="image-20220906112508384"></p><h3 id="2-3-镜像（Image）"><a href="#2-3-镜像（Image）" class="headerlink" title="2.3 镜像（Image）"></a>2.3 镜像（Image）</h3><p>在前面的博文已经提到，Image 是一种分层结构的只读镜像，它可通过服务端运行（run）为容器。而什么是镜像呢？又如何创建镜像呢？我们说，镜像是容器的基础。首先要了解镜像就先要了解一个概念——<code>base 镜像</code>，我们的任何镜像都是基于一个基础（base）镜像构建而成的。</p><p>而什么又是基础镜像呢？你需要明确基础镜像的两个特点：</p><ul><li>基础镜像不依赖于其他镜像，也即是说它是镜像的基本单元；</li><li>其他镜像就可以以基础镜像为基准进行构建。</li></ul><p>那这些（基础）镜像又存储于什么位置呢？一般我们可以通过创建自己的私有 docker 镜像仓库（如 Harbor）或直接使用官方的镜像仓库来实现基础镜像及其他镜像的存储，这就是接下来即将说到的 docker 仓库（Registry）。关于如何拉取 docker 仓库（Registry）中的镜像或其他镜像管理指令，大家可以自行看官方文档，这里不作为重点。</p><p>如下图就是从镜像仓库中拉取下来的镜像：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220906114947026.png" alt="image-20220906114947026"></p><p>&#x3D;&#x3D;那问题来了：既然镜像只读，那我其他镜像又是如何基于某个基础镜像来进行构建的呢？&#x3D;&#x3D;</p><p>关于这个问题我也已经做了总结，大家可以看看我前面的文章<a href="https://blog.csdn.net/IT_ZRS/article/details/124692778?spm=1001.2014.3001.5501">《Docker 的 Copy-on-Write 特性》</a></p><h3 id="2-4-仓库（Registry）"><a href="#2-4-仓库（Registry）" class="headerlink" title="2.4 仓库（Registry）"></a>2.4 仓库（Registry）</h3><p>在镜像一节中我们说了，仓库（Registry）就是用来存放镜像（Image）的，它分为私有镜像仓库和公有镜像仓库，所谓的私有镜像仓库就是你个人或你们公司内部搭建的镜像仓库（如 Harbor），只有你个人或你公司内部相关技术人员可使用。而公有镜像仓库默认是 Docker Hub，由 Docker 公司进行维护，该镜像仓库所有人都可进行下载使用。</p><p>关于如何部署一个私有 Docker 镜像仓库，大家可以参考我这篇部署文档<a href="https://blog.csdn.net/IT_ZRS/article/details/121585898?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166244634216800180625588%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=166244634216800180625588&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-121585898-null-null.nonecase&utm_term=harbor&spm=1018.2226.3001.4450">《Harbor 私有镜像仓库部署》</a></p><h3 id="2-5-容器（Container）"><a href="#2-5-容器（Container）" class="headerlink" title="2.5 容器（Container）"></a>2.5 容器（Container）</h3><p>有了以上的基础后，紧接着就是通过镜像（Image）来运行一个容器实例了，用户可通过 Docker 客户端工具来运行、停止、删除容器了。如下图就是运行中的一个 Nginx 容器实例：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220906110737069.png" alt="image-20220906110737069"></p><p><mark>以上就是 Docker 的基础架构及各组件的功能介绍。</mark></p>]]></content>
    
    
    <summary type="html">Docker 应用架构（C/S架构）。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 容器镜像制作</title>
    <link href="https://blog.rabcnops.cn/posts/articles/550cc753.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/550cc753.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:36:00.737Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、镜像制作"><a href="#一、镜像制作" class="headerlink" title="一、镜像制作"></a>一、镜像制作</h2><h3 id="方式1"><a href="#方式1" class="headerlink" title="方式1"></a>方式1</h3><p>通过命令行的交互式方式来生成新镜像，而且是基于运行的容器来制作的新镜像。</p><blockquote><p>语法：docker commit &lt;正在运行的容器名&gt; &lt;自定义新的镜像名:冒号后面为指定镜像版本&gt;</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker ps</span><br><span class="line">CONTAINER ID   IMAGE             COMMAND                  CREATED          STATUS          PORTS                                      NAMES</span><br><span class="line">a4cd671837dd   centos7.9:v1      &quot;/bin/bash&quot;              5 minutes ago    Up 5 minutes                                               ctos-1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将正在运行的ctos-1容器提交为新的镜像</span></span><br><span class="line">[root@qcloud ~]# docker commit ctos-1 centos7.9:v1</span><br></pre></td></tr></table></figure><h3 id="方式2"><a href="#方式2" class="headerlink" title="方式2"></a>方式2</h3><p>第二种方法就是通过 Dockerfile 文件进行镜像构建。实际上就是第一种方法 docker commit xx 指令的集合写在了 Dockerfile 文本中。</p><blockquote><p>语法1：docker build -t &lt;自定义新镜像名&gt; .<br>语法2：docker -f &#x2F;root&#x2F;Dockerfile build -t &lt;自定义新镜像名&gt; .</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker build -t centos7.9:v2 .</span><br><span class="line"></span><br><span class="line">docker build -f /opt/Dockerfile -t centos7.9:v2 .</span><br></pre></td></tr></table></figure><p>在 Dockerfile 文件里的每一个命令都会生成一个镜像，如 RUN yum install -y vim，docker 会生成一个临时镜像来进行相关写操作（其实就是我们提到镜像顶层的<code>容器层</code>），当该写操作执行完成后 Docker 就会 remove 掉这个临时镜像，并类似 docker commit xxx 生成一个新镜像层。</p><h2 id="二、镜像缓存"><a href="#二、镜像缓存" class="headerlink" title="二、镜像缓存"></a>二、镜像缓存</h2><p>Docker 具备镜像缓存功能，也就是说 Docker 会缓存已存在的镜像（我们知道 Dockerfile 里面的每条指令都会生成一层层镜像，这每一层镜像都会被容器引擎 Docker 给缓存下来），当我们通过 Dockerfile 生成新镜像的时候，如果 Dockerfile 里面的语句（如：RUN yum install -y vim）和 Docker 镜像缓存中一致时，则直接使用缓存镜像，大大提高了镜像构建速度，但是有一个前提，就是新构建的镜像的基础镜像需和 Docker 缓存的镜像的基础镜像属于同一镜像才行。</p><p>举个例子：<br>基础镜像：p<br>基础镜像：u</p><p>新镜像1：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM P</span><br><span class="line">RUN yum install -y vim</span><br></pre></td></tr></table></figure><p>新镜像2：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM p</span><br><span class="line">RUN yum install -y vim</span><br><span class="line">RUN touch /opt/docker.txt</span><br></pre></td></tr></table></figure><p>新镜像3：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM u</span><br><span class="line">RUN yum install -y vim</span><br></pre></td></tr></table></figure><p>构建顺序：新镜像1 ——&gt; 新镜像2 ——&gt; 新镜像3</p><p>是否使用到镜像缓存？</p><ul><li>镜像2：<br>新镜像2 使用到了镜像1的缓存，因为他们的 Dockerfile 都是同一个基础镜像，而且在该基础镜像上，他们都使用了相同的 <code>RUN yum install -y vim（即同个镜像）</code>，此时镜像2 就会直接使用镜像1 的缓存（即省略了安装 vim 的步骤），加快了镜像的构建。</li><li>镜像3：<br>但是镜像3 没有使用到镜像1 或者镜像2 的缓存，因为他们 Dockerfile 文件的基础镜像不同。</li></ul><p>但是有一个问题，如果镜像1、镜像2的 Dockerfile 文件的指令顺序发生变化，那镜像缓存就不会生效，具体如下：</p><p>对上述镜像2的 Dockerfile 的指令顺序做如下修改：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM p</span><br><span class="line">RUN touch /opt/docker.txt</span><br><span class="line">RUN yum install -y vim</span><br></pre></td></tr></table></figure><p>此时的 Dockerfile 构建的镜像是不会使用到镜像1的缓存的，尽管镜像1和镜像2的基础镜像是一样的，但是镜像2的 Dockerfile 的指令顺序与镜像1的 Dockerfile 指令顺序不一样，所以不会引用镜像1的镜像缓存。尽管内容没发生变化，仅仅顺序发生变化，但是由于 Docker 分层结构特性，Docker 必须重建受影响的镜像。</p><p>查看镜像构建的过程：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker history centos7.9:v2</span><br><span class="line">IMAGE          CREATED             CREATED BY                                      SIZE      COMMENT</span><br><span class="line">9f16f2ab2cbc   About an hour ago   /bin/sh -c yum install -y vim &amp;&amp; touch /opt/…   221MB     </span><br><span class="line">eeb6ee3f44bd   7 months ago        /bin/sh -c #(nop)  CMD [&quot;/bin/bash&quot;]            0B        </span><br><span class="line">&lt;missing&gt;      7 months ago        /bin/sh -c #(nop)  LABEL org.label-schema.sc…   0B        </span><br><span class="line">&lt;missing&gt;      7 months ago        /bin/sh -c #(nop) ADD file:b3ebbe8bd304723d4…   204MB </span><br></pre></td></tr></table></figure><p>如果不想使用缓存功能，可以在镜像构建时添加 –no-cache</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build --no-cache -t centos7.2:v3 .</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Docker 容器镜像制作。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 的 Copy-on-Write 特性</title>
    <link href="https://blog.rabcnops.cn/posts/articles/1fb9a4a3.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/1fb9a4a3.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T09:21:19.371Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、疑问"><a href="#一、疑问" class="headerlink" title="一、疑问"></a>一、疑问</h2><p>一个基础镜像可以运行一个容器，那可不可以一个基础镜像运行多个容器呢？答案是可以的。</p><p>那如果一个基础镜像运行多个容器后，我在某个容器上修改了基础镜像的内容，如：删除 &#x2F;etc&#x2F;hello.conf（假设我的基础镜像是有 hello.conf 文件的）文件，是否共用我基础镜像的其他容器的 &#x2F;etc&#x2F;hello.conf 文件也被删除了呢？答案是不会的。</p><h2 id="二、解答"><a href="#二、解答" class="headerlink" title="二、解答"></a>二、解答</h2><p>上面的问题其实应用到了 Docker 的 <code>Copy-on-Write</code> 特性，我们来看看这是怎么回事呢？</p><p>当某个容器启动时，一个新的可写层会被加载到其基础镜像的顶部，我们称之为“容器层”，所有添加、删除均发生在“容器层之中”。“容器层”之下的均为镜像层，最底部的镜像又称“基础镜像”层。</p><p>当在容器中进行数据修改时（比如修改 &#x2F;etc&#x2F;hello.conf 文件），Dockers 会从上至下依次在各个镜像层中查找此文件，一旦找到该文件，会立即将其复制到“容器层”，然后再进行修改操作（也就是 <code>Copy-on-Write</code>），其他的操作也是一样（如添加、读取、删除等操作）。<code>因此，“容器层”保存的是镜像变化的部分，而不会对镜像本身进行任何修改。</code></p>]]></content>
    
    
    <summary type="html">Docker 的 Copy-on-Write 特性。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 底层技术</title>
    <link href="https://blog.rabcnops.cn/posts/articles/3afbe0a6.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/3afbe0a6.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:36:12.267Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Cgroup"><a href="#一、Cgroup" class="headerlink" title="一、Cgroup"></a>一、Cgroup</h2><p>cgroup（Control Group），它用于 linux 系统资源分配、限制，前面提到的 Docker 资源分配与限制就是使用的 linux 底层技术来实现。</p><ul><li><p>CPU：&#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;docker</p></li><li><p>内存：&#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory&#x2F;docker</p></li><li><p>磁盘 IO：&#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;blkio&#x2F;docker</p></li></ul><p>当运行一个容器时，linux系统（宿主机）就会为这个容器创建一个 cgroup 目录，并以容器长 ID 命名，如下图：</p><p><img src="https://note.youdao.com/yws/res/16889/WEBRESOURCE25d35d64d34541c81435100fef10d9b5" alt="image"></p><p>该长 ID 目录下就有一个 cpu.shares 文件，其值为默认值或是你在运行容器时指定的值，如下图：</p><p><img src="https://note.youdao.com/yws/res/16888/WEBRESOURCE67b6b3c07f78727bfdebf529db1f53d0" alt="image"></p><p>内存、磁盘 IO 类似。</p><h2 id="二、Namespace"><a href="#二、Namespace" class="headerlink" title="二、Namespace"></a>二、Namespace</h2><p>抛开宿主机后，你会发现每个容器都已自己独立的一套完整资源，如网卡设备、文件系统等，而实现这一技术的正是 <code>namespace</code>，namespace 管理 Host 中全局唯一资源，并可以让每个容器都觉得只有自己在使用它。其实也就是 namespace 实现了容器间资源的隔离。你也可以类比 k8s 的 namespace，在 k8s 中，namespace 可实现权限划分、资源访问等。</p><p>Linux 使用了 6 种 namespace，分别是：Mount、UTS、IPC、PID、Network 和 User。</p><p><strong>1、Mount</strong></p><p>该 namespace 可让容器拥有自己独立的文件系统，比如容器有自己的 &#x2F; 目录，可实现相关的挂载操作（当然这些操作并不会影响我们的宿主机及其他容器）</p><p><strong>2、UTS</strong></p><p>该 namespace 可让容器拥有自己独立的 hostname，比如我们在运行容器时通过 -h 指定 hostname。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -h rab ...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">其中rab就是该容器的主机名</span></span><br></pre></td></tr></table></figure><p><strong>3、IPC</strong></p><p>该 namespace 让容器拥有自己的共享内存和信号量，来实现进程间的通信，而不会与宿主机（Host）及其他容器混在一起。</p><p><strong>4、PID</strong></p><p>该 namespace 让容器拥有自己独立一套的 PID，每个容器都是以进程的形式在宿主机（Host）中运行，如图下运行了三个容器及其在 Host 中对应的 PID。</p><p><img src="https://note.youdao.com/yws/res/16890/WEBRESOURCE86306d565994b1384112e040db363ee2" alt="image"></p><p><img src="https://note.youdao.com/yws/res/16892/WEBRESOURCE20a6e965c0cc47ee3e6ab4e8f56957b0" alt="image"></p><p>可看到，所有容器进程都挂到了 docker 容器引擎进程 <code>/usr/bin/containerd</code> 下。</p><p><strong>注意</strong>：每个容器拥有自己独立一套的 PID，但容器中为 1 的 PID 并不是 Host 的 init 进程，因为容器与 Host 的 PID 是完全隔离且完整独立的。</p><p><strong>5、Network</strong></p><p>该 namespace 让容器拥有自己独立网卡设备、路由等资源，同样与 Host 的 Network 是完全隔离且完整独立的。</p><p><img src="https://note.youdao.com/yws/res/16891/WEBRESOURCE4bf4fc64e9dbd76dd559227ec6ca9140" alt="image"></p><p><strong>6、User</strong></p><p>该 namespace 让容器拥有自己独立的用户空间，同样与 Host 的 User 是完全隔离且完整独立的。</p>]]></content>
    
    
    <summary type="html">Docker 底层技术。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 数据存储及持久化应用</title>
    <link href="https://blog.rabcnops.cn/posts/articles/ff15f591.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/ff15f591.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:35:48.344Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/cunchu.webp" alt="cunchu"></p><p><font color=Brown><strong>Author</strong>：rab</font><br><font color=Brown><strong>Date</strong>：2022&#x2F;08&#x2F;09</font><br><font color=Brown><strong>Blog</strong>：<a href="https://blog.csdn.net/IT_ZRS?type=blog"><font color=Brown>https://blog.csdn.net/IT_ZRS?type&#x3D;blog</font></a></font></p><hr><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Docker 为容器提供了两种存放数据的资源：</p><ul><li>storage driver：管理镜像层和容器层；</li><li>data volume：管理容器应用数据。</li></ul><h2 id="一、Storage-Driver"><a href="#一、Storage-Driver" class="headerlink" title="一、Storage Driver"></a>一、Storage Driver</h2><h3 id="1-1-Storage-Driver-介绍"><a href="#1-1-Storage-Driver-介绍" class="headerlink" title="1.1 Storage Driver 介绍"></a>1.1 Storage Driver 介绍</h3><p>不同操作系统 Docker 默认的存储驱动可能不同，如 Ubuntu 15.04 使用的存储驱动是 aufs，底层文件系统时 extfs。而我下图中是 CentOS 7.9。其 Docker 存储驱动就是 overlay2。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809122145202.png" alt="image-20220809122145202"></p><blockquote><p>查看存储驱动</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809121816382.png" alt="image-20220809121816382"></p><p>之前博客中提到 Docker 的 Copy-on-Write 特性，之所以可以实现这样的特性，主要是因为我们 Docker Storage Driver 存储驱动，它实现了多层数据堆叠，并为用户提供一个单一的合并之后的统一视图。有兴趣的可以去看看我前面的博客<a href="https://blog.csdn.net/IT_ZRS/article/details/124692778">《Docker 的 Copy-on-Write 特性》</a>。</p><h3 id="1-2-Storage-Driver-类型"><a href="#1-2-Storage-Driver-类型" class="headerlink" title="1.2 Storage Driver 类型"></a>1.2 Storage Driver 类型</h3><p>Docker 支持多种 Storage Driver，主要有这几种类型：</p><ul><li><p>VFS</p></li><li><p>ZFS</p></li><li><p>Btrfs</p></li><li><p>AUFS</p></li><li><p>OverlayFS</p></li><li><p>Device Mapper</p></li></ul><p>对于 DOcker 使用哪种类型的存储引擎，官方给出的答案是：默认使用你当前 Linux 发行版的 Storage Driver，因为默认的 Storage Driver 是最稳定存储引擎，在发行版上经过了严格的测试。</p><p>使用 Storage Driver 数据存储有什么优势呢？对于那些无状态（即无需数据持久化到本地）的容器，Storage Driver  的优势将是毫无疑问的，因为它能从镜像直接创建、删除（且删除时生成的数据也一并随容器删除）。</p><p>而对于需要做数据持久化的容器，Storage Driver 显然就不如 Data Volume，也就是对于这类有状态的容器，我们要用到 Docker 的 Data Volume 来做容器数据持久化存储。</p><h2 id="二、Data-Volume"><a href="#二、Data-Volume" class="headerlink" title="二、Data Volume"></a>二、Data Volume</h2><h3 id="2-1-Data-Volume-介绍"><a href="#2-1-Data-Volume-介绍" class="headerlink" title="2.1 Data Volume 介绍"></a>2.1 Data Volume 介绍</h3><p>Data Volume 实际上是我们宿主机上的目录或文件，我们通过挂载的方式将 Host 的目录或文件挂载到容器内部文件系统，有时也可以说是把容器文件系统映射到宿主机上。</p><p>这样一来容器产生的数据就可以往 Volume 写入数据了，并持久化到 Host 本地了，即使该容器被删除了，再次运行一个新的容器，状态也是与之前保持一致的。</p><h3 id="2-2-Data-Volume-类型"><a href="#2-2-Data-Volume-类型" class="headerlink" title="2.2 Data Volume 类型"></a>2.2 Data Volume 类型</h3><h4 id="2-2-1-bind-mount"><a href="#2-2-1-bind-mount" class="headerlink" title="2.2.1 bind mount"></a>2.2.1 bind mount</h4><p>该类型是将 Host 上已存在的目录或文件 mount 到容器。</p><p>1、具体案例</p><p>看下面案例：其语法结构为 <code>-v &lt;Host_path&gt;:&lt;container_path(不存在则创建)&gt;</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">docker run -it \</span><br><span class="line">--name=elasticsearch \</span><br><span class="line">--privileged=true \</span><br><span class="line">--restart=always \</span><br><span class="line">--net=host \</span><br><span class="line">-v /etc/localtime:/etc/localtime \</span><br><span class="line">-v /data/elasticsearch/data:/usr/share/elasticsearch/data \</span><br><span class="line">-v /data/elasticsearch/logs:/usr/share/elasticsearch/logs \</span><br><span class="line">-v /data/elasticsearch/plugins:/usr/share/elasticsearch/plugins \</span><br><span class="line">-v /data/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \</span><br><span class="line">-e ES_JAVA_OPTS=&quot;-Xms512m -Xmx512m&quot; \</span><br><span class="line">-e &quot;discovery.type=single-node&quot; \</span><br><span class="line">-d elasticsearch:6.8.20</span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;注意：&#x3D;&#x3D;如果 <code>container_path</code> 存在数据，则会被隐藏，取而代之的是 Host mount 的目录或文件，这与 Linux 中 mount 效果一样。</p><p>2、带有权限的 bind mount</p><p>类似 Linux 的 mount，在挂载时可指定挂载目录权限，默认时<code>读写权限</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run -it \</span><br><span class="line">...</span><br><span class="line">-v /data/elasticsearch/plugins:/usr/share/elasticsearch/plugins:ro \</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ro：只读</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">rw：读写</span></span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;小结：&#x3D;&#x3D;从上面的案例上看，bind mount 可实现对目录或文件的 mount 操作，可根据你的实际情况操作。</p><h4 id="2-2-2-docker-managed-volume"><a href="#2-2-2-docker-managed-volume" class="headerlink" title="2.2.2 docker managed volume"></a>2.2.2 docker managed volume</h4><p>与 bind mount 不同的是，<code>docker managed volume</code> 不需要指定 mount 源，只需指明挂载点（mount point）即可。</p><p>1、案例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name=tmp -p 8280:80 -v /usr/local/apache2/htdocs httpd</span><br></pre></td></tr></table></figure><blockquote><p>我只指定了容器内部挂载点，并没有指定 Host 源目录&#x2F;文件，那这个数据持久化到 Host 的哪个位置呢？</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809150246050.png" alt="image-20220809150246050"></p><p>继续查看容器的详细信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker inspect tmp</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">看 Mount 部分</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809150430133.png" alt="image-20220809150430133"></p><p>2、如何持久化呢？</p><p>此时上图红框中的部分就是数据持久化目录了，就可以像 bind mount 对持久化目录&#x2F;文件进行相关更新了。具体如下：</p><ul><li><p>当前内容</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809151421398.png" alt="image-20220809151421398"></p></li><li><p>内容更新</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@docker_swarm_work1 _data]# pwd</span><br><span class="line">/var/lib/docker/volumes/fb39b435deb9bd50531b7da00ff1313f94bed8e489afb0ff69f27b77cd8a9253/_data</span><br><span class="line">[root@docker_swarm_work1 _data]# cat index.html </span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</span><br><span class="line">[root@docker_swarm_work1 _data]# echo &#x27;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Update It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;&#x27; &gt; index.html</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809151823689.png" alt="image-20220809151823689"></p></li><li><p>删除容器并新起一个容器（验证数据持久化）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker stop tmp &amp;&amp; docker rm tmp</span><br><span class="line">docker run -d --name=tmp -p 8288:80 -v /usr/local/apache2/htdocs httpd</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">再起一个新容器的话，docker 又会重新创建一个随机的持久话目录</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">但是我们之前的数据依然是在红框的上一个目录里面的</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809152528267.png" alt="image-20220809152528267"></p></li></ul><h3 id="2-3-查看-Data-Volume"><a href="#2-3-查看-Data-Volume" class="headerlink" title="2.3 查看 Data Volume"></a>2.3 查看 Data Volume</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker volume ls</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809154016353.png" alt="image-20220809154016353"></p><p>但是需注意，<code>docker volume ls</code> 只能查看 <code>docker managed volume</code> 类型的 <code>Data Volume</code>， <code>bind mount</code> 的 <code>Data Volume</code> 需要通过 <code>docker inspect &lt;container_name&gt;</code> 来查看。</p><p>&#x3D;&#x3D;如果我想在删除容器时，连 volume 也一并删除，如何操作？&#x3D;&#x3D;</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker stop tmp</span><br><span class="line">docker rm -v tmp</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">其中-v就表示volume</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果你确定不再需要这些持久化数据了就可执行 -v 操作</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker <span class="built_in">rm</span> -v &lt;container_name&gt; 对 <span class="built_in">bind</span> mount 类型的volume无效（也是无法删除，想删除需手动）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果你运行容器时指定了--<span class="built_in">rm</span>，那在停止容器时volume也会被自动删除（当然也是只对docker managed volume才有效）</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809154426361.png" alt="image-20220809154426361"></p><blockquote><p>如果删除 docker managed volume 类型容器的时候，忘记带 -v 参数了，这样的化会产生孤儿 volume，也就是说被删除的容器数据还持久化在 Host 上的（除非你确定该数据已经不需要要了，那就可以删除了），如何删除？</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除指定volume</span></span><br><span class="line">docker volume rm 02cc4ecdf7ac50fe346d67476e5e1e5ef67e207ca5ce0dd5db93cb510377c79f</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除所有volume</span></span><br><span class="line">docker volume rm $(docker volume ls -q)</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220809170514878.png" alt="image-20220809170514878"></p><h2 id="三、小结"><a href="#三、小结" class="headerlink" title="三、小结"></a>三、小结</h2><p><code>bind mount</code> 与 <code>docker managed volume</code> 就类似于动态指定端口和静态指定端口，动态指定端口：<code>-p 80</code> 此时会将容器的 80 端口在 Host 上映射一个随机端口，静态指定端口：<code>-p 8080:80</code>。</p><p>&#x3D;&#x3D;区别：&#x3D;&#x3D;</p><ul><li><p><code>bind mount</code> 指定的数据卷是静态的，而 <code>docker managed volume</code> 指定的数据卷是随机动态的；</p></li><li><p><code>bind mount</code> 挂载时 Host 源 path 会覆盖掉容器目标 path（但并不代表被永久替换），而  <code>docker managed volume</code> 则是将容器原有的目录或文件随机持久化在 <code>/var/lib/docker/volumes</code> 目录下；</p></li><li><p><code>bind mount</code> 可指定挂载目录的读写权限，而 <code>docker managed volume</code> 不能；</p></li><li><p><code>bind mount</code> 的 mount 源可以是目录或文件，而 <code>docker managed volume</code> 只能是目录。</p></li></ul><p>对于无状态（无需做数据持久化）的容器我们可以选择 <code>Storage Driver</code> 默认存储引擎即可，如果对于有状态（需做数据持久化）的容器我们需要引入 <code>Data Volume</code> 实现数据持久化。</p>]]></content>
    
    
    <summary type="html">Docker 数据存储及持久化应用。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 网络</title>
    <link href="https://blog.rabcnops.cn/posts/articles/4b442585.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/4b442585.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T09:20:11.616Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、None"><a href="#一、None" class="headerlink" title="一、None"></a>一、None</h2><p>该网络模式，即没有网络的网络模式，可通过 –network&#x3D;none 来指定。该网络模式的容器除了 lo 本地回环网卡外，无其他任何网卡，那该网络模式存在的意义是什么呢？</p><p>在一些安全级别要求高的场景下是需要的，如：用作密码服务器，就不需要任何的网络模式。</p><h2 id="二、Bridge"><a href="#二、Bridge" class="headerlink" title="二、Bridge"></a>二、Bridge</h2><p><strong>1、容器虚拟网卡</strong></p><p>如果在运行容器时，不指定任何网络模式，那创建的容器默认都会挂到 docker0 网卡上，如下图，这三个容器我都没通过 –network 指定网络模式。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182925558.png" alt="image-20221214182925558"></p><p>【interfaces】字段下的内容就是运行的这三个容器对应的虚拟网卡。此时进入某个容器，去查看一下其网卡名，如下图所示：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214182942221.png" alt="image-20221214182942221"></p><p>你会发现该容器的网卡名与【interfaces】字段下的虚拟网卡名不一致，这是为什么呢？</p><p>其实这是因为容器的虚拟网卡与挂在 docker0 下的虚拟网卡是一对特殊的 <code>veth pair</code> 网络设备。</p><p><strong>2、容器 IP 地址</strong></p><p>通过上图我们可以看到，运行的容器自动分配了一个 IP 地址，那该 IP 地址是从哪获取的呢？我们可以查看一下 Bridge 的网络配置信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network inspect bridge</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214183000755.png" alt="image-20221214183000755"></p><p>网段：172.17.0.0</p><p>网关：172.17.0.1</p><p>此时你会想，容器是如何与外界通信的（比如 yum install .. 安装等），其实正是上面这个网关地址，这个网关地址就是 docker0 网卡地址，如下图：</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214183016265.png" alt="image-20221214183016265"></p><p>通过上图你就会明白，运行的容器能连接外网安装一些基础工具，通过路由表可知其过程是：</p><ul><li>先访问目标IP（比如：221.237.105.143），发现没在自己的路由表中（既不是 <code>10.150.16.0</code> 也不是 <code>172.17.0.0</code>）；</li><li>于是就走 <code>0.0.0.0</code>，通过宿主机网关 <code>10.150.16.1</code> 与外界通信。</li></ul><h2 id="三、Host"><a href="#三、Host" class="headerlink" title="三、Host"></a>三、Host</h2><p>相对 Bridge 网络模式来说，Host 网络模式更便于理解，可通过 –network&#x3D;host 来指定，此时，容器的网络配置与宿主机（Host）完全一样。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --network=host busybox</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214183035316.png" alt="image-20221214183035316"></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20221214183047741.png" alt="image-20221214183047741"></p><p>从上图可看出，容器和宿主机的网络保持一致，换句话说，容器共享宿主机网络，这有什么好处？</p><p>对于网络性能要求较高的场景可以使用 Host 网络模式。</p><p>但该网络模式也有一些缺点，就是要考虑到容器和宿主机端口冲突的问题。</p><h2 id="四、自定义网络"><a href="#四、自定义网络" class="headerlink" title="四、自定义网络"></a>四、自定义网络</h2><p>除了以上三种网络模式，我们也可以自定义网络模式。</p><p><strong>1、自定义 Bridge 类型网络模式</strong></p><blockquote><p>不指定 –driver 的话，默认就是 Bridge 类型</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker network create --driver bridge net_a</span><br><span class="line">8568822dd4bf8ab5e9a33635f2f5bdb6a4577652879c55e13390b43d950f99ec</span><br><span class="line">[root@qcloud ~]# brctl show</span><br><span class="line">bridge namebridge idSTP enabledinterfaces</span><br><span class="line">br-8568822dd4bf8000.0242232f6190no</span><br><span class="line">docker08000.02429fa58d80noveth4b12f0c</span><br><span class="line">veth5cfded2</span><br><span class="line">veth6e1ba81</span><br></pre></td></tr></table></figure><p>查看具体属性：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker network inspect net_a </span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;net_a&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;8568822dd4bf8ab5e9a33635f2f5bdb6a4577652879c55e13390b43d950f99ec&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2022-05-12T19:13:11.197656976+08:00&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Ingress&quot;: false,</span><br><span class="line">        &quot;ConfigFrom&quot;: &#123;</span><br><span class="line">            &quot;Network&quot;: &quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;ConfigOnly&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可看到 Driver 驱动类型为 bridge 类型网络，同时 Docker 为其分配了 IP 段。</p><p><strong>2、自定义 IP 段</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker network create --driver bridge --subnet 192.168.4.0/24 --gateway 192.168.4.1 net_b</span><br></pre></td></tr></table></figure><p>查看具体属性：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker network inspect net_b</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;net_b&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;bb8dfbced7b2b38b47dc603abc010ca30888192d035eace29268baa035ba10f4&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2022-05-12T19:21:57.617051707+08:00&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;192.168.4.0/24&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;192.168.4.1&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Ingress&quot;: false,</span><br><span class="line">        &quot;ConfigFrom&quot;: &#123;</span><br><span class="line">            &quot;Network&quot;: &quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;ConfigOnly&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p><strong>3、运行容器并指定自定义网络</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --network=net_b busybox</span><br><span class="line">/ # ifconfig </span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:04:02  </span><br><span class="line">          inet addr:192.168.4.2  Bcast:192.168.4.255  Mask:255.255.255.0</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:9 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:766 (766.0 B)  TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p>既然我可以自定义网络模式，那我可不可以运行容器时指定一个静态 IP？</p><p><code>答案是可以的</code>，但前提是你这个网络必须是 <code>--subnet</code> 指定网段方式的自定义网络模式才行，具体如下：</p><ul><li><p>未使用 –subnet 指定网段的网络模式</p><blockquote><p>这种情况下是无法指定静态 IP 的，会报错。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --network=net_a --ip 172.18.0.5 busybox</span><br><span class="line">docker: Error response from daemon: user specified IP address is supported only when connecting to networks with user configured subnets.</span><br></pre></td></tr></table></figure></li><li><p>使用 –subnet 指定网段的网络模式</p><blockquote><p>这种情况下可以指定静态 IP。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it --network=net_b --ip 192.168.4.191 busybox</span><br><span class="line">/ # ifconfig </span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:C0:A8:04:BF  </span><br><span class="line">          inet addr:192.168.4.191  Bcast:192.168.4.255  Mask:255.255.255.0</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:7 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:586 (586.0 B)  TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure></li></ul><p> 对于自定义的 Bridge 类型网络模式，你每定义一个，Docker 都会将默认的 IP 网段（172.17.0.0&#x2F;16）往上加 1（除非是你自定义IP段）。</p> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">172.17.0.0/16</span><br><span class="line">172.18.0.0/16</span><br><span class="line">172.19.0.0/16</span><br><span class="line">172.20.0.0/16</span><br><span class="line">172.21.0.0/16</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">Docker 共有 4 种网络模式，分别是 none、host、bridge 和 自定义网络模式。Docker 提供了三种自定义网络驱动，分别为 bridge、overlay 和 macvlan，其中 overlay 和 macvlan 用于创建跨主机网络。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 资源分配与限制</title>
    <link href="https://blog.rabcnops.cn/posts/articles/3767a45b.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/3767a45b.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:34:50.129Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>我的宿主机：1C&#x2F;2G 50G 配置</p></blockquote><h2 id="1、CPU"><a href="#1、CPU" class="headerlink" title="1、CPU"></a>1、CPU</h2><p>默认情况下所有容器平等使用 Host 宿主机 CPU 资源，Docker 通过 -c 或 –cpu-shares 参数来指定容器使用 <code>CPU 的权重</code>。如果在运行容器时不指定，则权重值默认为 1024。接下来启动两个容器来做测试：</p><p>A 容器：权重1024</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --name=cpu_a -c 1024 progrium/stress --cpu 1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--cpu：表示工作线程数</span></span><br></pre></td></tr></table></figure><p>B 容器：权重512</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --name=cpu_b -c 512 progrium/stress --cpu 1</span><br></pre></td></tr></table></figure><p>top 查看宿主机的 CPU 资源消耗情况：</p><p><img src="https://note.youdao.com/yws/res/16895/WEBRESOURCEaa2d68329f786488f1db2e6543a882fd" alt="image"></p><ul><li>66.3 为 A 容器消耗的 CPU</li><li>33.0 为 B 容器消耗的 CPU</li></ul><p>通过上图结果，那是不是表明权重值越高，占用 CPU 的时间就越多呢？</p><p>这并不一定，一般这种按权重分配 CPU 只会发生在 CPU 资源紧张的情况下，怎么理解呢，如果 A 容器处于空闲状态，此时为了 CPU 资源的充分利用，B 容器也可以分到全部可用 CPU。</p><p>此时，如果我停掉权重为 1024 的容器 cpu_a，再来看看权重为 512 的容器 cpu_b 占用的 CPU：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pause cpu_a</span><br></pre></td></tr></table></figure><p>top 查看宿主机的 CPU 资源消耗情况：</p><p><img src="https://note.youdao.com/yws/res/16896/WEBRESOURCE5381d12c2492f3aefd76423c871a7598" alt="image"></p><p>可以看到，尽管我的容器 B 的权重值为 512，但如果比容器 B 容器大的其他容器不占用 CPU 或对 CPU 的占用少时，权重小的容器依然能够充分利用 CPU 资源。</p><h2 id="2、内存"><a href="#2、内存" class="headerlink" title="2、内存"></a>2、内存</h2><p>默认情况下 Docker 运行的容器对宿主机的<code>物理内存/swap交换内存</code>的使用是无限制的，为了避免过多容器使用过多内存导致 Host 的资源消耗殆尽，因此我们需要按照实际情况来对容器进行合理的<code>物理内存/swap交换内存</code>分配。具体分配指令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -m 200M --memory-swap=300M &lt;image&gt;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">【-m（或--memory）：物理内存】表示该容器允许使用的最大物理内存。默认值为-1，表示无限制</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">【--memory-swap：物理内存+虚拟内存】表示该容器允许使用的最大 swap 交换内存。默认值为-1，表示无限制</span></span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd -m 200M --memory-swap=300M centos:7.9.2009</span><br></pre></td></tr></table></figure><p>需注意的是：</p><ul><li>如果只指定 -m，则 –memory-swap 默认为 -m 的两倍；</li><li>如果 -m 的值等于 –memory-swap 的值，那将无法使用 swap 交换分区。</li></ul><p>我们可以使用 progrium&#x2F;stress 镜像来进行压力测试：</p><ul><li><p>启动一个内存工作线程，且每个线程分配 280M 内存</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud opt]# docker run -it -m 200M --memory-swap=300M progrium/stress --vm 1 --vm-bytes 280M</span><br><span class="line">stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd</span><br><span class="line">stress: dbug: [1] using backoff sleep of 3000us</span><br><span class="line">stress: dbug: [1] --&gt; hogvm worker 1 [6] forked</span><br><span class="line">stress: dbug: [6] allocating 293601280 bytes ...</span><br><span class="line">stress: dbug: [6] touching bytes in strides of 4096 bytes ...</span><br><span class="line">stress: dbug: [6] freed 293601280 bytes</span><br><span class="line">stress: dbug: [6] allocating 293601280 bytes ...</span><br><span class="line">stress: dbug: [6] touching bytes in strides of 4096 bytes ...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--vm：指定内存工作线程数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">--vm-bytes：指定每个内存工作线程数分配的大小</span></span><br></pre></td></tr></table></figure></li><li><p>模拟内存分配超过指定的可使用内存大小</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud opt]# docker run -it -m 200M --memory-swap=300M progrium/stress --vm 1 --vm-bytes 310M</span><br><span class="line">stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd</span><br><span class="line">stress: dbug: [1] using backoff sleep of 3000us</span><br><span class="line">stress: dbug: [1] --&gt; hogvm worker 1 [6] forked</span><br><span class="line">stress: dbug: [6] allocating 325058560 bytes ...</span><br><span class="line">stress: dbug: [6] touching bytes in strides of 4096 bytes ...</span><br><span class="line">stress: FAIL: [1] (416) &lt;-- worker 6 got signal 9</span><br><span class="line">stress: WARN: [1] (418) now reaping child worker processes</span><br><span class="line">stress: FAIL: [1] (422) kill error: No such process</span><br><span class="line">stress: FAIL: [1] (452) failed run completed in 1s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可看到 <span class="built_in">kill</span> error: No such process</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="3、磁盘"><a href="#3、磁盘" class="headerlink" title="3、磁盘"></a>3、磁盘</h2><p>这里主要说的是磁盘 IO 读写情况，默认情况下，所有容器平等读写宿主机磁盘，与 CPU 资源类似，也是通过 –blkio-weight 参数设置权重值（<code>默认为 500</code>）来分配宿主机资源。启动两个容器来做测试：</p><p>A 容器：权重600</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --name disk_a --blkio-weight 600 centos:7.9.2009</span><br></pre></td></tr></table></figure><p>B 容器：权重300</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --name disk_b --blkio-weight 300 centos:7.9.2009</span><br></pre></td></tr></table></figure><p>与 CPU 资源利用类似，A 容器磁盘读写带宽为 B 容器的两倍数。</p><p><strong>如何限制 bps 和 iops ？</strong></p><blockquote><p>bps：每秒读写数据量</p><p>iops：每秒 IO 次数</p></blockquote><ul><li>--device-read-bps</li><li>--device-write-bps</li><li>--device-read-iops</li><li>--device-write-iops</li></ul><p>具体案例：</p><ul><li><p>限制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">限制容器使用宿主机的磁盘IO</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">/dev/vda 为宿主机的磁盘设备，限制该容器每秒最多可向宿主机写30MB的数据</span></span><br><span class="line"></span><br><span class="line">[root@qcloud test]# docker run -it --device-write-bps /dev/vda:30MB centos:7.9.2009</span><br><span class="line">[root@03e61211de28 /]# time dd if=/dev/zero of=test_file.out bs=1M count=1000 oflag=direct</span><br><span class="line">1000+0 records in</span><br><span class="line">1000+0 records out</span><br><span class="line">1048576000 bytes (1.0 GB) copied, 33.3441 s, 31.4 MB/s</span><br><span class="line"></span><br><span class="line">real0m33.353s</span><br><span class="line">user0m0.003s</span><br><span class="line">sys0m0.224s</span><br></pre></td></tr></table></figure><blockquote><p>从结果可看出，基本在30MB左右。</p></blockquote></li><li><p>不限制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud test]# docker run -it centos:7.9.2009</span><br><span class="line">[root@fa7ff773d45e /]# time dd if=/dev/zero of=test_file.out bs=1M count=1000 oflag=direct</span><br><span class="line">1000+0 records in</span><br><span class="line">1000+0 records out</span><br><span class="line">1048576000 bytes (1.0 GB) copied, 22.8758 s, 45.8 MB/s</span><br><span class="line"></span><br><span class="line">real0m22.877s</span><br><span class="line">user0m0.010s</span><br><span class="line">sys0m0.276s</span><br></pre></td></tr></table></figure><blockquote><p>从结果可看出，不做限制的情况下，基本在45MB以上甚至更高。</p></blockquote></li></ul><p>其他参数类似。</p><p>&#x3D;&#x3D;那以上配置的资源信息存储在 Host 哪个位置呢？如CPU资源&#x3D;&#x3D;</p><blockquote><p>其目录在 <code>/sys/fs/cgroup/cpu/docker/*</code> 下<br>该目录下会对应有一个以正在运行的容器长ID为名的目录<br>其他资源同理：<code>/sys/fs/cgroup/blkio/docker/*</code>、<code>/sys/fs/cgroup/memory/docker/*</code></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220907141842911.png" alt="image-20220907141842911"></p><p>如：CPU 的资源限制（权重或大小）就在这个长ID目录下的 cpu.shares 文件，可查看该值大小，且该值大小就是我们 –cpu-shares 指定的值。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220907142515237.png" alt="image-20220907142515237"></p>]]></content>
    
    
    <summary type="html">Docker 资源分配与限制。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 运行的容器的内核版本是谁的？</title>
    <link href="https://blog.rabcnops.cn/posts/articles/abf826c0.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/abf826c0.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:34:56.451Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、疑问"><a href="#一、疑问" class="headerlink" title="一、疑问"></a>一、疑问</h2><p>有没有想过这样一个问题，CentOS 7 系统版本的内核版本为 3.x.x，Ubuntu 18、CentOS 8 等系统版本的内核版本为 4.x.x。那如果我是在 CentOS 8 系统上运行 Dockers 容器（如 CentOS 7 ），运行的这个容器的内核版本会是多少呢？</p><h2 id="二、解答"><a href="#二、解答" class="headerlink" title="二、解答"></a>二、解答</h2><p>在上一篇文章<a href="https://blog.csdn.net/IT_ZRS/article/details/124682432?spm=1001.2014.3001.5502">《为什么运行一个 CentOS 容器的镜像只需 200MB 左右？》</a>中讲到，对于容器的镜像来说，底层直接使用宿主机的内核空间，它只需提供用户空间 rootfs 文件系统即可。因此，Docker 运行的容器的内核版本就是你宿主机（CentOS 8）的内核版本。实践出真理，接下来我们实际测试一下。</p><p>1、查看宿主机系统版本及内核版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 8.3.2011</span><br><span class="line">[root@qcloud ~]# uname -a</span><br><span class="line">Linux qcloud 4.18.0-240.el8.x86_64 #1 SMP Fri Sep 25 19:48:47 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure><p>2、在上述的宿主机上运行 CentOS 7 容器并查看其内核版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@qcloud ~]# docker run -it centos:7.9.2009</span><br><span class="line">[root@74ecee4db934 /]# uname -a</span><br><span class="line">Linux 74ecee4db934 4.18.0-240.el8.x86_64 #1 SMP Fri Sep 25 19:48:47 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure><p>从测试结果可看出，运行的 CentOS 7 容器的内核版本为 4.18，证明<code>对于容器的镜像来说，底层直接使用宿主机的内核空间</code>这句话是完全没问题的。</p>]]></content>
    
    
    <summary type="html">Docker 运行的容器的内核版本是谁的？</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker 镜像 Tag 管理</title>
    <link href="https://blog.rabcnops.cn/posts/articles/ad0675e5.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/ad0675e5.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:36:06.709Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/docker-docs.webp" alt="docker-docs"></p><p><font color="Brown"><strong>Author</strong>：rab</font></p><hr><p>良好的镜像版本命名习惯能让我们更好的管理和使用镜像（如项目上线失败后可有效的进行版本回退），以下是 Docker 社区常用的 tag 方案。</p><p>比如我现在已经构建了一个 <code>coredns/coredns:1.8.4</code> 镜像，现在对该镜像进行打 tag，具体命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker tag -t coredns/coredns:1.8.4 mycoredns:1.8</span><br><span class="line">docker tag -t coredns/coredns:1.8.4 mycoredns:1.8.4</span><br><span class="line">docker tag -t coredns/coredns:1.8.4 mycoredns:latest</span><br></pre></td></tr></table></figure><p>如果此时我又发布了 <code>coredns/coredns:1.8.5</code> 镜像，我又可以将之前打的 1.8 更新，因为我想实现的是：不管发布的镜像版本是 <code>1.8.4、1.8.5、1.8.6、1.8.x</code>，我的 1.8 大版本始终是保持最新的，而我的小版本（1.8.4）可以进行相关的版本回退或在特定环境中实现部署等，具体操作指令如下。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker tag -t coredns/coredns:1.8.5 mycoredns:1.8</span><br><span class="line">docker tag -t coredns/coredns:1.8.5 mycoredns:1.8.5</span><br><span class="line">docker tag -t coredns/coredns:1.8.5 mycoredns:latest</span><br></pre></td></tr></table></figure><p><strong>通过下图就比较容易理解与记忆：</strong></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/Docker%20Tag.jpg" alt="Docker Tag"></p><p>&#x3D;&#x3D;小结：每个镜像（repository）可以有多个 tag，而多个 tag 可能对应的是同一个镜像。&#x3D;&#x3D;</p>]]></content>
    
    
    <summary type="html">良好的镜像版本命名习惯能让我们更好的管理和使用镜像（如项目上线失败后可有效的进行版本回退）。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/Docker/"/>
    
    
    <category term="Docker" scheme="https://blog.rabcnops.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>K8s 高可用集群架构（二进制）部署及应用</title>
    <link href="https://blog.rabcnops.cn/posts/articles/2ac58511.html"/>
    <id>https://blog.rabcnops.cn/posts/articles/2ac58511.html</id>
    <published>2023-03-23T03:33:14.000Z</published>
    <updated>2023-03-27T07:34:09.802Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/k8s-cert.png" alt="k8s-cert"></p><p>K8s 版本：1.24.4</p><hr><h2 id="一、场景"><a href="#一、场景" class="headerlink" title="一、场景"></a>一、场景</h2><h3 id="1-1-部署演进"><a href="#1-1-部署演进" class="headerlink" title="1.1 部署演进"></a>1.1 部署演进</h3><ul><li>传统部署 ——&gt; 虚拟化部署 ——&gt; 容器化部署</li><li>单体架构 ——&gt; 微服务架构</li></ul><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/container_evolution.svg" alt="部署演进"></p><h3 id="1-2-应用场景"><a href="#1-2-应用场景" class="headerlink" title="1.2 应用场景"></a>1.2 应用场景</h3><ul><li><p>单 K8s 节点 ——&gt; 用于开发测试验证</p></li><li><p>单 K8s-master 集群 ——&gt; 存在 master 单点故障 ——&gt; 一般用于测试环境</p></li><li><p>K8s-master 高可用集群架构（解决单点故障）——&gt; keepalived 高可用 + LB 负载均衡 ——&gt; 企业级 K8s 集群架构 ——&gt; 用于正式环境</p></li></ul><h3 id="1-3-K8s-能做什么？"><a href="#1-3-K8s-能做什么？" class="headerlink" title="1.3 K8s 能做什么？"></a>1.3 K8s 能做什么？</h3><p>在生产环境中， 你需要管理运行着应用程序的容器，并确保服务不会下线。在没有引进 K8s 之前，我们可通过简单的 Docker swarm 集群来实现应用程序下线后自动拉起，保证可用性。而 K8s 能实现的功能却比 Docker swarm 更加丰富，当然也能保证应用程序的可用性，比如一个容器发生故障，那么 K8s 会进行自动修复。它具有以下这些特性：</p><ul><li><p><strong>服务发现和负载均衡</strong></p><p>K8s 可以使用 DNS 名称或自己的 IP 地址来曝露容器。 如果进入容器的流量很大， K8s 可以负载均衡并分配网络流量，从而使部署稳定。</p></li><li><p><strong>存储编排</strong></p><p>K8s 允许你自动挂载你选择的存储系统，例如本地存储、公有云提供商等。</p></li><li><p><strong>自动部署和回滚</strong></p><p>你可以使用 K8s 描述已部署容器的所需状态， 它可以以受控的速率将实际状态更改为期望状态。 例如，你可以自动化 K8s 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。</p></li><li><p><strong>自动完成装箱计算</strong></p><p>你为 K8s 提供许多节点组成的集群，在这个集群上运行容器化的任务。 你告诉 K8s 每个容器需要多少 CPU 和内存 (RAM)。 K8s 可以将这些容器按实际情况调度到你的节点上，以最佳方式利用你的资源。</p></li><li><p><strong>自我修复</strong></p><p>K8s 将重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器， 并且在准备好服务之前不将其通告给客户端。</p></li><li><p><strong>密钥与配置管理</strong></p><p>K8s 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p></li></ul><h2 id="二、架构"><a href="#二、架构" class="headerlink" title="二、架构"></a>二、架构</h2><h3 id="2-1-官方架构图"><a href="#2-1-官方架构图" class="headerlink" title="2.1 官方架构图"></a>2.1 官方架构图</h3><p>K8s 集群由一组被称为节点（node）的服务器组成，这些节点上会运行由 K8s 所管理的容器化应用，且每个集群至少有一个工作节点。</p><p>工作节点会托管所谓的 Pods，而 Pod 就是作为应用负载的组件。控制平面（就是 Master 管理节点）管理集群中的工作节点和 Pods。 为集群提供故障转移和高可用性， 这些控制平面一般跨多主机运行，而集群也会跨多个节点运行。看下图就够就很清晰了。</p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/components-of-kubernetes.svg" alt="Components of Kubernetes"></p><h3 id="2-2-生产环境架构"><a href="#2-2-生产环境架构" class="headerlink" title="2.2 生产环境架构"></a>2.2 生产环境架构</h3><blockquote><p>下图仅为大体示意图，具体的组件并没有详细展示。</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/K8s.jpg" alt="K8s"></p><h2 id="三、规划"><a href="#三、规划" class="headerlink" title="三、规划"></a>三、规划</h2><h3 id="3-1-主机规划"><a href="#3-1-主机规划" class="headerlink" title="3.1 主机规划"></a>3.1 主机规划</h3><table><thead><tr><th>Host</th><th>Hostname</th><th>Node</th><th>说明</th></tr></thead><tbody><tr><td>192.168.56.171（2C2G）</td><td>k8s-master1</td><td>k8s-master1、ETCD</td><td>k8s主节点、ETCD节点</td></tr><tr><td>192.168.56.172（2C2G）</td><td>k8s-master2</td><td>k8s-master2、ETCD</td><td>k8s主节点、ETCD节点</td></tr><tr><td>192.168.56.173（2C2G）</td><td>k8s-master3</td><td>k8s-master3、ETCD</td><td>k8s主节点、ETCD节点</td></tr><tr><td>192.168.56.174（2C2G）</td><td>k8s-work1</td><td>k8s-work1</td><td>k8s工作节点</td></tr><tr><td>192.168.56.175（2C2G）</td><td>k8s-work2</td><td>k8s-work2</td><td>k8s工作节点</td></tr><tr><td>192.168.56.176（2C2G）</td><td>k8s-ha1</td><td>k8s-ha1、keepalived</td><td>k8s负载均衡（负载master）</td></tr><tr><td>192.168.56.177（2C2G）</td><td>k8s-ha2</td><td>k8s-ha2、keepalived</td><td>k8s负载均衡（负载master）</td></tr><tr><td>192.168.56.178（VIP）</td><td>-</td><td>-</td><td>虚拟 IP，集群统一入口</td></tr></tbody></table><p>&#x3D;&#x3D;说明&#x3D;&#x3D;：以上为测试演示用，实际生产环境中至少 <code>8C/16G + </code>的服务器配置。公有云的话，VIP 为公有云的负载均衡的 IP。</p><h3 id="3-2-版本规划"><a href="#3-2-版本规划" class="headerlink" title="3.2 版本规划"></a>3.2 版本规划</h3><p>本次部署的 K8s 版本为 <code>1.24.x</code> ，<code>v1.24</code> 之前的 Kubernetes 版本直接集成了 Docker Engine 的一个组件，名为 <strong>dockershim</strong>。  自 <code>1.24</code> 版起，Dockershim 已从 Kubernetes 项目中正式移除。</p><table><thead><tr><th>软件名称</th><th>版本</th></tr></thead><tbody><tr><td>CentOS 7</td><td>kernel：3.10</td></tr><tr><td>K8s（kube-apiserver、kube-controller-manager、kube-scheduler、kubelet、kube-proxy）</td><td>v1.24.4</td></tr><tr><td>etcd</td><td>v3.5.4</td></tr><tr><td>calico</td><td>v3.23</td></tr><tr><td>coredns</td><td>v1.9.3</td></tr><tr><td>docker</td><td>v20.10.17</td></tr><tr><td>haproxy</td><td>v5.18</td></tr><tr><td>keepalived</td><td>v3.5</td></tr></tbody></table><h3 id="3-3-目录规划"><a href="#3-3-目录规划" class="headerlink" title="3.3 目录规划"></a>3.3 目录规划</h3><blockquote><p>在任意一台 k8s-master 节点创建即可，生成的相关文件（证书、私钥等）再通过 scp 等方式进行分发。</p></blockquote><table><thead><tr><th>DIR</th><th>说明</th></tr></thead><tbody><tr><td>&#x2F;data&#x2F;k8s-work&#x2F;</td><td>k8s-master 节点工作目录</td></tr><tr><td>&#x2F;data&#x2F;k8s-work&#x2F;cfssl</td><td>用于创建各种证书文件的目录</td></tr><tr><td>&#x2F;data&#x2F;k8s-work&#x2F;etcd</td><td>ETCD 二进制包存放目录</td></tr><tr><td>&#x2F;data&#x2F;k8s-work&#x2F;k8s</td><td>K8s 二进制包存放目录</td></tr><tr><td>&#x2F;data&#x2F;k8s-work&#x2F;calico</td><td>calico 配置文件</td></tr><tr><td>&#x2F;data&#x2F;k8s-work&#x2F;coredns</td><td>coredns 配置文件</td></tr><tr><td></td><td></td></tr><tr><td>&#x2F;data&#x2F;etcd&#x2F;{conf,data,ssl}</td><td>ETCD 集群服务（配置文件、数据、证书）目录</td></tr><tr><td>&#x2F;data&#x2F;kubernetes&#x2F;{conf,logs,ssl,tokenfile}</td><td>K8s 集群服务（配置文件、数据、证书）目录</td></tr></tbody></table><h3 id="3-4-网络分配"><a href="#3-4-网络分配" class="headerlink" title="3.4 网络分配"></a>3.4 网络分配</h3><table><thead><tr><th>网络名称</th><th>网段</th></tr></thead><tbody><tr><td>Node 节点网络</td><td>192.168.56.0&#x2F;24</td></tr><tr><td>Service 网络</td><td>10.96.0.0&#x2F;16</td></tr><tr><td>Pod 网络</td><td>10.244.0.0&#x2F;16</td></tr></tbody></table><h3 id="3-5-容器引擎"><a href="#3-5-容器引擎" class="headerlink" title="3.5 容器引擎"></a>3.5 容器引擎</h3><p>本次采用 Docker 作为 K8s 的编排对象，但要清楚，从 1.20+ 版本开始，K8s 已不再唯一支持 Docker 作为编排对象，且 1.24+ 版本开始完全移除了 <code>Dockershim</code>，进而支持 Contained 工业级容器，当然我们的 Docker 还是能继续使用的，可通过 <code>cri-docker</code> 接口实现，下文会有详细介绍。</p><h2 id="四、部署"><a href="#四、部署" class="headerlink" title="四、部署"></a>四、部署</h2><h3 id="4-1-服务器初始化"><a href="#4-1-服务器初始化" class="headerlink" title="4.1 服务器初始化"></a>4.1 服务器初始化</h3><h4 id="4-1-1-统一主机名"><a href="#4-1-1-统一主机名" class="headerlink" title="4.1.1 统一主机名"></a>4.1.1 统一主机名</h4><blockquote><p>对应主机执行</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname k8s-master1</span><br><span class="line">hostnamectl set-hostname k8s-master2</span><br><span class="line">hostnamectl set-hostname k8s-master3</span><br><span class="line">hostnamectl set-hostname k8s-work1</span><br><span class="line">hostnamectl set-hostname k8s-work2</span><br><span class="line">hostnamectl set-hostname k8s-ha1</span><br><span class="line">hostnamectl set-hostname k8s-ha2</span><br></pre></td></tr></table></figure><h4 id="4-1-2-互作本地解析"><a href="#4-1-2-互作本地解析" class="headerlink" title="4.1.2 互作本地解析"></a>4.1.2 互作本地解析</h4><blockquote><p>所有主机均执行</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">192.168.56.171 k8s-master1</span><br><span class="line">192.168.56.172 k8s-master2</span><br><span class="line">192.168.56.173 k8s-master3</span><br><span class="line">192.168.56.174 k8s-work1</span><br><span class="line">192.168.56.175 k8s-work2</span><br><span class="line">192.168.56.176 k8s-ha1</span><br><span class="line">192.168.56.177 k8s-ha2</span><br></pre></td></tr></table></figure><h4 id="4-1-3-主机系统优化"><a href="#4-1-3-主机系统优化" class="headerlink" title="4.1.3 主机系统优化"></a>4.1.3 主机系统优化</h4><blockquote><p>所有主机均执行</p></blockquote><p>1、关闭 firewalld</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure><p>2、关闭 Selinux</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -i &#x27;s/enforcing/disabled/&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure><p>3、停用交互分区</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab</span><br></pre></td></tr></table></figure><p>4、集群系统时间同步</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ntpdate &amp;&amp; ntpdate time.nist.gov &amp;&amp; hwclock --systohc</span><br></pre></td></tr></table></figure><p>5、加载 br_netfilter 模块</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">确保 br_netfilter 模块被加载</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载模块</span></span><br><span class="line">modprobe br_netfilter</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看加载情况</span></span><br><span class="line">lsmod | grep br_netfilter</span><br><span class="line">br_netfilter           22256  0 </span><br><span class="line">bridge                151336  1 br_netfilter</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">永久生效</span></span><br><span class="line">cat &lt;&lt;EOF | tee /etc/modules-load.d/k8s.conf</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>6、允许 iptables 检查桥接流量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置所需的 sysctl 参数，参数在重新启动后保持不变</span></span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">应用 sysctl 参数而不重新启动</span></span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure><p>7、文件描述符</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;&gt; /etc/security/limits.conf</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 655360</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* soft memlock unlimited</span><br><span class="line">* hard memlock unlimited</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>9、修改虚拟内存最大限制</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;&gt; /etc/sysctl.conf</span><br><span class="line">vm.max_map_count = 655360</span><br><span class="line">fs.file-max=655360</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>系统级别</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;&gt; /etc/systemd/system.conf</span><br><span class="line">DefaultLimitNOFILE=655360</span><br><span class="line">DefaultLimitNPROC=655360</span><br><span class="line">DefaultLimitMEMLOCK=infinity</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>使生效</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p>10、MAC 地址和 product_uuid 的唯一性</p><p>一般来讲，硬件设备会拥有唯一的地址，但是有些虚拟机的地址可能会重复。 Kubernetes 使用这些值来唯一确定集群中的节点。 如果这些值在每个节点上不唯一，可能会导致安装失败。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">可以使用命令 ip link 或 ifconfig -a 来获取网络接口的 MAC 地址</span><br><span class="line">可以使用 sudo cat /sys/class/dmi/id/product_uuid 命令对 product_uuid 校验</span><br></pre></td></tr></table></figure><h4 id="4-1-4-配置免密登录"><a href="#4-1-4-配置免密登录" class="headerlink" title="4.1.4 配置免密登录"></a>4.1.4 配置免密登录</h4><p>k8s-master1 节点免密钥登录其他节点，安装过程中生成配置文件和证书均在 k8s-master1 上操作，集群管理也在 k8s-master1 上操作，阿里云或者 AWS 上需要单独一台 kubectl 服务器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">一路回车即可</span></span><br><span class="line">ssh-keygen</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">免密登录</span></span><br><span class="line">ssh-copy-id k8s-master2</span><br><span class="line">ssh-copy-id k8s-master3</span><br><span class="line">ssh-copy-id k8s-work1</span><br><span class="line">ssh-copy-id k8s-work2</span><br></pre></td></tr></table></figure><h3 id="4-2-K8s-负载均衡配置"><a href="#4-2-K8s-负载均衡配置" class="headerlink" title="4.2 K8s 负载均衡配置"></a>4.2 K8s 负载均衡配置</h3><blockquote><p>在 k8s-ha1、k8s-ha2 服务器上执行</p></blockquote><h4 id="4-2-1-Haproxy"><a href="#4-2-1-Haproxy" class="headerlink" title="4.2.1 Haproxy"></a>4.2.1 Haproxy</h4><p>1、安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install haproxy</span><br></pre></td></tr></table></figure><p>2、配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/etc/haproxy/haproxy.cfg&lt;&lt;&quot;EOF&quot;</span><br><span class="line">global</span><br><span class="line"> maxconn 2000</span><br><span class="line"> ulimit-n 16384</span><br><span class="line"> log 127.0.0.1 local0 err</span><br><span class="line"> stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"> log global</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> timeout connect 5000</span><br><span class="line"> timeout client 50000</span><br><span class="line"> timeout server 50000</span><br><span class="line"> timeout http-request 15s</span><br><span class="line"> timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line"> bind *:33305</span><br><span class="line"> mode http</span><br><span class="line"> option httplog</span><br><span class="line"> monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">frontend k8s-master</span><br><span class="line"> bind 0.0.0.0:6443</span><br><span class="line"> bind 127.0.0.1:6443</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> tcp-request inspect-delay 5s</span><br><span class="line"> default_backend k8s-master</span><br><span class="line"></span><br><span class="line">backend k8s-master</span><br><span class="line"> mode tcp</span><br><span class="line"> option tcplog</span><br><span class="line"> option tcp-check</span><br><span class="line"> balance roundrobin</span><br><span class="line"> default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line"> server  k8s-master1  192.168.56.171:6443 check</span><br><span class="line"> server  k8s-master2  192.168.56.172:6443 check</span><br><span class="line"> server  k8s-master3  192.168.56.173:6443 check</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>3、启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start haproxy.service</span><br><span class="line">systemctl enable haproxy.service</span><br></pre></td></tr></table></figure><h4 id="4-2-2-Keepalived"><a href="#4-2-2-Keepalived" class="headerlink" title="4.2.2 Keepalived"></a>4.2.2 Keepalived</h4><p>1、安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y keepalived</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置文件路径：/etc/keepalived/keepalived.conf</span></span><br></pre></td></tr></table></figure><p>2、配置</p><ul><li>k8s-ha1（主）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/etc/keepalived/keepalived.conf&lt;&lt;&quot;EOF&quot;</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id k8s-master</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_k8s-master &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_k8s-master_status.sh&quot;</span><br><span class="line">    interval 5</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens33</span><br><span class="line">    mcast_src_ip 192.168.56.176</span><br><span class="line">    virtual_router_id 90</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8S_PASSWD</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.56.178/24</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_k8s-master</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>k8s-ha2（备）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;/etc/keepalived/keepalived.conf&lt;&lt;&quot;EOF&quot;</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id k8s-master</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_k8s-master &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_k8s-master_status.sh&quot;</span><br><span class="line">    interval 5</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens33</span><br><span class="line">    mcast_src_ip 192.168.56.177</span><br><span class="line">    virtual_router_id 90</span><br><span class="line">    priority 50</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass K8S_PASSWD</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.56.178/24</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_k8s-master</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>3、K8s-master 健康检测脚本</p><blockquote><p>主备均创建该文件</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/keepalived/check_k8s-master_status.sh &lt;&lt;&quot;EOF&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">err=0</span><br><span class="line">for k in $(seq 1 3)</span><br><span class="line">do</span><br><span class="line">   check_code=$(pgrep haproxy)</span><br><span class="line">   if [[ $check_code == &quot;&quot; ]]; then</span><br><span class="line">       err=$(expr $err + 1)</span><br><span class="line">       sleep 1</span><br><span class="line">       continue</span><br><span class="line">   else</span><br><span class="line">       err=0</span><br><span class="line">       break</span><br><span class="line">   fi</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [[ $err != &quot;0&quot; ]]; then</span><br><span class="line">   echo &quot;systemctl stop keepalived&quot;</span><br><span class="line">   /usr/bin/systemctl stop keepalived</span><br><span class="line">   exit 1</span><br><span class="line">else</span><br><span class="line">   exit 0</span><br><span class="line">fi</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>4、启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start keepalived.service</span><br><span class="line">systemctl enable keepalived.service</span><br></pre></td></tr></table></figure><h3 id="4-3-K8s-集群组件部署"><a href="#4-3-K8s-集群组件部署" class="headerlink" title="4.3 K8s 集群组件部署"></a>4.3 K8s 集群组件部署</h3><h4 id="4-3-1-ETCD-集群"><a href="#4-3-1-ETCD-集群" class="headerlink" title="4.3.1 ETCD 集群"></a>4.3.1 ETCD 集群</h4><h5 id="4-3-1-1-部署-cfssl-工具"><a href="#4-3-1-1-部署-cfssl-工具" class="headerlink" title="4.3.1.1 部署 cfssl 工具"></a>4.3.1.1 部署 cfssl 工具</h5><blockquote><p>包下载地址：<a href="https://github.com/cloudflare/cfssl/">https://github.com/cloudflare/cfssl/</a></p></blockquote><p>1、创建工作目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><p>2、安装 cfssl 工具</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">我用的版本是1.6.1（大家根据实际选择）</span></span><br><span class="line">cd /data/k8s-work/cfssl</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">上传文件到当前目录下（这里用到了三个文件）</span></span><br><span class="line">[root@k8s-master1 cfssl]# ll</span><br><span class="line">total 40232</span><br><span class="line">-rw-r--r-- 1 root root 16659824 May 31 22:12 cfssl_1.6.1_linux_amd64</span><br><span class="line">-rw-r--r-- 1 root root 13502544 May 31 21:49 cfssl-certinfo_1.6.1_linux_amd64</span><br><span class="line">-rw-r--r-- 1 root root 11029744 May 31 21:50 cfssljson_1.6.1_linux_amd64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">说明</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cfssl文件：命令行工具</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cfssljson文件：用来从cfssl程序获取JSON输出，并将证书，密钥，CSR和bundle写入文件中</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">cfssl-certinfo文件：证书相关信息查看工具</span></span><br></pre></td></tr></table></figure><p>3、软链接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chmod +x ./cfssl*</span><br><span class="line">ln -s /data/k8s-work/cfssl/cfssl_1.6.1_linux_amd64 /usr/sbin/cfssl</span><br><span class="line">ln -s /data/k8s-work/cfssl/cfssl-certinfo_1.6.1_linux_amd64 /usr/sbin/cfssl-certinfo</span><br><span class="line">ln -s /data/k8s-work/cfssl/cfssljson_1.6.1_linux_amd64 /usr/sbin/cfssljson</span><br></pre></td></tr></table></figure><p>4、验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 cfssl]# cfssl version</span><br><span class="line">Version: 1.6.1</span><br><span class="line">Runtime: go1.12.12</span><br></pre></td></tr></table></figure><h5 id="4-3-1-2-生成-CA-证书"><a href="#4-3-1-2-生成-CA-证书" class="headerlink" title="4.3.1.2 生成 CA 证书"></a>4.3.1.2 生成 CA 证书</h5><p>1、配置 CA 证书请求文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br><span class="line"></span><br><span class="line">cat &gt; ca-csr.json &lt;&lt;&quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">      &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">      &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;xgxy&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;ca&quot;: &#123;</span><br><span class="line">          &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>2、创建 ca 证书</p><blockquote><p>会生成三个文件：ca.csr 请求文件、ca-key.pem请求 key、ca.pem 证书</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220828220937384.png" alt="image-20220828220937384"></p><p>3、CA 证书策略</p><p>你可以通过 cfssl 命令行工具来默认生成，然后再修改。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl print-defaults config &gt; ca-config.json</span><br></pre></td></tr></table></figure><p>生成后，修改为下面案例即可（或就直接使用下面的示例配置即可）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ca-config.json &lt;&lt;&quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">      &quot;default&quot;: &#123;</span><br><span class="line">          &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">      &quot;profiles&quot;: &#123;</span><br><span class="line">          &quot;kubernetes&quot;: &#123;</span><br><span class="line">              &quot;usages&quot;: [</span><br><span class="line">                  &quot;signing&quot;,</span><br><span class="line">                  &quot;key encipherment&quot;,</span><br><span class="line">                  &quot;server auth&quot;,</span><br><span class="line">                  &quot;client auth&quot;</span><br><span class="line">              ],</span><br><span class="line">              &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">说明</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">server auth：表示client客户端可以使用ca对server提供的证书进行验证</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">client auth：表示server客户端可以使用ca对client提供的证书进行验证</span></span><br></pre></td></tr></table></figure><h5 id="4-3-1-3-生成-ETCD-证书"><a href="#4-3-1-3-生成-ETCD-证书" class="headerlink" title="4.3.1.3 生成 ETCD 证书"></a>4.3.1.3 生成 ETCD 证书</h5><p>1、配置 ETCD 证书请求文件</p><blockquote><p>为了方便后期扩容可以多写几个预留的 IP</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-csr.json &lt;&lt;&quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.56.171&quot;,</span><br><span class="line">    &quot;192.168.56.172&quot;,</span><br><span class="line">    &quot;192.168.56.173&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [&#123;</span><br><span class="line">    &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">    &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">    &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">    &quot;O&quot;: &quot;xgxy&quot;,</span><br><span class="line">    &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">  &#125;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>2、生成 ETCD 证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes etcd-csr.json | cfssljson -bare etcd</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829141739248.png" alt="image-20220829141739248"></p><h5 id="4-3-1-4-部署-ETCD-集群"><a href="#4-3-1-4-部署-ETCD-集群" class="headerlink" title="4.3.1.4 部署 ETCD 集群"></a>4.3.1.4 部署 ETCD 集群</h5><blockquote><p>包下载地址：<a href="https://github.com/etcd-io/etcd">https://github.com/etcd-io/etcd</a></p></blockquote><p>1、下载 ETCD 软件包并上传至服务器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/k8s-work/etcd</span><br><span class="line">tar xzf etcd-v3.5.4-linux-amd64.tar.gz</span><br><span class="line">mv etcd-v3.5.4-linux-amd64 etcd-v3.5.4</span><br></pre></td></tr></table></figure><p>2、做软链接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/k8s-work/etcd/etcd-v3.5.4/etcd* /usr/bin/</span><br></pre></td></tr></table></figure><p>3、版本验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master1 etcd]# etcd --version</span><br><span class="line">etcd Version: 3.5.4</span><br><span class="line">Git SHA: 08407ff76</span><br><span class="line">Go Version: go1.16.15</span><br><span class="line">Go OS/Arch: linux/amd64</span><br></pre></td></tr></table></figure><p>4、分发 ETCD 二进制工具至其他 ETCD 集群节点主机上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp etcd-v3.5.4/etcd* k8s-master2:/usr/bin/</span><br><span class="line">scp etcd-v3.5.4/etcd* k8s-master3:/usr/bin/</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829143435683.png" alt="image-20220829143435683"></p><p>5、新建 ETCD 集群相关目录</p><blockquote><p>所有 ETCD 集群节点均操作</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/etcd/&#123;conf,data,ssl&#125;</span><br></pre></td></tr></table></figure><p>6、创建 ETCD 配置文件</p><blockquote><p>所有 ETCD 集群节点均操作</p></blockquote><ul><li><p>k8s-master1</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/etcd/conf/etcd.conf &lt;&lt;&quot;EOF&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Member]</span></span><br><span class="line">ETCD_NAME=&quot;etcd-1&quot;</span><br><span class="line">ETCD_DATA_DIR=&quot;/data/etcd/data&quot;</span><br><span class="line">ETCD_LISTEN_PEER_URLS=&quot;https://192.168.56.171:2380&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.56.171:2379,http://127.0.0.1:2379&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Clustering]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.56.171:2380&quot;</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.56.171:2379&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.56.171:2380,etcd-2=https://192.168.56.172:2380,etcd-3=https://192.168.56.173:2380&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Security]</span></span><br><span class="line">ETCD_CERT_FILE=&quot;/data/etcd/ssl/etcd.pem&quot;</span><br><span class="line">ETCD_KEY_FILE=&quot;/data/etcd/ssl/etcd-key.pem&quot;</span><br><span class="line">ETCD_TRUSTED_CA_FILE=&quot;/data/etcd/ssl/ca.pem&quot;</span><br><span class="line">ETCD_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class="line">ETCD_PEER_CERT_FILE=&quot;/data/etcd/ssl/etcd.pem&quot;</span><br><span class="line">ETCD_PEER_KEY_FILE=&quot;/data/etcd/ssl/etcd-key.pem&quot;</span><br><span class="line">ETCD_PEER_TRUSTED_CA_FILE=&quot;/data/etcd/ssl/ca.pem&quot;</span><br><span class="line">ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>k8s-master2</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/etcd/conf/etcd.conf &lt;&lt;&quot;EOF&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Member]</span></span><br><span class="line">ETCD_NAME=&quot;etcd-2&quot;</span><br><span class="line">ETCD_DATA_DIR=&quot;/data/etcd/data&quot;</span><br><span class="line">ETCD_LISTEN_PEER_URLS=&quot;https://192.168.56.172:2380&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.56.172:2379,http://127.0.0.1:2379&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Clustering]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.56.172:2380&quot;</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.56.172:2379&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.56.171:2380,etcd-2=https://192.168.56.172:2380,etcd-3=https://192.168.56.173:2380&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Security]</span></span><br><span class="line">ETCD_CERT_FILE=&quot;/data/etcd/ssl/etcd.pem&quot;</span><br><span class="line">ETCD_KEY_FILE=&quot;/data/etcd/ssl/etcd-key.pem&quot;</span><br><span class="line">ETCD_TRUSTED_CA_FILE=&quot;/data/etcd/ssl/ca.pem&quot;</span><br><span class="line">ETCD_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class="line">ETCD_PEER_CERT_FILE=&quot;/data/etcd/ssl/etcd.pem&quot;</span><br><span class="line">ETCD_PEER_KEY_FILE=&quot;/data/etcd/ssl/etcd-key.pem&quot;</span><br><span class="line">ETCD_PEER_TRUSTED_CA_FILE=&quot;/data/etcd/ssl/ca.pem&quot;</span><br><span class="line">ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>k8s-master3</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/etcd/conf/etcd.conf &lt;&lt;&quot;EOF&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Member]</span></span><br><span class="line">ETCD_NAME=&quot;etcd-3&quot;</span><br><span class="line">ETCD_DATA_DIR=&quot;/data/etcd/data&quot;</span><br><span class="line">ETCD_LISTEN_PEER_URLS=&quot;https://192.168.56.173:2380&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.56.173:2379,http://127.0.0.1:2379&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Clustering]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.56.173:2380&quot;</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.56.173:2379&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.56.171:2380,etcd-2=https://192.168.56.172:2380,etcd-3=https://192.168.56.173:2380&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">[Security]</span></span><br><span class="line">ETCD_CERT_FILE=&quot;/data/etcd/ssl/etcd.pem&quot;</span><br><span class="line">ETCD_KEY_FILE=&quot;/data/etcd/ssl/etcd-key.pem&quot;</span><br><span class="line">ETCD_TRUSTED_CA_FILE=&quot;/data/etcd/ssl/ca.pem&quot;</span><br><span class="line">ETCD_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class="line">ETCD_PEER_CERT_FILE=&quot;/data/etcd/ssl/etcd.pem&quot;</span><br><span class="line">ETCD_PEER_KEY_FILE=&quot;/data/etcd/ssl/etcd-key.pem&quot;</span><br><span class="line">ETCD_PEER_TRUSTED_CA_FILE=&quot;/data/etcd/ssl/ca.pem&quot;</span><br><span class="line">ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">说明：</span><br><span class="line">ETCD_NAME：节点名称，集群中唯一</span><br><span class="line">ETCD_DATA_DIR：数据目录（自定义）</span><br><span class="line">ETCD_LISTEN_PEER_URLS：集群通信监听地址</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址</span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址</span><br><span class="line">ETCD_INITIAL_CLUSTER：集群节点地址（所有ETCD节点地址）</span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN：集群Token（ETCD集群节点统一口令）</span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new是新集群，existing 表示加入已有集群</span><br><span class="line">ETCD_CERT_FILE：etcd.pem文件</span><br><span class="line">ETCD_KEY_FILE：etcd<span class="literal">-key</span>.pem文件</span><br><span class="line">ETCD_TRUSTED_CA_FILE：ca.pem文件</span><br><span class="line">ETCD_CLIENT_CERT_AUTH=<span class="string">&quot;true&quot;</span></span><br><span class="line">ETCD_PEER_CERT_FILE：etcd.pem文件</span><br><span class="line">ETCD_PEER_KEY_FILE：etcd<span class="literal">-key</span>.pem文件</span><br><span class="line">ETCD_PEER_TRUSTED_CA_FILE：ca.pem文件</span><br><span class="line">ETCD_PEER_CLIENT_CERT_AUTH=<span class="string">&quot;true&quot;</span></span><br></pre></td></tr></table></figure></li></ul><p>7、复制 ETCD 证书至刚创建对应的目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master1</span></span><br><span class="line">cd /data/k8s-work/cfssl</span><br><span class="line">cp ca*.pem etcd*.pem /data/etcd/ssl/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master2</span></span><br><span class="line">scp ca*.pem etcd*.pem k8s-master2:/data/etcd/ssl/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master3</span></span><br><span class="line">scp ca*.pem etcd*.pem k8s-master3:/data/etcd/ssl/</span><br></pre></td></tr></table></figure><p>8、配置 systemd 管理</p><blockquote><p>ETCD 三台集群节点均操作</p></blockquote><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &lt;&lt; EOF | <span class="built_in">tee</span> /usr/lib/systemd/system/etcd.service</span><br><span class="line">[<span class="type">Unit</span>]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network<span class="literal">-online</span>.target</span><br><span class="line">Wants=network<span class="literal">-online</span>.target</span><br><span class="line"></span><br><span class="line">[<span class="type">Service</span>]</span><br><span class="line"><span class="built_in">Type</span>=notify</span><br><span class="line">EnvironmentFile=-/<span class="keyword">data</span>/etcd/conf/etcd.conf</span><br><span class="line">ExecStart=/usr/bin/etcd</span><br><span class="line">Restart=on<span class="literal">-failure</span></span><br><span class="line">RestartSec=<span class="number">5</span></span><br><span class="line">LimitNOFILE=<span class="number">65536</span></span><br><span class="line"></span><br><span class="line">[<span class="type">Install</span>]</span><br><span class="line">WantedBy=multi<span class="literal">-user</span>.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>9、启动 ETCD 集群</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon<span class="literal">-reload</span></span><br><span class="line">systemctl <span class="built_in">start</span> etcd.service</span><br><span class="line">systemctl enable etcd.service</span><br><span class="line"></span><br><span class="line">这里注意：启动第一个ETCD节点后，它就会等待其他集群节点加入，如果特定时间内其他节点未加入，则启动会失败</span><br><span class="line">因此，我们需要在特定时间内启动ETCD集群，避免超时启动失败</span><br></pre></td></tr></table></figure><p>10、集群验证</p><ul><li><p>节点可用性验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 /usr/bin/etcdctl --cacert=/data/etcd/ssl/ca.pem --cert=/data/etcd/ssl/etcd.pem --key=/data/etcd/ssl/etcd-key.pem --endpoints=&quot;https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379&quot; endpoint health --write-out=table</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829161255754.png" alt="image-20220829161255754"></p></li><li><p>ETCD 数据库性能验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 /usr/bin/etcdctl --write-out=table --cacert=/data/etcd/ssl/ca.pem --cert=/data/etcd/ssl/etcd.pem --key=/data/etcd/ssl/etcd-key.pem --endpoints=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 check perf</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829161833128.png" alt="image-20220829161833128"></p></li><li><p>集群节点成员列表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 /usr/bin/etcdctl --write-out=table --cacert=/data/etcd/ssl/ca.pem --cert=/data/etcd/ssl/etcd.pem --key=/data/etcd/ssl/etcd-key.pem --endpoints=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 member list</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829162029485.png" alt="image-20220829162029485"></p><p>这里看不了谁是 Leader，继续看下一条测试命令。</p></li><li><p>查看集群 Leader</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 /usr/bin/etcdctl --write-out=table --cacert=/data/etcd/ssl/ca.pem --cert=/data/etcd/ssl/etcd.pem --key=/data/etcd/ssl/etcd-key.pem --endpoints=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 endpoint status</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829162425388.png" alt="image-20220829162425388"></p></li></ul><h4 id="4-3-2-K8s-集群部署"><a href="#4-3-2-K8s-集群部署" class="headerlink" title="4.3.2 K8s 集群部署"></a>4.3.2 K8s 集群部署</h4><blockquote><p>包下载地址：<a href="https://github.com/kubernetes/kubernetes">https://github.com/kubernetes/kubernetes</a></p></blockquote><h5 id="4-3-2-1-Master-节点"><a href="#4-3-2-1-Master-节点" class="headerlink" title="4.3.2.1 Master 节点"></a>4.3.2.1 Master 节点</h5><blockquote><p>k8s-master 必须的节点：kube-apiserver、kube-controller-manager、kube-scheduler、kubectl（k8s-master 客户端工具）</p></blockquote><h6 id="4-3-2-1-1-kubernetes"><a href="#4-3-2-1-1-kubernetes" class="headerlink" title="4.3.2.1.1 kubernetes"></a>4.3.2.1.1 kubernetes</h6><blockquote><p>K8s 二进制包下载并分发</p></blockquote><p>1、创建工作目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/k8s-work/k8s</span><br></pre></td></tr></table></figure><p>2、下载并上传 K8s 包至服务器</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar xzf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这个二进制包包含了master、work的所有组件，所以下载一个二进制包即可</span></span><br></pre></td></tr></table></figure><p>3、做软链接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ln -s /data/k8s-work/k8s/kubernetes/server/bin/kube-apiserver /usr/bin/</span><br><span class="line">ln -s /data/k8s-work/k8s/kubernetes/server/bin/kube-controller-manager /usr/bin/</span><br><span class="line">ln -s /data/k8s-work/k8s/kubernetes/server/bin/kube-scheduler /usr/bin/</span><br><span class="line">ln -s /data/k8s-work/k8s/kubernetes/server/bin/kubectl /usr/bin/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果你希望将你的 k8s-master 节点也用于工作负载，那还需要分发以下二进制组件。本次我不希望在master节点上进行工作负载</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">ln</span> -s /data/k8s-work/k8s/kubernetes/server/bin/kubelet /usr/bin/</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">ln</span> -s /data/k8s-work/k8s/kubernetes/server/bin/kube-proxy /usr/bin/</span></span><br></pre></td></tr></table></figure><p>4、二进制组件分发</p><blockquote><p>分发二进制命令至其他 k8s-master 节点，这是 k8s-master 必须的二进制组件。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp kube-apiserver kube-controller-manager kube-scheduler kubectl k8s-master2:/usr/bin/</span><br><span class="line">scp kube-apiserver kube-controller-manager kube-scheduler kubectl k8s-master3:/usr/bin/</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829170425953.png" alt="image-20220829170425953"></p><blockquote><p>如果你希望将你的 k8s-master 节点也用于<code>工作负载</code>，那还需要分发这几个二进制组件。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp kubelet kube-proxy k8s-master2:/usr/bin/</span><br><span class="line">scp kubelet kube-proxy k8s-master3:/usr/bin/</span><br></pre></td></tr></table></figure><h6 id="4-3-2-1-2-apiserver"><a href="#4-3-2-1-2-apiserver" class="headerlink" title="4.3.2.1.2 apiserver"></a>4.3.2.1.2 apiserver</h6><p>1、配置 apiserver 证书请求文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同样，进入到我们的cfssl目录下创建</span></span><br><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-apiserver-csr.json &lt;&lt; &quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">&quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.56.171&quot;,</span><br><span class="line">    &quot;192.168.56.172&quot;,</span><br><span class="line">    &quot;192.168.56.173&quot;,</span><br><span class="line">    &quot;192.168.56.174&quot;,</span><br><span class="line">    &quot;192.168.56.175&quot;,</span><br><span class="line">    &quot;192.168.56.176&quot;,</span><br><span class="line">    &quot;192.168.56.177&quot;,</span><br><span class="line">    &quot;192.168.56.178&quot;,</span><br><span class="line">    &quot;192.168.56.179&quot;,</span><br><span class="line">    &quot;192.168.56.180&quot;,</span><br><span class="line">    &quot;10.96.0.1&quot;,</span><br><span class="line">    &quot;kubernetes&quot;,</span><br><span class="line">    &quot;kubernetes.default&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster.local&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;xgxy&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>以上 IP 为我们的 k8s-master 节点 IP、k8s-work 节点 IP、k8s-ha 节点 IP、VIP，且这些 IP 都是必要的。</p><p>为了方便后期扩容可以多写几个预留的 IP，方便 master 或 work 的加入。</p><p>注意：hosts 字段不仅可写 IP，也可写域名。</p></blockquote><p>2、生成 apiserver 证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-apiserver-csr.json | cfssljson -bare kube-apiserver</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829173940350.png" alt="image-20220829173940350"></p><p>3、配置 token文件</p><blockquote><p>其目的是为了实现自动签发证书，因为 Master apiserver 启用 TLS 认证后，work 节点的 kubelet、kube-proxy 与 kube-apiserver 进行通信时必须使用 CA 签发的有效证书，如果我有几百上千台 work 节点，那每次进行通信无疑都会增加工作量。</p><p>为了简化流程，Kubernetes 引入了 TLS bootstraping 机制来实现动态颁发客户端证书。目前主要用于kubelet，kube-proxy 还是由我们统一颁发一个证书。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; token.csv &lt;&lt; EOF</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">(<span class="built_in">head</span> -c 16 /dev/urandom | <span class="built_in">od</span> -An -t x | <span class="built_in">tr</span> -d <span class="string">&#x27; &#x27;</span>),kubelet-bootstrap,10001,<span class="string">&quot;system:kubelet-bootstrap&quot;</span></span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>4、创建 apiserver 配置文件</p><blockquote><p>其实你会发现，流程与部署 ETCD 集群类似</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/kubernetes/&#123;conf,tokenfile,ssl,logs/kube-apiserver&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/kubernetes/conf</span><br></pre></td></tr></table></figure><ul><li><p>k8s-master1</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-apiserver.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_APISERVER_OPTS=&quot;--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \</span><br><span class="line">  --anonymous-auth=false \</span><br><span class="line">  --bind-address=192.168.56.171 \</span><br><span class="line">  --secure-port=6443 \</span><br><span class="line">  --advertise-address=192.168.56.171 \</span><br><span class="line">  --authorization-mode=Node,RBAC \</span><br><span class="line">  --runtime-config=api/all=true \</span><br><span class="line">  --enable-bootstrap-token-auth \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --token-auth-file=/data/kubernetes/tokenfile/token.csv \</span><br><span class="line">  --service-node-port-range=30000-50000 \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-apiserver.pem  \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --client-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --kubelet-client-certificate=/data/kubernetes/ssl/kube-apiserver.pem \</span><br><span class="line">  --kubelet-client-key=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --service-account-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --service-account-signing-key-file=/data/kubernetes/ssl/ca-key.pem  \</span><br><span class="line">  --service-account-issuer=api \</span><br><span class="line">  --etcd-cafile=/data/etcd/ssl/ca.pem \</span><br><span class="line">  --etcd-certfile=/data/etcd/ssl/etcd.pem \</span><br><span class="line">  --etcd-keyfile=/data/etcd/ssl/etcd-key.pem \</span><br><span class="line">  --etcd-servers=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 \</span><br><span class="line">  --allow-privileged=true \</span><br><span class="line">  --apiserver-count=3 \</span><br><span class="line">  --audit-log-maxage=30 \</span><br><span class="line">  --audit-log-maxbackup=3 \</span><br><span class="line">  --audit-log-maxsize=100 \</span><br><span class="line">  --audit-log-path=/data/kubernetes/logs/kube-apiserver/kube-apiserver-audit.log \</span><br><span class="line">  --event-ttl=1h \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-apiserver \</span><br><span class="line">  --v=4&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>k8s-master2</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-apiserver.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_APISERVER_OPTS=&quot;--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \</span><br><span class="line">  --anonymous-auth=false \</span><br><span class="line">  --bind-address=192.168.56.172 \</span><br><span class="line">  --secure-port=6443 \</span><br><span class="line">  --advertise-address=192.168.56.172 \</span><br><span class="line">  --authorization-mode=Node,RBAC \</span><br><span class="line">  --runtime-config=api/all=true \</span><br><span class="line">  --enable-bootstrap-token-auth \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --token-auth-file=/data/kubernetes/tokenfile/token.csv \</span><br><span class="line">  --service-node-port-range=30000-50000 \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-apiserver.pem  \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --client-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --kubelet-client-certificate=/data/kubernetes/ssl/kube-apiserver.pem \</span><br><span class="line">  --kubelet-client-key=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --service-account-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --service-account-signing-key-file=/data/kubernetes/ssl/ca-key.pem  \</span><br><span class="line">  --service-account-issuer=api \</span><br><span class="line">  --etcd-cafile=/data/etcd/ssl/ca.pem \</span><br><span class="line">  --etcd-certfile=/data/etcd/ssl/etcd.pem \</span><br><span class="line">  --etcd-keyfile=/data/etcd/ssl/etcd-key.pem \</span><br><span class="line">  --etcd-servers=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 \</span><br><span class="line">  --allow-privileged=true \</span><br><span class="line">  --apiserver-count=3 \</span><br><span class="line">  --audit-log-maxage=30 \</span><br><span class="line">  --audit-log-maxbackup=3 \</span><br><span class="line">  --audit-log-maxsize=100 \</span><br><span class="line">  --audit-log-path=/data/kubernetes/logs/kube-apiserver/kube-apiserver-audit.log \</span><br><span class="line">  --event-ttl=1h \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-apiserver \</span><br><span class="line">  --v=4&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li><li><p>k8s-master3</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-apiserver.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_APISERVER_OPTS=&quot;--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \</span><br><span class="line">  --anonymous-auth=false \</span><br><span class="line">  --bind-address=192.168.56.173 \</span><br><span class="line">  --secure-port=6443 \</span><br><span class="line">  --advertise-address=192.168.56.173 \</span><br><span class="line">  --authorization-mode=Node,RBAC \</span><br><span class="line">  --runtime-config=api/all=true \</span><br><span class="line">  --enable-bootstrap-token-auth \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --token-auth-file=/data/kubernetes/tokenfile/token.csv \</span><br><span class="line">  --service-node-port-range=30000-50000 \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-apiserver.pem  \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --client-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --kubelet-client-certificate=/data/kubernetes/ssl/kube-apiserver.pem \</span><br><span class="line">  --kubelet-client-key=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --service-account-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --service-account-signing-key-file=/data/kubernetes/ssl/ca-key.pem  \</span><br><span class="line">  --service-account-issuer=api \</span><br><span class="line">  --etcd-cafile=/data/etcd/ssl/ca.pem \</span><br><span class="line">  --etcd-certfile=/data/etcd/ssl/etcd.pem \</span><br><span class="line">  --etcd-keyfile=/data/etcd/ssl/etcd-key.pem \</span><br><span class="line">  --etcd-servers=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 \</span><br><span class="line">  --allow-privileged=true \</span><br><span class="line">  --apiserver-count=3 \</span><br><span class="line">  --audit-log-maxage=30 \</span><br><span class="line">  --audit-log-maxbackup=3 \</span><br><span class="line">  --audit-log-maxsize=100 \</span><br><span class="line">  --audit-log-path=/data/kubernetes/logs/kube-apiserver/kube-apiserver-audit.log \</span><br><span class="line">  --event-ttl=1h \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-apiserver \</span><br><span class="line">  --v=4&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><p>5、配置 systemd 管理</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; &quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=etcd.service</span><br><span class="line">Wants=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/data/kubernetes/conf/kube-apiserver.conf</span><br><span class="line">ExecStart=/usr/bin/kube-apiserver $KUBE_APISERVER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>6、根据配置文件中的配置，复制相关文件到指定目录中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master1</span></span><br><span class="line">cd /data/k8s-work/cfssl/</span><br><span class="line">cp ca*.pem kube-apiserver*.pem /data/kubernetes/ssl/</span><br><span class="line">cp token.csv /data/kubernetes/tokenfile/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master2</span></span><br><span class="line">cd /data/k8s-work/cfssl/</span><br><span class="line">scp ca*.pem kube-apiserver*.pem k8s-master2:/data/kubernetes/ssl/</span><br><span class="line">scp token.csv k8s-master2:/data/kubernetes/tokenfile/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master3</span></span><br><span class="line">cd /data/k8s-work/cfssl/</span><br><span class="line">scp ca*.pem kube-apiserver*.pem k8s-master3:/data/kubernetes/ssl/</span><br><span class="line">scp token.csv k8s-master3:/data/kubernetes/tokenfile/</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220829183321945.png" alt="image-20220829183321945"></p><p>7、启动 apiserver</p><blockquote><p>三台 k8s-master 均启动</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-apiserver.service</span><br><span class="line">systemctl enable kube-apiserver.service</span><br></pre></td></tr></table></figure><p>8、验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl --insecure https://192.168.56.171:6443/</span><br><span class="line">curl --insecure https://192.168.56.172:6443/</span><br><span class="line">curl --insecure https://192.168.56.173:6443/</span><br><span class="line">curl --insecure https://192.168.56.178:6443/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">均为验证，401，通过curl没有通过身份验证，所以是正常</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830100749696.png" alt="image-20220830100749696"></p><h6 id="4-3-2-1-3-kubectl"><a href="#4-3-2-1-3-kubectl" class="headerlink" title="4.3.2.1.3 kubectl"></a>4.3.2.1.3 kubectl</h6><p>严格意义上来讲，kubectl 并不是 k8s-master 的组件，而是一个客户端工具，也就是说没有 kubectl，那我的 K8s 集群也是可以正常运行的。</p><p>1、配置 kubectl 证书请求文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubectl-csr.json &lt;&lt; &quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,             </span><br><span class="line">      &quot;OU&quot;: &quot;system&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这个admin 证书，是将来生成管理员用的kubeconfig 配置文件用的</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">现在我们一般建议使用RBAC 来对kubernetes 进行角色权限控制</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kubernetes 将证书中的CN 字段 作为User， O 字段作为 Group；</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">&quot;O&quot;</span>: <span class="string">&quot;system:masters&quot;</span>, 必须是system:masters，否则后面kubectl create clusterrolebinding报错。</span></span><br></pre></td></tr></table></figure><p>2、生成 kubectl 证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kubectl-csr.json | cfssljson -bare kubectl</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830103602218.png" alt="image-20220830103602218"></p><p>3、复制相关证书到 k8s-master 目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master1</span></span><br><span class="line">cp kubectl*.pem /data/kubernetes/ssl/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master2</span></span><br><span class="line">scp kubectl*.pem k8s-master2:/data/kubernetes/ssl/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master3</span></span><br><span class="line">scp kubectl*.pem k8s-master3:/data/kubernetes/ssl/</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830103919560.png" alt="image-20220830103919560"></p><p>4、生成 kubeconfig 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">192.168.56.178 为VIP，如果没有做master高可用，则为master节点IP</span></span><br><span class="line">kubectl config set-cluster kubernetes --certificate-authority=ca.pem --embed-certs=true --server=https://192.168.56.178:6443 --kubeconfig=kube.config</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials admin --client-certificate=kubectl.pem --client-key=kubectl-key.pem --embed-certs=true --kubeconfig=kube.config</span><br><span class="line"></span><br><span class="line">kubectl config set-context kubernetes --cluster=kubernetes --user=admin --kubeconfig=kube.config</span><br><span class="line"></span><br><span class="line">kubectl config use-context kubernetes --kubeconfig=kube.config</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">kube.config为kubectl的配置文件，包含访问apiserver的所有信息，如apiserver地址、CA证书和自身使用的证书等</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830104838097.png" alt="image-20220830104838097"></p><p>5、对 kubeconfig 配置文件进行角色绑定</p><p>也就是说我当前 centos 操作系统的登录用户为 root，那我们一般会将该 kube.config 复制到当前用户家目录下进行管理，以此来管理我整个 K8s 集群。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br><span class="line">mkdir ~/.kube</span><br><span class="line">cp kube.config ~/.kube/config</span><br><span class="line">kubectl create clusterrolebinding kube-apiserver:kubelet-apis --clusterrole=system:kubelet-api-admin --user kubernetes --kubeconfig=/root/.kube/config</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830105627119.png" alt="image-20220830105627119"></p><p>6、kubectl 命令验证</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">查看集群信息</span><br><span class="line">kubectl cluster<span class="literal">-info</span></span><br><span class="line"></span><br><span class="line">查看集群组件状态，可看到警告提示：ComponentStatu在<span class="number">1.19</span>+版本已经被弃用了（我当前为<span class="number">1.24</span>.<span class="number">4</span>）</span><br><span class="line">kubectl get componentstatuses</span><br><span class="line"></span><br><span class="line">查看命名空间中资源对象</span><br><span class="line">kubectl get all <span class="literal">--all-namespaces</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830105928998.png" alt="image-20220830105928998"></p><p>&#x3D;&#x3D;如果你也希望其他 k8s-master 节点也具备管理能力，那你需要复制相关证书文件至其他 k8s-master 节点&#x3D;&#x3D;</p><p>证书在上面已经分发到 k8s-master 的其他节点了，接下来只需要在其他 k8s-master 节点家目录创建相关文件，并将 k8s-master1 上配置好的 config 配置文件分发至其他 k8s-master 节点对应目录下即可。</p><ul><li><p>先在其他 k8s-master 节点创建目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master2:</span></span><br><span class="line">mkdir /root/.kube</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master3:</span></span><br><span class="line">mkdir /root/.kube</span><br></pre></td></tr></table></figure></li><li><p>在 k8s-master1 分发配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp /root/.kube/config k8s-master2:/root/.kube/config</span><br><span class="line">scp /root/.kube/config k8s-master3:/root/.kube/config</span><br></pre></td></tr></table></figure></li></ul><p>&#x3D;&#x3D;这样的话，所有 k8s-master 节点都具备 K8s 集群的管理能力了。&#x3D;&#x3D;</p><p>kubectl 命令补全（所有 k8s-master 节点执行）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum install -y bash-completion</span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line">source &lt;(kubectl completion bash)</span><br><span class="line">kubectl completion bash &gt; ~/.kube/completion.bash.inc</span><br><span class="line">source &#x27;/root/.kube/completion.bash.inc&#x27;  </span><br><span class="line">source $HOME/.bash_profile</span><br></pre></td></tr></table></figure><h6 id="4-3-2-1-4-kube-controller-manager"><a href="#4-3-2-1-4-kube-controller-manager" class="headerlink" title="4.3.2.1.4 kube-controller-manager"></a>4.3.2.1.4 kube-controller-manager</h6><p>1、配置 kube-controller-manager 证书请求文件</p><blockquote><p>因为我们部署的是 k8s-master 的高可用，所以 kube-controller-manager 也是配置的高可用</p><p>同理，也是统一在 k8s-master 节点 cfssl 目录下执行</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager-csr.json &lt;&lt; &quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;192.168.56.171&quot;,</span><br><span class="line">      &quot;192.168.56.172&quot;,</span><br><span class="line">      &quot;192.168.56.173&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">        &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">        &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">        &quot;O&quot;: &quot;system:kube-controller-manager&quot;,</span><br><span class="line">        &quot;OU&quot;: &quot;system&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">hosts列表包含所有kube-controller-manager节点IP</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">CN为system:kube-controller-manager</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">O为system:kube-controller-manager，其为kubernetes内置的ClusterRoleBindings</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">system:kube-controller-manager赋予kube-controller-manager工作所需的权限</span></span><br></pre></td></tr></table></figure><p>2、生成 kube-controller-manager 证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830112802956.png" alt="image-20220830112802956"></p><p>3、生成 kube-controller-manager 的 .kubeconfig 配置文件</p><blockquote><p>与 kubectl 类似，想要进行 k8s 集群控制，就需要进行相关配置。</p><p>同样是在 k8s-master1 的 cfssl 目录下执行</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-cluster kubernetes --certificate-authority=ca.pem --embed-certs=true --server=https://192.168.56.178:6443 --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager --client-certificate=kube-controller-manager.pem --client-key=kube-controller-manager-key.pem --embed-certs=true --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-controller-manager --cluster=kubernetes --user=system:kube-controller-manager --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-controller-manager --kubeconfig=kube-controller-manager.kubeconfig</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830113733447.png" alt="image-20220830113733447"></p><p>4、创建 kube-controller-manager 的 .conf 配置文件</p><blockquote><p>同样是在 k8s-master1 的 cfssl 目录下执行。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=&quot;--secure-port=10257 \</span><br><span class="line">  --bind-address=127.0.0.1 \</span><br><span class="line">  --kubeconfig=/data/kubernetes/conf/kube-controller-manager.kubeconfig \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --cluster-name=kubernetes \</span><br><span class="line">  --cluster-signing-cert-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cluster-signing-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --allocate-node-cidrs=true \</span><br><span class="line">  --cluster-cidr=10.244.0.0/16 \</span><br><span class="line">  --experimental-cluster-signing-duration=87600h \</span><br><span class="line">  --root-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --service-account-private-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --leader-elect=true \</span><br><span class="line">  --feature-gates=RotateKubeletServerCertificate=true \</span><br><span class="line">  --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-controller-manager.pem \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-controller-manager-key.pem \</span><br><span class="line">  --use-service-account-credentials=true \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-controller-manager \</span><br><span class="line">  --v=2&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建kube-controller-manager日志目录（所有k8s-master节点均执行）</span></span><br><span class="line">mkdir /data/kubernetes/logs/kube-controller-manager</span><br></pre></td></tr></table></figure><p>5、复制相关证书文件至配置文件中的指定目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master1</span></span><br><span class="line">cd /data/k8s-work/cfssl</span><br><span class="line">cp kube-controller-manager*.pem /data/kubernetes/ssl/</span><br><span class="line">cp kube-controller-manager.kubeconfig /data/kubernetes/conf/</span><br><span class="line">cp kube-controller-manager.conf /data/kubernetes/conf/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master2</span></span><br><span class="line">scp kube-controller-manager*.pem k8s-master2:/data/kubernetes/ssl/</span><br><span class="line">scp kube-controller-manager.kubeconfig k8s-master2:/data/kubernetes/conf/</span><br><span class="line">scp kube-controller-manager.conf k8s-master2:/data/kubernetes/conf/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master3</span></span><br><span class="line">scp kube-controller-manager*.pem k8s-master3:/data/kubernetes/ssl/</span><br><span class="line">scp kube-controller-manager.kubeconfig k8s-master3:/data/kubernetes/conf/</span><br><span class="line">scp kube-controller-manager.conf k8s-master3:/data/kubernetes/conf/</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830115607487.png" alt="image-20220830115607487"></p><p>6、配置 systemd 管理</p><blockquote><p>k8s-master 所有节点均执行，或者在 k8s-master1 上执行完成后再分发至其他 master 节点</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; &quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/data/kubernetes/conf/kube-controller-manager.conf</span><br><span class="line">ExecStart=/usr/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>7、启动 kube-controller-manager 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-controller-manager.service</span><br><span class="line">systemctl enable kube-controller-manager.service</span><br></pre></td></tr></table></figure><p>8、验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get componentstatuses</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830125423606.png" alt="image-20220830125423606"></p><h6 id="4-3-2-1-5-kube-scheduler"><a href="#4-3-2-1-5-kube-scheduler" class="headerlink" title="4.3.2.1.5 kube-scheduler"></a>4.3.2.1.5 kube-scheduler</h6><p>1、配置 kube-scheduler 证书请求文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler-csr.json &lt;&lt; &quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;192.168.56.171&quot;,</span><br><span class="line">      &quot;192.168.56.172&quot;,</span><br><span class="line">      &quot;192.168.56.173&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">        &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">        &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">        &quot;O&quot;: &quot;system:kube-scheduler&quot;,</span><br><span class="line">        &quot;OU&quot;: &quot;system&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>2、生成 kube-scheduler 证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830130500777.png" alt="image-20220830130500777"></p><p>3、生成 kube-scheduler 的 .kubeconfig 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-cluster kubernetes --certificate-authority=ca.pem --embed-certs=true --server=https://192.168.56.178:6443 --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials system:kube-scheduler --client-certificate=kube-scheduler.pem --client-key=kube-scheduler-key.pem --embed-certs=true --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context system:kube-scheduler --cluster=kubernetes --user=system:kube-scheduler --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context system:kube-scheduler --kubeconfig=kube-scheduler.kubeconfig</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830130910387.png" alt="image-20220830130910387"></p><p>4、创建 kube-scheduler 的 .conf 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_SCHEDULER_OPTS=&quot;--kubeconfig=/data/kubernetes/conf/kube-scheduler.kubeconfig \</span><br><span class="line">--leader-elect=true \</span><br><span class="line">--alsologtostderr=true \</span><br><span class="line">--logtostderr=false \</span><br><span class="line">--log-dir=/data/kubernetes/logs/kube-scheduler \</span><br><span class="line">--v=2&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建kube-scheduler日志目录（所有k8s-master节点均执行）</span></span><br><span class="line">mkdir /data/kubernetes/logs/kube-scheduler</span><br></pre></td></tr></table></figure><p>5、复制相关证书文件至配置文件中的指定目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-master1</span></span><br><span class="line">cd /data/k8s-work/cfssl</span><br><span class="line">cp kube-scheduler*.pem /data/kubernetes/ssl/</span><br><span class="line">cp kube-scheduler.kubeconfig /data/kubernetes/conf/</span><br><span class="line">cp kube-scheduler.conf /data/kubernetes/conf/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master2</span></span><br><span class="line">scp kube-scheduler*.pem k8s-master2:/data/kubernetes/ssl/</span><br><span class="line">scp kube-scheduler.kubeconfig k8s-master2:/data/kubernetes/conf/</span><br><span class="line">scp kube-scheduler.conf k8s-master2:/data/kubernetes/conf/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-master3</span></span><br><span class="line">scp kube-scheduler*.pem k8s-master3:/data/kubernetes/ssl/</span><br><span class="line">scp kube-scheduler.kubeconfig k8s-master3:/data/kubernetes/conf/</span><br><span class="line">scp kube-scheduler.conf k8s-master3:/data/kubernetes/conf/</span><br></pre></td></tr></table></figure><p>6、配置 systemd 管理</p><blockquote><p>k8s-master 所有节点均执行，或者在 k8s-master1 上执行完成后再分发至其他 master 节点</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; &quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/data/kubernetes/conf/kube-scheduler.conf</span><br><span class="line">ExecStart=/usr/bin/kube-scheduler $KUBE_SCHEDULER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>7、启动 kube-controller-manager 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-scheduler.service</span><br><span class="line">systemctl enable kube-scheduler.service</span><br></pre></td></tr></table></figure><p>8、验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get componentstatuses</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830133247786.png" alt="image-20220830133247786"></p><p>&#x3D;&#x3D;至此，k8s-master 节点的所有组件已经部署完成，并已成功在运行。接下来就是部署 k8s-work 节点组件了。&#x3D;&#x3D;</p><h5 id="4-3-2-2-Work-节点"><a href="#4-3-2-2-Work-节点" class="headerlink" title="4.3.2.2 Work 节点"></a>4.3.2.2 Work 节点</h5><blockquote><p>k8s-master 必须的组件：kubelet、kube-proxy</p><p>k8s 在 1.20+ 开始，不再唯一支持 docker，而且也支持 Containerd，而 1.24+ 版本开始，完全移除 dockershim（不代表不可用，而是以其他方式进行使用 docker），对于 work 节点来说，容器化引擎是必须的。</p></blockquote><h6 id="4-3-2-2-1-部署说明"><a href="#4-3-2-2-1-部署说明" class="headerlink" title="4.3.2.2.1 部署说明"></a>4.3.2.2.1 部署说明</h6><blockquote><p>看看官方的解释</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830135059526.png" alt="image-20220830135059526"></p><p>&#x3D;&#x3D;本次我将采用 Docker 的方式部署&#x3D;&#x3D;</p><h6 id="4-3-2-2-2-组件分发"><a href="#4-3-2-2-2-组件分发" class="headerlink" title="4.3.2.2.2 组件分发"></a>4.3.2.2.2 组件分发</h6><blockquote><p>在上面，我们下载了 kubernetes 的二进制包，里面包含了 master 节点和 work 节点的所有组件，因此在 k8s-master 节点上分发到 work 节点上即可。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/k8s/kubernetes/server/bin</span><br><span class="line">scp kubelet kube-proxy k8s-work1:/usr/bin/</span><br><span class="line">scp kubelet kube-proxy k8s-work2:/usr/bin/</span><br></pre></td></tr></table></figure><h6 id="4-3-2-2-3-docker"><a href="#4-3-2-2-3-docker" class="headerlink" title="4.3.2.2.3 docker"></a>4.3.2.2.3 docker</h6><p>1、安装 docker 引擎</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sh docker_install.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">需要安装脚本的私信</span></span><br></pre></td></tr></table></figure><p>2、修改 cgroup</p><blockquote><p>k8s 和 docker 的 cgroup 必须保持一致，这里官方推荐为 systemd。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/docker/daemon.json </span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://q1rw9tzz.mirror.aliyuncs.com&quot;],</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="4-3-2-2-4-cri-dockerd"><a href="#4-3-2-2-4-cri-dockerd" class="headerlink" title="4.3.2.2.4 cri-dockerd"></a>4.3.2.2.4 cri-dockerd</h6><blockquote><p>想要使用 docker 作为 k8s 的编排对象，那需要安装 cri-docker 来作为 dockershim。</p><p>cri-docker 源码安装地址：<a href="https://github.com/Mirantis/cri-dockerd">https://github.com/Mirantis/cri-dockerd</a></p></blockquote><p>1、安装 Go 环境</p><blockquote><p>k8s-work 节点执行</p></blockquote><p>因为 cri-dockerd 由 go 编写，所以 k8s-work 主机需具备 go 环境。go 二进制包下载地址：<a href="https://golang.google.cn/dl/">https://golang.google.cn/dl/</a></p><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830144911203.png" alt="image-20220830144911203"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-work1</span></span><br><span class="line">tar xzf go1.18.5.linux-amd64.tar.gz -C /opt/</span><br><span class="line">ln -s /opt/go/bin/* /usr/bin/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">k8s-work2</span></span><br><span class="line">tar xzf go1.18.5.linux-amd64.tar.gz -C /opt/</span><br><span class="line">ln -s /opt/go/bin/* /usr/bin/</span><br></pre></td></tr></table></figure><p>2、clone 源码项目并编译</p><blockquote><p>安装官方文档来部署即可</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830151256425.png" alt="image-20220830151256425"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">GO环境我们已经有了</span></span><br><span class="line">git clone https://github.com/Mirantis/cri-dockerd.git</span><br><span class="line">cd cri-dockerd</span><br><span class="line">mkdir bin</span><br><span class="line">go build -o bin/cri-dockerd</span><br><span class="line">mkdir -p /usr/local/bin</span><br><span class="line">install -o root -g root -m 0755 bin/cri-dockerd /usr/local/bin/cri-dockerd</span><br><span class="line">cp -a packaging/systemd/* /etc/systemd/system</span><br><span class="line">sed -i -e &#x27;s,/usr/bin/cri-dockerd,/usr/local/bin/cri-dockerd,&#x27; /etc/systemd/system/cri-docker.service</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable cri-docker.service</span><br><span class="line">systemctl enable --now cri-docker.socket</span><br></pre></td></tr></table></figure><blockquote><p>最后看看是否启动成功（下图，成功启动并正在监听）</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830152319042.png" alt="image-20220830152319042"></p><p>3、修改 cri-docker 的 systemd 文件</p><ul><li><p>修改前</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=CRI Interface for Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.mirantis.com</span><br><span class="line">After=network-online.target firewalld.service docker.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Requires=cri-docker.socket</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/cri-dockerd --container-runtime-endpoint fd://</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">TimeoutSec=0</span><br><span class="line">RestartSec=2</span><br><span class="line">Restart=always</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Note that StartLimit* options were moved from <span class="string">&quot;Service&quot;</span> to <span class="string">&quot;Unit&quot;</span> <span class="keyword">in</span> systemd 229.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Both the old, and new location are accepted by systemd 229 and up, so using the old location</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">to make them work <span class="keyword">for</span> either version of systemd.</span></span><br><span class="line">StartLimitBurst=3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Note that StartLimitInterval was renamed to StartLimitIntervalSec <span class="keyword">in</span> systemd 230.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Both the old, and new name are accepted by systemd 230 and up, so using the old name to make</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">this option work <span class="keyword">for</span> either version of systemd.</span></span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Having non-zero Limit*s causes performance problems due to accounting overhead</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">in</span> the kernel. We recommend using cgroups to <span class="keyword">do</span> container-local accounting.</span></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Comment TasksMax <span class="keyword">if</span> your systemd version does not support it.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Only systemd 226 and above support this option.</span></span><br><span class="line">TasksMax=infinity</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></li><li><p>修改后</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=CRI Interface for Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.mirantis.com</span><br><span class="line">After=network-online.target firewalld.service docker.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Requires=cri-docker.socket</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/cri-dockerd --container-runtime-endpoint fd:// --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">TimeoutSec=0</span><br><span class="line">RestartSec=2</span><br><span class="line">Restart=always</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Note that StartLimit* options were moved from <span class="string">&quot;Service&quot;</span> to <span class="string">&quot;Unit&quot;</span> <span class="keyword">in</span> systemd 229.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Both the old, and new location are accepted by systemd 229 and up, so using the old location</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">to make them work <span class="keyword">for</span> either version of systemd.</span></span><br><span class="line">StartLimitBurst=3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Note that StartLimitInterval was renamed to StartLimitIntervalSec <span class="keyword">in</span> systemd 230.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Both the old, and new name are accepted by systemd 230 and up, so using the old name to make</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">this option work <span class="keyword">for</span> either version of systemd.</span></span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Having non-zero Limit*s causes performance problems due to accounting overhead</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">in</span> the kernel. We recommend using cgroups to <span class="keyword">do</span> container-local accounting.</span></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Comment TasksMax <span class="keyword">if</span> your systemd version does not support it.</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Only systemd 226 and above support this option.</span></span><br><span class="line">TasksMax=infinity</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></li></ul><h6 id="4-3-2-2-5-kubelet"><a href="#4-3-2-2-5-kubelet" class="headerlink" title="4.3.2.2.5 kubelet"></a>4.3.2.2.5 kubelet</h6><blockquote><p>同样在 k8s-master1 上执行</p></blockquote><p>1、创建 kubelet 的 .kubeconfig 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl/</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">BOOTSTRAP_TOKEN=$(awk -F &quot;,&quot; &#x27;&#123;print $1&#125;&#x27; /data/kubernetes/tokenfile/token.csv)</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes --certificate-authority=ca.pem --embed-certs=true --server=https://192.168.56.178:6443 --kubeconfig=kubelet-bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubelet-bootstrap --token=$&#123;BOOTSTRAP_TOKEN&#125; --kubeconfig=kubelet-bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context default --cluster=kubernetes --user=kubelet-bootstrap --kubeconfig=kubelet-bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context default --kubeconfig=kubelet-bootstrap.kubeconfig</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830155243172.png" alt="image-20220830155243172"></p><blockquote><p>指定角色</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding cluster-system-anonymous --clusterrole=cluster-admin --user=kubelet-bootstrap</span><br><span class="line"></span><br><span class="line">kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap --kubeconfig=kubelet-bootstrap.kubeconfig</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830155351265.png" alt="image-20220830155351265"></p><blockquote><p>基础验证</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe clusterrolebinding cluster-system-anonymous</span><br><span class="line">kubectl describe clusterrolebinding kubelet-bootstrap</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830155445682.png" alt="image-20220830155445682"></p><p>4、创建 kubelet 的 .conf 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubelet.json &lt;&lt; &quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;kind&quot;: &quot;KubeletConfiguration&quot;,</span><br><span class="line">  &quot;apiVersion&quot;: &quot;kubelet.config.k8s.io/v1beta1&quot;,</span><br><span class="line">  &quot;authentication&quot;: &#123;</span><br><span class="line">    &quot;x509&quot;: &#123;</span><br><span class="line">      &quot;clientCAFile&quot;: &quot;/data/kubernetes/ssl/ca.pem&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;webhook&quot;: &#123;</span><br><span class="line">      &quot;enabled&quot;: true,</span><br><span class="line">      &quot;cacheTTL&quot;: &quot;2m0s&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;anonymous&quot;: &#123;</span><br><span class="line">      &quot;enabled&quot;: false</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;authorization&quot;: &#123;</span><br><span class="line">    &quot;mode&quot;: &quot;Webhook&quot;,</span><br><span class="line">    &quot;webhook&quot;: &#123;</span><br><span class="line">      &quot;cacheAuthorizedTTL&quot;: &quot;5m0s&quot;,</span><br><span class="line">      &quot;cacheUnauthorizedTTL&quot;: &quot;30s&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;address&quot;: &quot;192.168.56.174&quot;,</span><br><span class="line">  &quot;port&quot;: 10250,</span><br><span class="line">  &quot;readOnlyPort&quot;: 10255,</span><br><span class="line">  &quot;cgroupDriver&quot;: &quot;systemd&quot;,                    </span><br><span class="line">  &quot;hairpinMode&quot;: &quot;promiscuous-bridge&quot;,</span><br><span class="line">  &quot;serializeImagePulls&quot;: false,</span><br><span class="line">  &quot;clusterDomain&quot;: &quot;cluster.local.&quot;,</span><br><span class="line">  &quot;clusterDNS&quot;: [&quot;10.96.0.2&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">address：work节点对应的IP（分发至其他work节点后记得修改IP地址）</span></span><br></pre></td></tr></table></figure><p>5、复制相关证书文件至配置文件中的指定 work 节点目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">首先在k8s-work节点创建相关目录</span></span><br><span class="line">mkdir -p /data/kubernetes/&#123;conf,ssl,logs/kubelet&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-work1</span></span><br><span class="line">scp kubelet-bootstrap.kubeconfig kubelet.json k8s-work1:/data/kubernetes/conf/</span><br><span class="line">scp ca.pem k8s-work1:/data/kubernetes/ssl/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-work2</span></span><br><span class="line">scp kubelet-bootstrap.kubeconfig kubelet.json k8s-work2:/data/kubernetes/conf/</span><br><span class="line">scp ca.pem k8s-work2:/data/kubernetes/ssl/</span><br></pre></td></tr></table></figure><p>6、配置 systemd 管理</p><blockquote><p>k8s-work 所有节点均执行</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; &quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/bin/kubelet \</span><br><span class="line">  --bootstrap-kubeconfig=/data/kubernetes/conf/kubelet-bootstrap.kubeconfig \</span><br><span class="line">  --cert-dir=/data/kubernetes/ssl \</span><br><span class="line">  --kubeconfig=/data/kubernetes/conf/kubelet.kubeconfig \</span><br><span class="line">  --config=/data/kubernetes/conf/kubelet.json \</span><br><span class="line">  --container-runtime=remote \</span><br><span class="line">  --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock \</span><br><span class="line">  --rotate-certificates \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kubelet \</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>7、启动 kubelet 组件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kubelet.service</span><br><span class="line">systemctl enable kubelet.service</span><br></pre></td></tr></table></figure><p>8、验证</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">注意：我的master节点并没有进工作负载</span></span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830180454193.png" alt="image-20220830180454193"></p><h6 id="4-3-2-2-6-kube-proxy"><a href="#4-3-2-2-6-kube-proxy" class="headerlink" title="4.3.2.2.6 kube-proxy"></a>4.3.2.2.6 kube-proxy</h6><p>1、配置 kube-proxy 证书请求文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt; &quot;EOF&quot;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;Beijing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;xgxy&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;ops&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>2、生成 kube-proxy 证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830181238980.png" alt="image-20220830181238980"></p><p>3、生成 kube-proxy 的 .kubeconfig 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-cluster kubernetes --certificate-authority=ca.pem --embed-certs=true --server=https://192.168.56.178:6443 --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kube-proxy --client-certificate=kube-proxy.pem --client-key=kube-proxy-key.pem --embed-certs=true --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context default --cluster=kubernetes --user=kube-proxy --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220830181512383.png" alt="image-20220830181512383"></p><p>4、创建 kube-proxy 的 .yaml 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /data/k8s-work/cfssl</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy.yaml &lt;&lt; &quot;EOF&quot;</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 192.168.56.174</span><br><span class="line">clientConnection:</span><br><span class="line">  kubeconfig: /data/kubernetes/conf/kube-proxy.kubeconfig</span><br><span class="line">clusterCIDR: 10.244.0.0/16</span><br><span class="line">healthzBindAddress: 192.168.56.174:10256</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: 192.168.56.174:10249</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>5、复制相关证书文件至配置文件中的指定目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-work1</span></span><br><span class="line">scp kube-proxy*.pem k8s-work1:/data/kubernetes/ssl/</span><br><span class="line">scp kube-proxy.kubeconfig kube-proxy.yaml k8s-work1:/data/kubernetes/conf/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发至k8s-work2</span></span><br><span class="line">scp kube-proxy*.pem k8s-work2:/data/kubernetes/ssl/</span><br><span class="line">scp kube-proxy.kubeconfig kube-proxy.yaml k8s-work2:/data/kubernetes/conf/</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">分发后记得修改IP</span></span><br></pre></td></tr></table></figure><p>6、配置 systemd 管理</p><blockquote><p>k8s-work 所有节点均执行</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; &quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/bin/kube-proxy \</span><br><span class="line">  --config=/data/kubernetes/conf/kube-proxy.yaml \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-proxy \</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建kube-proxy日志目录（所有k8s-work节点均执行）</span></span><br><span class="line">mkdir /data/kubernetes/logs/kube-proxy</span><br></pre></td></tr></table></figure><p>7、启动 kube-proxy 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-proxy.service</span><br><span class="line">systemctl enable kube-proxy.service</span><br></pre></td></tr></table></figure><p>&#x3D;&#x3D;至此，k8s-work 节点的所有组件已经部署完成，并已成功在运行。接下来就是部署 k8s 网络组件了。&#x3D;&#x3D;</p><h3 id="4-4-网络组件部署（Calico）"><a href="#4-4-网络组件部署（Calico）" class="headerlink" title="4.4 网络组件部署（Calico）"></a>4.4 网络组件部署（Calico）</h3><blockquote><p>对于高可用集群架构来说，在任意一台 master 节点上执行即可，因为Calico会以容器的方式部署于 work 节点上</p></blockquote><p>Calico是一个纯三层的数据中心网络方案，是目前Kubernetes主流的网络方案。在 3.4 小节的网络规划中，说到了 pod 的网络规划，那 Calico 就是用来分配该网络（IP）的。</p><h4 id="4-4-1-下载-yaml-文件"><a href="#4-4-1-下载-yaml-文件" class="headerlink" title="4.4.1 下载 yaml 文件"></a>4.4.1 下载 yaml 文件</h4><blockquote><p>yaml 文件下载地址：<a href="https://docs.projectcalico.org/">https://docs.projectcalico.org/</a></p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831095736333.png" alt="image-20220831095736333"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同样在k8s-master1执行</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先创建一个工作目录，用于存放yaml文件</span></span><br><span class="line">mkdir /data/k8s-work/calico &amp;&amp; cd /data/k8s-work/calico</span><br><span class="line">curl https://projectcalico.docs.tigera.io/archive/v3.23/manifests/calico-etcd.yaml -o calico.yaml</span><br></pre></td></tr></table></figure><h4 id="4-4-2-修改文件配置"><a href="#4-4-2-修改文件配置" class="headerlink" title="4.4.2 修改文件配置"></a>4.4.2 修改文件配置</h4><blockquote><p>在 391 行处，修改配置 value 值为上面定义的 10.244.0.0&#x2F;16</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831100505327.png" alt="image-20220831100505327"></p><blockquote><p>修改后</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831100747852.png" alt="image-20220831100747852"></p><h4 id="4-4-3-应用配置文件"><a href="#4-4-3-应用配置文件" class="headerlink" title="4.4.3 应用配置文件"></a>4.4.3 应用配置文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure><h4 id="4-4-4-验证-Calico-网络"><a href="#4-4-4-验证-Calico-网络" class="headerlink" title="4.4.4  验证 Calico 网络"></a>4.4.4  验证 Calico 网络</h4><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831101123441.png" alt="image-20220831101123441"></p><blockquote><p>包括之前未就绪的 work 节点，现在已经就绪了（Ready）</p></blockquote><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831101215397.png" alt="image-20220831101215397"></p><p>&#x3D;&#x3D;如果以上 calico 版本的不能成功运行，建议降低版本，使用以下版本&#x3D;&#x3D;</p><p><a href="https://docs.projectcalico.org/v3.19/manifests/calico.yaml">https://docs.projectcalico.org/v3.19/manifests/calico.yaml</a></p><h3 id="4-5-CoreDNS-部署"><a href="#4-5-CoreDNS-部署" class="headerlink" title="4.5 CoreDNS 部署"></a>4.5 CoreDNS 部署</h3><blockquote><p>对于高可用集群架构来说，在任意一台 master 节点上执行即可，因为 CoreDNS 会以容器的方式部署于 work 节点上</p></blockquote><h4 id="4-5-1-下载-yaml-文件"><a href="#4-5-1-下载-yaml-文件" class="headerlink" title="4.5.1 下载 yaml 文件"></a>4.5.1 下载 yaml 文件</h4><blockquote><p>参考：<a href="https://github.com/coredns/deployment/blob/master/kubernetes/coredns.yaml.sed">https://github.com/coredns/deployment/blob/master/kubernetes/coredns.yaml.sed</a></p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">    - endpoints</span><br><span class="line">    - services</span><br><span class="line">    - pods</span><br><span class="line">    - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - discovery.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">    - endpointslices</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health &#123;</span><br><span class="line">          lameduck 5s</span><br><span class="line">        &#125;</span><br><span class="line">        ready</span><br><span class="line">        kubernetes CLUSTER_DOMAIN REVERSE_CIDRS &#123;</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        forward . UPSTREAMNAMESERVER &#123;</span><br><span class="line">          max_concurrent 1000</span><br><span class="line">        &#125;</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;STUBDOMAINS</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">replicas: not specified here:</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">1. Default is 1.</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">2. Will be tuned <span class="keyword">in</span> real time <span class="keyword">if</span> DNS horizontal auto-scaling is turned on.</span></span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">          operator: &quot;Exists&quot;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      affinity:</span><br><span class="line">         podAntiAffinity:</span><br><span class="line">           requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">           - labelSelector:</span><br><span class="line">               matchExpressions:</span><br><span class="line">               - key: k8s-app</span><br><span class="line">                 operator: In</span><br><span class="line">                 values: [&quot;kube-dns&quot;]</span><br><span class="line">             topologyKey: kubernetes.io/hostname</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: coredns/coredns:1.9.3</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 170Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        args: [ &quot;-conf&quot;, &quot;/etc/coredns/Corefile&quot; ]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /ready</span><br><span class="line">            port: 8181</span><br><span class="line">            scheme: HTTP</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: coredns</span><br><span class="line">            items:</span><br><span class="line">            - key: Corefile</span><br><span class="line">              path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: &quot;9153&quot;</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: CLUSTER_DNS_IP</span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br></pre></td></tr></table></figure><h4 id="4-5-2-修改文件配置"><a href="#4-5-2-修改文件配置" class="headerlink" title="4.5.2 修改文件配置"></a>4.5.2 修改文件配置</h4><blockquote><p>修改部分：</p><p>forward . UPSTREAMNAMESERVER ——&gt; forward . &#x2F;etc&#x2F;resolv.conf</p><p>clusterIP: CLUSTER_DNS_IP ——&gt; clusterIP: 10.96.0.2</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;  coredns.yaml &lt;&lt; &quot;EOF&quot;</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - &quot;&quot;</span><br><span class="line">    resources:</span><br><span class="line">    - endpoints</span><br><span class="line">    - services</span><br><span class="line">    - pods</span><br><span class="line">    - namespaces</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">  - apiGroups:</span><br><span class="line">    - discovery.k8s.io</span><br><span class="line">    resources:</span><br><span class="line">    - endpointslices</span><br><span class="line">    verbs:</span><br><span class="line">    - list</span><br><span class="line">    - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health &#123;</span><br><span class="line">          lameduck 5s</span><br><span class="line">        &#125;</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local  in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        forward . /etc/resolv.conf &#123;</span><br><span class="line">          max_concurrent 1000</span><br><span class="line">        &#125;</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">replicas: not specified here:</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">1. Default is 1.</span></span><br><span class="line"><span class="meta prompt_">  # </span><span class="language-bash">2. Will be tuned <span class="keyword">in</span> real time <span class="keyword">if</span> DNS horizontal auto-scaling is turned on.</span></span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">          operator: &quot;Exists&quot;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">      affinity:</span><br><span class="line">         podAntiAffinity:</span><br><span class="line">           preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">           - weight: 100</span><br><span class="line">             podAffinityTerm:</span><br><span class="line">               labelSelector:</span><br><span class="line">                 matchExpressions:</span><br><span class="line">                   - key: k8s-app</span><br><span class="line">                     operator: In</span><br><span class="line">                     values: [&quot;kube-dns&quot;]</span><br><span class="line">               topologyKey: kubernetes.io/hostname</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: coredns/coredns:1.9.3</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 170Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        args: [ &quot;-conf&quot;, &quot;/etc/coredns/Corefile&quot; ]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /ready</span><br><span class="line">            port: 8181</span><br><span class="line">            scheme: HTTP</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: coredns</span><br><span class="line">            items:</span><br><span class="line">            - key: Corefile</span><br><span class="line">              path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: &quot;9153&quot;</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: 10.96.0.2</span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line"> </span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="4-5-3-应用配置文件"><a href="#4-5-3-应用配置文件" class="headerlink" title="4.5.3 应用配置文件"></a>4.5.3 应用配置文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure><h4 id="4-5-4-验证-CoreDNS"><a href="#4-5-4-验证-CoreDNS" class="headerlink" title="4.5.4 验证 CoreDNS"></a>4.5.4 验证 CoreDNS</h4><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831112825416.png" alt="image-20220831112825416"></p><p>看看是否能正常解析：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master2 ~]# kubectl run -it --rm dns-test --image=busybox:1.28.4 sh</span><br><span class="line">If you don&#x27;t see a command prompt, try pressing enter.</span><br><span class="line">/ # nslookup kubernetes </span><br><span class="line">Server:    10.96.0.2</span><br><span class="line">Address 1: 10.96.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831132451319.png" alt="image-20220831132451319"></p><p>&#x3D;&#x3D;如果以上 coredns yaml 配置文件中的镜像版本的不能成功运行，建议降低版本，使用以下版本&#x3D;&#x3D;</p><p>image: coredns&#x2F;coredns:1.8.4</p><h2 id="五、验证"><a href="#五、验证" class="headerlink" title="五、验证"></a>五、验证</h2><h3 id="5-1-部署-Nginx"><a href="#5-1-部署-Nginx" class="headerlink" title="5.1 部署 Nginx"></a>5.1 部署 Nginx</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;  /data/k8s-work/server/nginx.yaml  &lt;&lt; &quot;EOF&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ReplicationController</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-web</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    name: nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        name: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: nginx</span><br><span class="line">          image: nginx:1.19.6</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-service-nodeport</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 80</span><br><span class="line">      nodePort: 30001</span><br><span class="line">      protocol: TCP</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    name: nginx</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="5-2-Host-访问验证"><a href="#5-2-Host-访问验证" class="headerlink" title="5.2 Host 访问验证"></a>5.2 Host 访问验证</h3><p><img src="https://csdn-rab.oss-cn-chengdu.aliyuncs.com/img/image-20220831131507658.png" alt="image-20220831131507658"></p><p>&#x3D;&#x3D;至此，K8s 高可用集群架构部署完毕！！&#x3D;&#x3D;</p><h2 id="六、FAQ"><a href="#六、FAQ" class="headerlink" title="六、FAQ"></a>六、FAQ</h2><h3 id="6-1-ETCD-启动报错"><a href="#6-1-ETCD-启动报错" class="headerlink" title="6.1 ETCD 启动报错"></a>6.1 ETCD 启动报错</h3><h4 id="6-1-1-报错类型"><a href="#6-1-1-报错类型" class="headerlink" title="6.1.1 报错类型"></a>6.1.1 报错类型</h4><p>当我配置完 ETCD 的 systemd 管理后，启动包如下错误：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conflicting environment variable is shadowed by corresponding command-line flag</span><br></pre></td></tr></table></figure><p>大概意思就是 ETCD 的环境变量冲突问题，查阅了一番资料，再 ETCD3.4+ 版本中已经可以自动读取配置文件。</p><p>原始的 systemd 管理文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF | tee /usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/data/etcd/conf/etcd.conf</span><br><span class="line">ExecStart=/usr/bin/etcd \</span><br><span class="line">  --name=\$&#123;ETCD_NAME&#125; \</span><br><span class="line">  --data-dir=\$&#123;ETCD_DATA_DIR&#125; \</span><br><span class="line">  --listen-peer-urls=\$&#123;ETCD_LISTEN_PEER_URLS&#125; \</span><br><span class="line">  --listen-client-urls=\$&#123;ETCD_LISTEN_CLIENT_URLS&#125; \</span><br><span class="line">  --advertise-client-urls=\$&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \</span><br><span class="line">  --initial-advertise-peer-urls=\$&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \</span><br><span class="line">  --initial-cluster=\$&#123;ETCD_INITIAL_CLUSTER&#125; \</span><br><span class="line">  --initial-cluster-token=\$&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \</span><br><span class="line">  --initial-cluster-state=\$&#123;ETCD_INITIAL_CLUSTER_STATE&#125;  \</span><br><span class="line">  --cert-file=\$&#123;ETCD_CERT_FILE&#125; \</span><br><span class="line">  --key-file=\$&#123;ETCD_KEY_FILE&#125; \</span><br><span class="line">  --peer-cert-file=\$&#123;ETCD_PEER_CERT_FILE&#125; \</span><br><span class="line">  --peer-key-file=\$&#123;ETCD_PEER_KEY_FILE&#125; \</span><br><span class="line">  --trusted-ca-file=\$&#123;ETCD_TRUSTED_CA_FILE&#125; \</span><br><span class="line">  --client-cert-auth=\$&#123;ETCD_CLIENT_CERT_AUTH&#125; \</span><br><span class="line">  --peer-client-cert-auth=\$&#123;ETCD_PEER_CLIENT_CERT_AUTH&#125; \</span><br><span class="line">  --peer-trusted-ca-file=\$&#123;ETCD_PEER_TRUSTED_CA_FILE&#125;</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="6-2-1-解决方案"><a href="#6-2-1-解决方案" class="headerlink" title="6.2.1 解决方案"></a>6.2.1 解决方案</h4><ul><li><p>方案一：去掉 systemd 管理文件中的 <code>EnvironmentFile</code> 参数，<code>ExecStart</code> 部分就可以使用 <code>--xxx=xxx</code> 参数了</p></li><li><p>方案二：去掉 <code>ExecStart</code> 部分后的 <code>--xxx=xxx</code> 参数，因为该 ETCD 版本会自动读取。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt; EOF | tee /usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=-/data/etcd/conf/etcd.conf</span><br><span class="line">ExecStart=/usr/bin/etcd</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li></ul><h3 id="6-2-apiserver-启动报错"><a href="#6-2-apiserver-启动报错" class="headerlink" title="6.2 apiserver 启动报错"></a>6.2 apiserver 启动报错</h3><h4 id="6-2-1-报错类型"><a href="#6-2-1-报错类型" class="headerlink" title="6.2.1 报错类型"></a>6.2.1 报错类型</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kube-apiserver[1706]: Error: unknown flag: --insecure-port</span><br><span class="line">kube-apiserver[2196]: Error: unknown flag: --enable-swagger-ui</span><br></pre></td></tr></table></figure><p>大致意思就是 kube-apiserver 不知道这些变量，看了一下官方文档，在 1.24+ 版本中已经遗弃了 –insecure-port、–enable-swagger-ui 这两个参数了。</p><h4 id="6-2-2-解决方案"><a href="#6-2-2-解决方案" class="headerlink" title="6.2.2 解决方案"></a>6.2.2 解决方案</h4><blockquote><p>修改 .conf 配置文件</p></blockquote><p>修改前：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-apiserver.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_APISERVER_OPTS=&quot;--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \</span><br><span class="line">  --anonymous-auth=false \</span><br><span class="line">  --bind-address=192.168.56.171 \</span><br><span class="line">  --secure-port=6443 \</span><br><span class="line">  --advertise-address=192.168.56.171 \</span><br><span class="line">  --insecure-port=8080 \</span><br><span class="line">  --authorization-mode=Node,RBAC \</span><br><span class="line">  --runtime-config=api/all=true \</span><br><span class="line">  --enable-bootstrap-token-auth \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --token-auth-file=/data/kubernetes/tokenfile/token.csv \</span><br><span class="line">  --service-node-port-range=30000-50000 \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-apiserver.pem  \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --client-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --kubelet-client-certificate=/data/kubernetes/ssl/kube-apiserver.pem \</span><br><span class="line">  --kubelet-client-key=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --service-account-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --service-account-signing-key-file=/data/kubernetes/ssl/ca-key.pem  \</span><br><span class="line">  --service-account-issuer=api \</span><br><span class="line">  --etcd-cafile=/data/etcd/ssl/ca.pem \</span><br><span class="line">  --etcd-certfile=/data/etcd/ssl/etcd.pem \</span><br><span class="line">  --etcd-keyfile=/data/etcd/ssl/etcd-key.pem \</span><br><span class="line">  --etcd-servers=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 \</span><br><span class="line">  --enable-swagger-ui=true \</span><br><span class="line">  --allow-privileged=true \</span><br><span class="line">  --apiserver-count=3 \</span><br><span class="line">  --audit-log-maxage=30 \</span><br><span class="line">  --audit-log-maxbackup=3 \</span><br><span class="line">  --audit-log-maxsize=100 \</span><br><span class="line">  --audit-log-path=/data/kubernetes/logs/kube-apiserver/kube-apiserver-audit.log \</span><br><span class="line">  --event-ttl=1h \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-apiserver \</span><br><span class="line">  --v=4&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>修改后：去掉 –insecure-port、–enable-swagger-ui 选项参数即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-apiserver.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_APISERVER_OPTS=&quot;--enable-admission-plugins=NamespaceLifecycle,NodeRestriction,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \</span><br><span class="line">  --anonymous-auth=false \</span><br><span class="line">  --bind-address=192.168.56.171 \</span><br><span class="line">  --secure-port=6443 \</span><br><span class="line">  --advertise-address=192.168.56.171 \</span><br><span class="line">  --authorization-mode=Node,RBAC \</span><br><span class="line">  --runtime-config=api/all=true \</span><br><span class="line">  --enable-bootstrap-token-auth \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --token-auth-file=/data/kubernetes/tokenfile/token.csv \</span><br><span class="line">  --service-node-port-range=30000-50000 \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-apiserver.pem  \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --client-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --kubelet-client-certificate=/data/kubernetes/ssl/kube-apiserver.pem \</span><br><span class="line">  --kubelet-client-key=/data/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="line">  --service-account-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --service-account-signing-key-file=/data/kubernetes/ssl/ca-key.pem  \</span><br><span class="line">  --service-account-issuer=api \</span><br><span class="line">  --etcd-cafile=/data/etcd/ssl/ca.pem \</span><br><span class="line">  --etcd-certfile=/data/etcd/ssl/etcd.pem \</span><br><span class="line">  --etcd-keyfile=/data/etcd/ssl/etcd-key.pem \</span><br><span class="line">  --etcd-servers=https://192.168.56.171:2379,https://192.168.56.172:2379,https://192.168.56.173:2379 \</span><br><span class="line">  --allow-privileged=true \</span><br><span class="line">  --apiserver-count=3 \</span><br><span class="line">  --audit-log-maxage=30 \</span><br><span class="line">  --audit-log-maxbackup=3 \</span><br><span class="line">  --audit-log-maxsize=100 \</span><br><span class="line">  --audit-log-path=/data/kubernetes/logs/kube-apiserver/kube-apiserver-audit.log \</span><br><span class="line">  --event-ttl=1h \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-apiserver \</span><br><span class="line">  --v=4&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="6-3-controller-manager-启动报错"><a href="#6-3-controller-manager-启动报错" class="headerlink" title="6.3 controller-manager 启动报错"></a>6.3 controller-manager 启动报错</h3><blockquote><p>与 apiserver 启动报错类似，在该 k8s 版本中，有些选项参数已经被遗弃了，根据提示去掉即可。</p></blockquote><h4 id="6-3-1-报错类型"><a href="#6-3-1-报错类型" class="headerlink" title="6.3.1 报错类型"></a>6.3.1 报错类型</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kube-controller-manager[3505]: Error: unknown flag: --port</span><br><span class="line">kube-controller-manager[4159]: Error: unknown flag: --horizontal-pod-autoscaler-use-rest-clients</span><br></pre></td></tr></table></figure><h4 id="6-3-2-解决方案"><a href="#6-3-2-解决方案" class="headerlink" title="6.3.2 解决方案"></a>6.3.2 解决方案</h4><blockquote><p>修改 .conf 配置文件</p></blockquote><p>修改前：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-controller-manager.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=&quot;--port=10252 \</span><br><span class="line">  --secure-port=10257 \</span><br><span class="line">  --bind-address=127.0.0.1 \</span><br><span class="line">  --kubeconfig=/data/kubernetes/conf/kube-controller-manager.kubeconfig \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --cluster-name=kubernetes \</span><br><span class="line">  --cluster-signing-cert-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cluster-signing-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --allocate-node-cidrs=true \</span><br><span class="line">  --cluster-cidr=10.244.0.0/16 \</span><br><span class="line">  --experimental-cluster-signing-duration=87600h \</span><br><span class="line">  --root-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --service-account-private-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --leader-elect=true \</span><br><span class="line">  --feature-gates=RotateKubeletServerCertificate=true \</span><br><span class="line">  --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">  --horizontal-pod-autoscaler-use-rest-clients=true \</span><br><span class="line">  --horizontal-pod-autoscaler-sync-period=10s \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-controller-manager.pem \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-controller-manager-key.pem \</span><br><span class="line">  --use-service-account-credentials=true \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-controller-manager \</span><br><span class="line">  --v=2&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>修改后：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-controller-manager.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=&quot;--secure-port=10257 \</span><br><span class="line">  --bind-address=127.0.0.1 \</span><br><span class="line">  --kubeconfig=/data/kubernetes/conf/kube-controller-manager.kubeconfig \</span><br><span class="line">  --service-cluster-ip-range=10.96.0.0/16 \</span><br><span class="line">  --cluster-name=kubernetes \</span><br><span class="line">  --cluster-signing-cert-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cluster-signing-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --allocate-node-cidrs=true \</span><br><span class="line">  --cluster-cidr=10.244.0.0/16 \</span><br><span class="line">  --experimental-cluster-signing-duration=87600h \</span><br><span class="line">  --root-ca-file=/data/kubernetes/ssl/ca.pem \</span><br><span class="line">  --service-account-private-key-file=/data/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  --leader-elect=true \</span><br><span class="line">  --feature-gates=RotateKubeletServerCertificate=true \</span><br><span class="line">  --controllers=*,bootstrapsigner,tokencleaner \</span><br><span class="line">  --tls-cert-file=/data/kubernetes/ssl/kube-controller-manager.pem \</span><br><span class="line">  --tls-private-key-file=/data/kubernetes/ssl/kube-controller-manager-key.pem \</span><br><span class="line">  --use-service-account-credentials=true \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kube-controller-manager \</span><br><span class="line">  --v=2&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="6-4-scheduler-启动报错"><a href="#6-4-scheduler-启动报错" class="headerlink" title="6.4 scheduler 启动报错"></a>6.4 scheduler 启动报错</h3><h4 id="6-4-1-报错类型"><a href="#6-4-1-报错类型" class="headerlink" title="6.4.1 报错类型"></a>6.4.1 报错类型</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kube-scheduler[5036]: Error: unknown flag: --address</span><br></pre></td></tr></table></figure><h4 id="6-4-2-解决方案"><a href="#6-4-2-解决方案" class="headerlink" title="6.4.2 解决方案"></a>6.4.2 解决方案</h4><p>修改前：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-scheduler.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_SCHEDULER_OPTS=&quot;--address=127.0.0.1 \</span><br><span class="line">--kubeconfig=/data/kubernetes/conf/kube-scheduler.kubeconfig \</span><br><span class="line">--leader-elect=true \</span><br><span class="line">--alsologtostderr=true \</span><br><span class="line">--logtostderr=false \</span><br><span class="line">--log-dir=/data/kubernetes/logs/kube-scheduler \</span><br><span class="line">--v=2&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>修改后：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /data/kubernetes/conf/kube-scheduler.conf &lt;&lt; &quot;EOF&quot;</span><br><span class="line">KUBE_SCHEDULER_OPTS=&quot;--kubeconfig=/data/kubernetes/conf/kube-scheduler.kubeconfig \</span><br><span class="line">--leader-elect=true \</span><br><span class="line">--alsologtostderr=true \</span><br><span class="line">--logtostderr=false \</span><br><span class="line">--log-dir=/data/kubernetes/logs/kube-scheduler \</span><br><span class="line">--v=2&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="6-5-kubelet-启动报错"><a href="#6-5-kubelet-启动报错" class="headerlink" title="6.5 kubelet 启动报错"></a>6.5 kubelet 启动报错</h3><h4 id="6-5-1-报错类型"><a href="#6-5-1-报错类型" class="headerlink" title="6.5.1 报错类型"></a>6.5.1 报错类型</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubelet[5036]: Error: unknown flag: --network-plugin</span><br></pre></td></tr></table></figure><h4 id="6-5-2-解决方案"><a href="#6-5-2-解决方案" class="headerlink" title="6.5.2 解决方案"></a>6.5.2 解决方案</h4><p>修改前：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; &quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/bin/kubelet \</span><br><span class="line">  --bootstrap-kubeconfig=/data/kubernetes/conf/kubelet-bootstrap.kubeconfig \</span><br><span class="line">  --cert-dir=/data/kubernetes/ssl \</span><br><span class="line">  --kubeconfig=/data/kubernetes/conf/kubelet.kubeconfig \</span><br><span class="line">  --config=/data/kubernetes/conf/kubelet.json \</span><br><span class="line">  --container-runtime=remote \</span><br><span class="line">  --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock \</span><br><span class="line">  --network-plugin=cni \</span><br><span class="line">  --rotate-certificates \</span><br><span class="line">  --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.2 \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kubelet \</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>修改后：去掉 <code>--network-plugin</code> 和 <code>--pod-infra-container-image</code> 因为，cri-docker 的 systemd 文件已经指定了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; &quot;EOF&quot;</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/bin/kubelet \</span><br><span class="line">  --bootstrap-kubeconfig=/data/kubernetes/conf/kubelet-bootstrap.kubeconfig \</span><br><span class="line">  --cert-dir=/data/kubernetes/ssl \</span><br><span class="line">  --kubeconfig=/data/kubernetes/conf/kubelet.kubeconfig \</span><br><span class="line">  --config=/data/kubernetes/conf/kubelet.json \</span><br><span class="line">  --container-runtime=remote \</span><br><span class="line">  --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock \</span><br><span class="line">  --rotate-certificates \</span><br><span class="line">  --alsologtostderr=true \</span><br><span class="line">  --logtostderr=false \</span><br><span class="line">  --log-dir=/data/kubernetes/logs/kubelet \</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">K8s 高可用集群架构（二进制）部署及应用，版本 1.24.4。</summary>
    
    
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
    <category term="K8s" scheme="https://blog.rabcnops.cn/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/K8s/"/>
    
    
    <category term="K8s" scheme="https://blog.rabcnops.cn/tags/K8s/"/>
    
    <category term="云原生" scheme="https://blog.rabcnops.cn/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"/>
    
  </entry>
  
</feed>
